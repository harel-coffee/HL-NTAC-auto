{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mccarthyajb/HL-NTAC/blob/main/Fig12_coarse_and_fine_Better_Keras2_Multiclassifier_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItPEsplPVrS_",
        "outputId": "eed9d4bd-db89-4c58-cc87-11211bb69662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul 24 14:28:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX7-IPH85Arq"
      },
      "source": [
        "# SDAV Extra - Violin Plots\n",
        "\n",
        "This notebook will demonstrate the use of Violin Plots. This visualisation technique, similar to a box plot, is well suited for comparing multiple distributions, and show a curved distribution plot for each feature under consideration. Below shows a simple violin plot example using Seaborn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "4lYJo_Iv5Arr",
        "outputId": "c13ec524-328d-46b6-f721-4cb1f668d49d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.7/site-packages (0.2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from lime) (4.59.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/site-packages (from lime) (0.24.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/site-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from lime) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from lime) (1.21.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (from lime) (3.5.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2.19.5)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (21.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (9.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.12->lime) (5.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging>=20.0->scikit-image>=0.12->lime) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn>=0.18->lime) (1.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->lime) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/site-packages (from matplotlib->lime) (4.34.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->lime) (4.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.15.0)\n",
            "Drive already mounted at ./mount; to attempt to forcibly remount, call drive.mount(\"./mount\", force_remount=True).\n",
            "Drive Mounted\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#!pip install seaborn\n",
        "!pip install lime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('./mount')\n",
        "print(\"Drive Mounted\")\n",
        "\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "ax = sns.violinplot(x=\"day\", y=\"total_bill\", data=tips)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8smbGmxq5Aru"
      },
      "source": [
        "## Case Study: Comparing Benign and DDoS behaviours in network traffic analysis using CICIDS2017\n",
        "\n",
        "Let's consider an example where we want to look at benign and malicious network traffic. We will use to CICIDS2017 dataset for this. This dataset captures in the region of 80 numerical features that characterise network activity. Each data instance has been labelled as either benign or as an attack type (we focus on DDoS here, however other attacks are present in the full dataset). What data attributes set these two classes apart? We can use violin plots to judge this visually over the entire dataset.\n",
        "\n",
        "### Load in dataset and clean it up\n",
        "\n",
        "First we will load in the data set, and we will remove all Not-a-Number and Infinity values that may be present. We will also remove columns that contain only zeros (i.e., no separating features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "gsgMZTkq5Arv",
        "outputId": "7e35605f-9721-461d-82d8-36e7b3d32ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read in df1 - DDoS\n",
            "Read in df2 - PortScan\n",
            "Read in df3 - Botnet\n",
            "Read in df4 - Benign (Normal Human Activities)\n",
            "Read in df5 - Infiltration\n",
            "Read in df6 - Web Attacks\n",
            "Read in df7 - Brute Force\n",
            "Read in df8 - DoS/DDoS/HeartBleed\n",
            "Before Concat\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34e94ed3-1508-46d9-a2c0-4079002f3c82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>...</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54865</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55054</td>\n",
              "      <td>109</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55055</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46236</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54863</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692698</th>\n",
              "      <td>53</td>\n",
              "      <td>32215</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>112</td>\n",
              "      <td>152</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692699</th>\n",
              "      <td>53</td>\n",
              "      <td>324</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>84</td>\n",
              "      <td>362</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692700</th>\n",
              "      <td>58030</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>21.92031</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692701</th>\n",
              "      <td>53</td>\n",
              "      <td>1048635</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>192</td>\n",
              "      <td>256</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692702</th>\n",
              "      <td>53</td>\n",
              "      <td>94939</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>188</td>\n",
              "      <td>226</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2827876 rows × 71 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34e94ed3-1508-46d9-a2c0-4079002f3c82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34e94ed3-1508-46d9-a2c0-4079002f3c82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34e94ed3-1508-46d9-a2c0-4079002f3c82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Destination Port   Flow Duration   Total Fwd Packets  \\\n",
              "0                   54865               3                   2   \n",
              "1                   55054             109                   1   \n",
              "2                   55055              52                   1   \n",
              "3                   46236              34                   1   \n",
              "4                   54863               3                   2   \n",
              "...                   ...             ...                 ...   \n",
              "692698                 53           32215                   4   \n",
              "692699                 53             324                   2   \n",
              "692700              58030              82                   2   \n",
              "692701                 53         1048635                   6   \n",
              "692702                 53           94939                   4   \n",
              "\n",
              "         Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "0                             0                           12   \n",
              "1                             1                            6   \n",
              "2                             1                            6   \n",
              "3                             1                            6   \n",
              "4                             0                           12   \n",
              "...                         ...                          ...   \n",
              "692698                        2                          112   \n",
              "692699                        2                           84   \n",
              "692700                        1                           31   \n",
              "692701                        2                          192   \n",
              "692702                        2                          188   \n",
              "\n",
              "         Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
              "0                                  0                       6   \n",
              "1                                  6                       6   \n",
              "2                                  6                       6   \n",
              "3                                  6                       6   \n",
              "4                                  0                       6   \n",
              "...                              ...                     ...   \n",
              "692698                           152                      28   \n",
              "692699                           362                      42   \n",
              "692700                             6                      31   \n",
              "692701                           256                      32   \n",
              "692702                           226                      47   \n",
              "\n",
              "         Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
              "0                            6                      6.0   \n",
              "1                            6                      6.0   \n",
              "2                            6                      6.0   \n",
              "3                            6                      6.0   \n",
              "4                            6                      6.0   \n",
              "...                        ...                      ...   \n",
              "692698                      28                     28.0   \n",
              "692699                      42                     42.0   \n",
              "692700                       0                     15.5   \n",
              "692701                      32                     32.0   \n",
              "692702                      47                     47.0   \n",
              "\n",
              "         Fwd Packet Length Std  ...   min_seg_size_forward  Active Mean  \\\n",
              "0                      0.00000  ...                     20          0.0   \n",
              "1                      0.00000  ...                     20          0.0   \n",
              "2                      0.00000  ...                     20          0.0   \n",
              "3                      0.00000  ...                     20          0.0   \n",
              "4                      0.00000  ...                     20          0.0   \n",
              "...                        ...  ...                    ...          ...   \n",
              "692698                 0.00000  ...                     20          0.0   \n",
              "692699                 0.00000  ...                     20          0.0   \n",
              "692700                21.92031  ...                     32          0.0   \n",
              "692701                 0.00000  ...                     20          0.0   \n",
              "692702                 0.00000  ...                     20          0.0   \n",
              "\n",
              "         Active Std   Active Max   Active Min  Idle Mean   Idle Std  \\\n",
              "0               0.0            0            0        0.0        0.0   \n",
              "1               0.0            0            0        0.0        0.0   \n",
              "2               0.0            0            0        0.0        0.0   \n",
              "3               0.0            0            0        0.0        0.0   \n",
              "4               0.0            0            0        0.0        0.0   \n",
              "...             ...          ...          ...        ...        ...   \n",
              "692698          0.0            0            0        0.0        0.0   \n",
              "692699          0.0            0            0        0.0        0.0   \n",
              "692700          0.0            0            0        0.0        0.0   \n",
              "692701          0.0            0            0        0.0        0.0   \n",
              "692702          0.0            0            0        0.0        0.0   \n",
              "\n",
              "         Idle Max   Idle Min   Label  \n",
              "0               0          0  BENIGN  \n",
              "1               0          0  BENIGN  \n",
              "2               0          0  BENIGN  \n",
              "3               0          0  BENIGN  \n",
              "4               0          0  BENIGN  \n",
              "...           ...        ...     ...  \n",
              "692698          0          0  BENIGN  \n",
              "692699          0          0  BENIGN  \n",
              "692700          0          0  BENIGN  \n",
              "692701          0          0  BENIGN  \n",
              "692702          0          0  BENIGN  \n",
              "\n",
              "[2827876 rows x 71 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load in the dataset\n",
        "df = pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "df1=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "print(\"Read in df1 - DDoS\")\n",
        "\n",
        "df2=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
        "print(\"Read in df2 - PortScan\")\n",
        "    \n",
        "df3=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017//Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
        "print(\"Read in df3 - Botnet\")\n",
        "    \n",
        "df4=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017//Monday-WorkingHours.pcap_ISCX.csv')\n",
        "print(\"Read in df4 - Benign (Normal Human Activities)\")\n",
        "    \n",
        "df5=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')\n",
        "print(\"Read in df5 - Infiltration\")\n",
        "    \n",
        "df6=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017//Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')\n",
        "print(\"Read in df6 - Web Attacks\")\n",
        "    \n",
        "df7=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017//Tuesday-WorkingHours.pcap_ISCX.csv')\n",
        "print(\"Read in df7 - Brute Force\")\n",
        "    \n",
        "df8=pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017//Wednesday-workingHours.pcap_ISCX.csv')\n",
        "print(\"Read in df8 - DoS/DDoS/HeartBleed\")\n",
        "\n",
        "#frames = [df1, df2, df3, df4]\n",
        "frames = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
        "print(\"Before Concat\")\n",
        "df = pd.concat(frames)\n",
        "\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Monday-WorkingHours.pcap_ISCX.csv')\n",
        "# Remove NaN and Inf\n",
        "df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "# Remove columns with all zero values\n",
        "df = df.loc[:, (df != 0).any(axis=0)]\n",
        "# Output table\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37PsvhHm5Arx",
        "outputId": "7b207003-be0b-45c8-8f11-b093c29ed014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
            "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
            "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
            "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
            "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
            "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
            "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
            "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
            "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
            "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
            "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Fwd URG Flags',\n",
            "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
            "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
            "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
            "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
            "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
            "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
            "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
            "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Subflow Fwd Packets',\n",
            "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
            "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
            "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
            "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
            "       ' Idle Max', ' Idle Min', ' Label'],\n",
            "      dtype='object')\n",
            "Length:  71\n"
          ]
        }
      ],
      "source": [
        "# What columns are left?\n",
        "print (df.columns)\n",
        "# How many columns?\n",
        "print (\"Length: \", len(df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMNMIjX25Arz"
      },
      "source": [
        "### Normalise each column\n",
        "\n",
        "Each column has its own range of values - some are quite narrow, some are quite large. We often normalise data to make it easier to work with and draw comparisons - this essentially means scaling it to be within a fixed range. Here, we want to normalise each feature indepedently - essentially meaning that each column will have a minimum value of zero and a maximum value of one, and all values for that particular feature will be scaled within this range.\n",
        "\n",
        "We will use the sci-kit learn library to achieve this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "s2ZmxzNu5Ar0",
        "outputId": "8a22607f-72ac-4b51-e875-d4675d909fb3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6c87068f-927c-43ff-88dc-029f6dbe9f2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>...</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113636</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>1.333333e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>9.323764e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.002072</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111968</td>\n",
              "      <td>0.336391</td>\n",
              "      <td>1.016667e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>4.661882e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>9.153974e-09</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.002072</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112020</td>\n",
              "      <td>0.339744</td>\n",
              "      <td>5.416666e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>4.661882e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>9.153974e-09</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.002072</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112072</td>\n",
              "      <td>0.343137</td>\n",
              "      <td>3.916666e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>4.661882e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>9.153974e-09</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.005035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113636</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>1.333333e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>9.323764e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692698</th>\n",
              "      <td>0.012043</td>\n",
              "      <td>0.004713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003891</td>\n",
              "      <td>0.026243</td>\n",
              "      <td>0.013102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111925</td>\n",
              "      <td>0.333364</td>\n",
              "      <td>5.379999e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>8.702180e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.319007e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692699</th>\n",
              "      <td>0.018065</td>\n",
              "      <td>0.007070</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009268</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.031204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112511</td>\n",
              "      <td>0.335391</td>\n",
              "      <td>1.008333e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>6.526635e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>5.522898e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692700</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002609</td>\n",
              "      <td>0.003076</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.002072</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112115</td>\n",
              "      <td>0.339431</td>\n",
              "      <td>4.500000e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>2.408639e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>9.153974e-09</td>\n",
              "      <td>0.015366</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692701</th>\n",
              "      <td>0.013763</td>\n",
              "      <td>0.005386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006554</td>\n",
              "      <td>0.044199</td>\n",
              "      <td>0.022067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111921</td>\n",
              "      <td>0.333335</td>\n",
              "      <td>1.248483e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>1.491802e-05</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.905696e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692702</th>\n",
              "      <td>0.020215</td>\n",
              "      <td>0.007911</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005786</td>\n",
              "      <td>0.039019</td>\n",
              "      <td>0.019481</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111923</td>\n",
              "      <td>0.333344</td>\n",
              "      <td>1.583400e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>1.460723e-05</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.447997e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2827876 rows × 58 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c87068f-927c-43ff-88dc-029f6dbe9f2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c87068f-927c-43ff-88dc-029f6dbe9f2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c87068f-927c-43ff-88dc-029f6dbe9f2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
              "0                     0.002581                 0.001010   \n",
              "1                     0.002581                 0.001010   \n",
              "2                     0.002581                 0.001010   \n",
              "3                     0.002581                 0.001010   \n",
              "4                     0.002581                 0.001010   \n",
              "...                        ...                      ...   \n",
              "692698                0.012043                 0.004713   \n",
              "692699                0.018065                 0.007070   \n",
              "692700                0.000000                 0.002609   \n",
              "692701                0.013763                 0.005386   \n",
              "692702                0.020215                 0.007911   \n",
              "\n",
              "         Fwd Packet Length Std  Bwd Packet Length Max   Bwd Packet Length Min  \\\n",
              "0                     0.000000               0.000000                0.000000   \n",
              "1                     0.000000               0.000307                0.002072   \n",
              "2                     0.000000               0.000307                0.002072   \n",
              "3                     0.000000               0.000307                0.002072   \n",
              "4                     0.000000               0.000000                0.000000   \n",
              "...                        ...                    ...                     ...   \n",
              "692698                0.000000               0.003891                0.026243   \n",
              "692699                0.000000               0.009268                0.062500   \n",
              "692700                0.003076               0.000307                0.002072   \n",
              "692701                0.000000               0.006554                0.044199   \n",
              "692702                0.000000               0.005786                0.039019   \n",
              "\n",
              "         Bwd Packet Length Mean   Bwd Packet Length Std  Flow Bytes/s  \\\n",
              "0                      0.000000                     0.0      0.113636   \n",
              "1                      0.001034                     0.0      0.111968   \n",
              "2                      0.001034                     0.0      0.112020   \n",
              "3                      0.001034                     0.0      0.112072   \n",
              "4                      0.000000                     0.0      0.113636   \n",
              "...                         ...                     ...           ...   \n",
              "692698                 0.013102                     0.0      0.111925   \n",
              "692699                 0.031204                     0.0      0.112511   \n",
              "692700                 0.001034                     0.0      0.112115   \n",
              "692701                 0.022067                     0.0      0.111921   \n",
              "692702                 0.019481                     0.0      0.111923   \n",
              "\n",
              "         Flow Packets/s   Flow IAT Mean  ...   Subflow Fwd Bytes  \\\n",
              "0              0.444444    1.333333e-07  ...        9.323764e-07   \n",
              "1              0.336391    1.016667e-06  ...        4.661882e-07   \n",
              "2              0.339744    5.416666e-07  ...        4.661882e-07   \n",
              "3              0.343137    3.916666e-07  ...        4.661882e-07   \n",
              "4              0.444444    1.333333e-07  ...        9.323764e-07   \n",
              "...                 ...             ...  ...                 ...   \n",
              "692698         0.333364    5.379999e-05  ...        8.702180e-06   \n",
              "692699         0.335391    1.008333e-06  ...        6.526635e-06   \n",
              "692700         0.339431    4.500000e-07  ...        2.408639e-06   \n",
              "692701         0.333335    1.248483e-03  ...        1.491802e-05   \n",
              "692702         0.333344    1.583400e-04  ...        1.460723e-05   \n",
              "\n",
              "         Subflow Bwd Packets   Subflow Bwd Bytes  Init_Win_bytes_forward  \\\n",
              "0                   0.000000        0.000000e+00                0.000519   \n",
              "1                   0.000003        9.153974e-09                0.000458   \n",
              "2                   0.000003        9.153974e-09                0.000458   \n",
              "3                   0.000003        9.153974e-09                0.000488   \n",
              "4                   0.000000        0.000000e+00                0.000504   \n",
              "...                      ...                 ...                     ...   \n",
              "692698              0.000007        2.319007e-07                0.000000   \n",
              "692699              0.000007        5.522898e-07                0.000000   \n",
              "692700              0.000003        9.153974e-09                0.015366   \n",
              "692701              0.000007        3.905696e-07                0.000000   \n",
              "692702              0.000007        3.447997e-07                0.000000   \n",
              "\n",
              "         Init_Win_bytes_backward   act_data_pkt_fwd   min_seg_size_forward  \\\n",
              "0                       0.000000           0.000005                    1.0   \n",
              "1                       0.003922           0.000000                    1.0   \n",
              "2                       0.003922           0.000000                    1.0   \n",
              "3                       0.005035           0.000000                    1.0   \n",
              "4                       0.000000           0.000005                    1.0   \n",
              "...                          ...                ...                    ...   \n",
              "692698                  0.000000           0.000014                    1.0   \n",
              "692699                  0.000000           0.000005                    1.0   \n",
              "692700                  0.000015           0.000000                    1.0   \n",
              "692701                  0.000000           0.000023                    1.0   \n",
              "692702                  0.000000           0.000014                    1.0   \n",
              "\n",
              "        Active Mean   Active Std   Active Max  \n",
              "0               0.0          0.0          0.0  \n",
              "1               0.0          0.0          0.0  \n",
              "2               0.0          0.0          0.0  \n",
              "3               0.0          0.0          0.0  \n",
              "4               0.0          0.0          0.0  \n",
              "...             ...          ...          ...  \n",
              "692698          0.0          0.0          0.0  \n",
              "692699          0.0          0.0          0.0  \n",
              "692700          0.0          0.0          0.0  \n",
              "692701          0.0          0.0          0.0  \n",
              "692702          0.0          0.0          0.0  \n",
              "\n",
              "[2827876 rows x 58 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import scikit learn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Creating X and Y from the dataset\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df[' Label'])\n",
        "Y_attack = le.transform(df[' Label']) # multi-class \n",
        "Y_class = df.iloc[:,-1].values # binary\n",
        "\n",
        "# Extract only the numerical feature columns\n",
        "subset = df.iloc[:,7:65].astype(float)\n",
        "# Define the scaler\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# Apply the scaler to each column of our dataframe\n",
        "df2 = pd.DataFrame(min_max_scaler.fit_transform(subset), columns=subset.columns, index=subset.index)\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFpjJqAh5Ar2"
      },
      "source": [
        "### Separate data based on class\n",
        "\n",
        "We have scaled the entire dataset so that all data for each feature is scaled in a consistent manner. We now want to split our dataset based on the classes of data that exist. Here, we know we have benign and DDoS classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xqd_s7d5Ar2",
        "outputId": "804fd5a2-0941-4a0d-c869-aac7cc6fda7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['BENIGN' 'DDoS' 'PortScan' 'Bot' 'Infiltration'\n",
            " 'Web Attack � Brute Force' 'Web Attack � XSS'\n",
            " 'Web Attack � Sql Injection' 'FTP-Patator' 'SSH-Patator' 'DoS slowloris'\n",
            " 'DoS Slowhttptest' 'DoS Hulk' 'DoS GoldenEye' 'Heartbleed']\n",
            "0         BENIGN\n",
            "1         BENIGN\n",
            "2         BENIGN\n",
            "3         BENIGN\n",
            "4         BENIGN\n",
            "           ...  \n",
            "692698    BENIGN\n",
            "692699    BENIGN\n",
            "692700    BENIGN\n",
            "692701    BENIGN\n",
            "692702    BENIGN\n",
            "Name:  Label, Length: 2827876, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Output the classes\n",
        "outcome = df[' Label'].unique()\n",
        "print(outcome)\n",
        "\n",
        "Y_attack = df[' Label']\n",
        "print(Y_attack)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXAbfBVpQWIx"
      },
      "source": [
        "#Resample the dataset adjusting for bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LgMFZLzjueV",
        "outputId": "25fe5f37-67d1-4ec6-c6fb-7e8f4a6fcfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imblearn:0.8.1\n",
            "0         BENIGN\n",
            "1         BENIGN\n",
            "2         BENIGN\n",
            "3         BENIGN\n",
            "4         BENIGN\n",
            "           ...  \n",
            "692698    BENIGN\n",
            "692699    BENIGN\n",
            "692700    BENIGN\n",
            "692701    BENIGN\n",
            "692702    BENIGN\n",
            "Name:  Label, Length: 2827876, dtype: object\n",
            "[0 0 0 ... 0 0 0]\n",
            "['BENIGN' 'DDoS' 'PortScan' 'Bot' 'Infiltration'\n",
            " 'Web Attack � Brute Force' 'Web Attack � XSS'\n",
            " 'Web Attack � Sql Injection' 'FTP-Patator' 'SSH-Patator' 'DoS slowloris'\n",
            " 'DoS Slowhttptest' 'DoS Hulk' 'DoS GoldenEye' 'Heartbleed']\n",
            "Oversampling...\n",
            "Finished oversampling...\n",
            "Undersampling...\n",
            "Finished undersampling...\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.00900909 0.0177251  ... 0.00047064 0.00099173 0.00147409]\n",
            " [0.         0.02291102 0.0406136  ... 0.00942168 0.         0.00942168]\n",
            " ...\n",
            " [0.         0.02129322 0.02753706 ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "0                 BENIGN\n",
            "1                 BENIGN\n",
            "2                 BENIGN\n",
            "3                 BENIGN\n",
            "4                 BENIGN\n",
            "              ...       \n",
            "4495    Web Attack � XSS\n",
            "4496    Web Attack � XSS\n",
            "4497    Web Attack � XSS\n",
            "4498    Web Attack � XSS\n",
            "4499    Web Attack � XSS\n",
            "Name:  Label, Length: 4500, dtype: object\n",
            "(225745, 59)\n",
            "[ 0  0  0 ... 14 14 14]\n"
          ]
        }
      ],
      "source": [
        "# Resample\n",
        "import imblearn\n",
        "print(\"imblearn:\" + imblearn.__version__)\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "# print(Y_class)\n",
        "print(Y_attack)\n",
        "x_scaled = np.array(df2)\n",
        "transformed_label = le.fit_transform(Y_attack)\n",
        "print(transformed_label)\n",
        "\n",
        "#define oversampling strategy\n",
        "print(outcome)\n",
        "# orig_sampling_strategy = {\n",
        "#     \"BENIGN\"                    : 2271320,\n",
        "#     \"DDoS\"                      :  128025,\n",
        "#     'PortScan'                  :  158804, \n",
        "#     'Bot'                       :    1956, \n",
        "#     'Infiltration'               :      36,\n",
        "#     'Web Attack � Brute Force'  :    1507, \n",
        "#     'Web Attack � XSS'          :     652,\n",
        "#     'Web Attack � Sql Injection':      21, \n",
        "#     'FTP-Patator'               :    7935, \n",
        "#     'SSH-Patator'               :    5897, \n",
        "#     'DoS slowloris'             :    5796,\n",
        "#     'DoS Slowhttptest'          :    5499, \n",
        "#     'DoS Hulk'                  :  231073, \n",
        "#     'DoS GoldenEye'             :   10293, \n",
        "#     'Heartbleed'                :      11\n",
        "# }\n",
        "\n",
        "over_sampling_strategy = { # Minimum 25\n",
        "    \"BENIGN\"                    : 2271320,\n",
        "    \"DDoS\"                      :  128025,\n",
        "    'PortScan'                  :  158804, \n",
        "    'Bot'                       :    1956, \n",
        "    'Infiltration'               :      36,\n",
        "    'Web Attack � Brute Force'  :    1507, \n",
        "    'Web Attack � XSS'          :     652,\n",
        "    'Web Attack � Sql Injection':      25, \n",
        "    'FTP-Patator'               :    7935, \n",
        "    'SSH-Patator'               :    5897, \n",
        "    'DoS slowloris'             :    5796,\n",
        "    'DoS Slowhttptest'          :    5499, \n",
        "    'DoS Hulk'                  :  231073, \n",
        "    'DoS GoldenEye'             :   10293, \n",
        "    'Heartbleed'                :      25\n",
        "}\n",
        "\n",
        "over_sampling_strategy40 = { # Minimum 40\n",
        "    \"BENIGN\"                    : 2271320,\n",
        "    \"DDoS\"                      :  128025,\n",
        "    'PortScan'                  :  158804, \n",
        "    'Bot'                       :    1956, \n",
        "    'Infiltration'               :      40,\n",
        "    'Web Attack � Brute Force'  :    1507, \n",
        "    'Web Attack � XSS'          :     652,\n",
        "    'Web Attack � Sql Injection':      40, \n",
        "    'FTP-Patator'               :    7935, \n",
        "    'SSH-Patator'               :    5897, \n",
        "    'DoS slowloris'             :    5796,\n",
        "    'DoS Slowhttptest'          :    5499, \n",
        "    'DoS Hulk'                  :  231073, \n",
        "    'DoS GoldenEye'             :   10293, \n",
        "    'Heartbleed'                :      40\n",
        "}\n",
        "\n",
        "over_sampling_strategy45 = { # Minimum 45\n",
        "    \"BENIGN\"                    : 2271320,\n",
        "    \"DDoS\"                      :  128025,\n",
        "    'PortScan'                  :  158804, \n",
        "    'Bot'                       :    1956, \n",
        "    'Infiltration'               :      45,\n",
        "    'Web Attack � Brute Force'  :    1507, \n",
        "    'Web Attack � XSS'          :     652,\n",
        "    'Web Attack � Sql Injection':      45, \n",
        "    'FTP-Patator'               :    7935, \n",
        "    'SSH-Patator'               :    5897, \n",
        "    'DoS slowloris'             :    5796,\n",
        "    'DoS Slowhttptest'          :    5499, \n",
        "    'DoS Hulk'                  :  231073, \n",
        "    'DoS GoldenEye'             :   10293, \n",
        "    'Heartbleed'                :      45\n",
        "}\n",
        "\n",
        "\n",
        "over_sampling_strategy300 = { # Minimum 300\n",
        "    \"BENIGN\"                    : 2271320,\n",
        "    \"DDoS\"                      :  128025,\n",
        "    'PortScan'                  :  158804, \n",
        "    'Bot'                       :    1956, \n",
        "    'Infiltration'               :     300,\n",
        "    'Web Attack � Brute Force'  :    1507, \n",
        "    'Web Attack � XSS'          :     652,\n",
        "    'Web Attack � Sql Injection':     300, \n",
        "    'FTP-Patator'               :    7935, \n",
        "    'SSH-Patator'               :    5897, \n",
        "    'DoS slowloris'             :    5796,\n",
        "    'DoS Slowhttptest'          :    5499, \n",
        "    'DoS Hulk'                  :  231073, \n",
        "    'DoS GoldenEye'             :   10293, \n",
        "    'Heartbleed'                :     300\n",
        "}\n",
        "\n",
        "over_sampling_strategy400 = { # Minimum 400\n",
        "    \"BENIGN\"                    : 2271320,\n",
        "    \"DDoS\"                      :  128025,\n",
        "    'PortScan'                  :  158804, \n",
        "    'Bot'                       :    1956, \n",
        "    'Infiltration'               :     400,\n",
        "    'Web Attack � Brute Force'  :    1507, \n",
        "    'Web Attack � XSS'          :     652,\n",
        "    'Web Attack � Sql Injection':     400, \n",
        "    'FTP-Patator'               :    7935, \n",
        "    'SSH-Patator'               :    5897, \n",
        "    'DoS slowloris'             :    5796,\n",
        "    'DoS Slowhttptest'          :    5499, \n",
        "    'DoS Hulk'                  :  231073, \n",
        "    'DoS GoldenEye'             :   10293, \n",
        "    'Heartbleed'                :     400\n",
        "}\n",
        "\n",
        "\n",
        "over_sampling_strategy500 = { # Minimum 500\n",
        "    \"BENIGN\"                    : 2271320,\n",
        "    \"DDoS\"                      :  128025,\n",
        "    'PortScan'                  :  158804, \n",
        "    'Bot'                       :    1956, \n",
        "    'Infiltration'               :     500,\n",
        "    'Web Attack � Brute Force'  :    1507, \n",
        "    'Web Attack � XSS'          :     652,\n",
        "    'Web Attack � Sql Injection':     500, \n",
        "    'FTP-Patator'               :    7935, \n",
        "    'SSH-Patator'               :    5897, \n",
        "    'DoS slowloris'             :    5796,\n",
        "    'DoS Slowhttptest'          :    5499, \n",
        "    'DoS Hulk'                  :  231073, \n",
        "    'DoS GoldenEye'             :   10293, \n",
        "    'Heartbleed'                :     500\n",
        "}\n",
        "\n",
        "over_sampling_strategy1000 = { # Minimum 1000\n",
        "    \"BENIGN\"                    : 2271320,\n",
        "    \"DDoS\"                      :  128025,\n",
        "    'PortScan'                  :  158804, \n",
        "    'Bot'                       :    1956, \n",
        "    'Infiltration'               :    1000,\n",
        "    'Web Attack � Brute Force'  :    1507, \n",
        "    'Web Attack � XSS'          :    1000,\n",
        "    'Web Attack � Sql Injection':    1000, \n",
        "    'FTP-Patator'               :    7935, \n",
        "    'SSH-Patator'               :    5897, \n",
        "    'DoS slowloris'             :    5796,\n",
        "    'DoS Slowhttptest'          :    5499, \n",
        "    'DoS Hulk'                  :  231073, \n",
        "    'DoS GoldenEye'             :   10293, \n",
        "    'Heartbleed'                :    1000\n",
        "}\n",
        "\n",
        "over = RandomOverSampler(sampling_strategy = over_sampling_strategy300)\n",
        "print(\"Oversampling...\")\n",
        "x_over, y_over = over.fit_resample(x_scaled, Y_attack)\n",
        "x_scaled = x_over\n",
        "Y_attack = y_over\n",
        "\n",
        "print(\"Finished oversampling...\")\n",
        "\n",
        "#define undersampling strategy\n",
        "under = RandomUnderSampler(sampling_strategy = 'not minority')\n",
        "print(\"Undersampling...\")\n",
        "x_under, y_under = under.fit_resample(x_scaled, Y_attack)\n",
        "print(\"Finished undersampling...\")\n",
        "\n",
        "print(x_under)\n",
        "print(y_under)\n",
        "#from now on use undersampled\n",
        "x_scaled = x_under\n",
        "Y_class  = y_under\n",
        "\n",
        "tempdf2 = pd.DataFrame(x_scaled,columns=subset.columns)\n",
        "templabledf = pd.DataFrame(Y_class,columns=[' Label']) \n",
        "\n",
        "\n",
        "df2 = pd.concat([tempdf2, templabledf.reindex(df1.index)], axis=1)\n",
        "print(df2.shape)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df2[' Label'])\n",
        "transformed_label = le.transform(templabledf[' Label']) # multi-class \n",
        "print(transformed_label)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smp3Cxw6vS3H",
        "outputId": "8f153862-0a8a-435c-cde5-9590c7d84c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
            "0                     0.000000                 0.000000   \n",
            "1                     0.000000                 0.009009   \n",
            "2                     0.000000                 0.022911   \n",
            "3                     0.020645                 0.008080   \n",
            "4                     0.000000                 0.000000   \n",
            "...                        ...                      ...   \n",
            "225740                     NaN                      NaN   \n",
            "225741                     NaN                      NaN   \n",
            "225742                     NaN                      NaN   \n",
            "225743                     NaN                      NaN   \n",
            "225744                     NaN                      NaN   \n",
            "\n",
            "         Fwd Packet Length Std  Bwd Packet Length Max   Bwd Packet Length Min  \\\n",
            "0                     0.000000               0.000000                0.000000   \n",
            "1                     0.017725               0.074757                0.000000   \n",
            "2                     0.040614               0.115719                0.000000   \n",
            "3                     0.000000               0.002458                0.016575   \n",
            "4                     0.000000               0.000000                0.000000   \n",
            "...                        ...                    ...                     ...   \n",
            "225740                     NaN                    NaN                     NaN   \n",
            "225741                     NaN                    NaN                     NaN   \n",
            "225742                     NaN                    NaN                     NaN   \n",
            "225743                     NaN                    NaN                     NaN   \n",
            "225744                     NaN                    NaN                     NaN   \n",
            "\n",
            "         Bwd Packet Length Mean   Bwd Packet Length Std  Flow Bytes/s  \\\n",
            "0                      0.000000                0.000000      0.111921   \n",
            "1                      0.181172                0.078494      0.111921   \n",
            "2                      0.121231                0.102224      0.111921   \n",
            "3                      0.008275                0.000000      0.111924   \n",
            "4                      0.000000                0.000000      0.111921   \n",
            "...                         ...                     ...           ...   \n",
            "225740                      NaN                     NaN           NaN   \n",
            "225741                      NaN                     NaN           NaN   \n",
            "225742                      NaN                     NaN           NaN   \n",
            "225743                      NaN                     NaN           NaN   \n",
            "225744                      NaN                     NaN           NaN   \n",
            "\n",
            "         Flow Packets/s   Flow IAT Mean  ...   Subflow Bwd Packets  \\\n",
            "0              0.444444    1.333333e-07  ...              0.000000   \n",
            "1              0.333334    6.738636e-03  ...              0.000120   \n",
            "2              0.333334    7.323683e-03  ...              0.000034   \n",
            "3              0.333354    1.338417e-04  ...              0.000003   \n",
            "4              0.339506    5.583333e-07  ...              0.000003   \n",
            "...                 ...             ...  ...                   ...   \n",
            "225740              NaN             NaN  ...                   NaN   \n",
            "225741              NaN             NaN  ...                   NaN   \n",
            "225742              NaN             NaN  ...                   NaN   \n",
            "225743              NaN             NaN  ...                   NaN   \n",
            "225744              NaN             NaN  ...                   NaN   \n",
            "\n",
            "         Subflow Bwd Bytes  Init_Win_bytes_forward   Init_Win_bytes_backward  \\\n",
            "0             0.000000e+00                0.082993                  0.000000   \n",
            "1             5.611539e-05                0.125015                  0.000504   \n",
            "2             1.072846e-05                0.125015                  0.000198   \n",
            "3             7.323179e-08                0.000000                  0.000000   \n",
            "4             0.000000e+00                0.001755                  0.003799   \n",
            "...                    ...                     ...                       ...   \n",
            "225740                 NaN                     NaN                       NaN   \n",
            "225741                 NaN                     NaN                       NaN   \n",
            "225742                 NaN                     NaN                       NaN   \n",
            "225743                 NaN                     NaN                       NaN   \n",
            "225744                 NaN                     NaN                       NaN   \n",
            "\n",
            "         act_data_pkt_fwd   min_seg_size_forward  Active Mean   Active Std  \\\n",
            "0                0.000000                    1.0     0.000000     0.000000   \n",
            "1                0.000103                    1.0     0.000471     0.000992   \n",
            "2                0.000033                    1.0     0.009422     0.000000   \n",
            "3                0.000000                    1.0     0.000000     0.000000   \n",
            "4                0.000000                    1.0     0.000000     0.000000   \n",
            "...                   ...                    ...          ...          ...   \n",
            "225740                NaN                    NaN          NaN          NaN   \n",
            "225741                NaN                    NaN          NaN          NaN   \n",
            "225742                NaN                    NaN          NaN          NaN   \n",
            "225743                NaN                    NaN          NaN          NaN   \n",
            "225744                NaN                    NaN          NaN          NaN   \n",
            "\n",
            "         Active Max   Label  \n",
            "0          0.000000  BENIGN  \n",
            "1          0.001474  BENIGN  \n",
            "2          0.009422  BENIGN  \n",
            "3          0.000000  BENIGN  \n",
            "4          0.000000  BENIGN  \n",
            "...             ...     ...  \n",
            "225740          NaN     NaN  \n",
            "225741          NaN     NaN  \n",
            "225742          NaN     NaN  \n",
            "225743          NaN     NaN  \n",
            "225744          NaN     NaN  \n",
            "\n",
            "[225745 rows x 59 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df2)\n",
        "df2.to_csv('mount/My Drive/Colab Notebooks/CICIDS2017/resampledforbalance.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gimgzLlC5Ar4"
      },
      "outputs": [],
      "source": [
        "# Split data based on identified classes\n",
        "# df2[' Label'] = df[' Label']\n",
        "benign = df2[df2[' Label'] == outcome[0]]\n",
        "ddos = df2[df2[' Label'] == outcome[1]]\n",
        "portscan = df2[df2[' Label'] == outcome[2]]\n",
        "bot = df2[df2[' Label'] == outcome[3]]\n",
        "infiltration = df2[df2[' Label'] == outcome[4]]\n",
        "webattackbruteforce = df2[df2[' Label'] == outcome[5]]\n",
        "webattackxxs = df2[df2[' Label'] == outcome[6]]\n",
        "webattacksqlinjection = df2[df2[' Label'] == outcome[7]]\n",
        "ftppatator = df2[df2[' Label'] == outcome[8]]\n",
        "sshpatator = df2[df2[' Label'] == outcome[9]]\n",
        "dosslowloris = df2[df2[' Label'] == outcome[10]]\n",
        "dosslowhttptest = df2[df2[' Label'] == outcome[11]]\n",
        "doshulk = df2[df2[' Label'] == outcome[12]]\n",
        "dosgoldeneye = df2[df2[' Label'] == outcome[13]]\n",
        "heartbleed = df2[df2[' Label'] == outcome[14]]\n",
        "\n",
        "traffictypes = [benign, ddos, portscan ,bot, infiltration,\n",
        "webattackbruteforce, webattackxxs, webattacksqlinjection,\n",
        "ftppatator, sshpatator, dosslowloris, dosslowhttptest, doshulk , dosgoldeneye, heartbleed ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rQIbyrAV5Ar6",
        "outputId": "eb6dc081-becb-4b85-91b0-e0d6cf9bf50b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-96ba08e8-43a6-4a89-882b-7ca298fb8fae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>...</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111921</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>1.333333e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.082993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009009</td>\n",
              "      <td>0.017725</td>\n",
              "      <td>0.074757</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181172</td>\n",
              "      <td>0.078494</td>\n",
              "      <td>0.111921</td>\n",
              "      <td>0.333334</td>\n",
              "      <td>6.738636e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>5.611539e-05</td>\n",
              "      <td>0.125015</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022911</td>\n",
              "      <td>0.040614</td>\n",
              "      <td>0.115719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121231</td>\n",
              "      <td>0.102224</td>\n",
              "      <td>0.111921</td>\n",
              "      <td>0.333334</td>\n",
              "      <td>7.323683e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.072846e-05</td>\n",
              "      <td>0.125015</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.009422</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009422</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.008080</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002458</td>\n",
              "      <td>0.016575</td>\n",
              "      <td>0.008275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111924</td>\n",
              "      <td>0.333354</td>\n",
              "      <td>1.338417e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>7.323179e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111921</td>\n",
              "      <td>0.339506</td>\n",
              "      <td>5.583333e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.001755</td>\n",
              "      <td>0.003799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>0.012903</td>\n",
              "      <td>0.005050</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006042</td>\n",
              "      <td>0.040746</td>\n",
              "      <td>0.020343</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111922</td>\n",
              "      <td>0.333342</td>\n",
              "      <td>2.039366e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.600563e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.002072</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111982</td>\n",
              "      <td>0.337255</td>\n",
              "      <td>8.166666e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>9.153974e-09</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.015914</td>\n",
              "      <td>0.006228</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006708</td>\n",
              "      <td>0.045235</td>\n",
              "      <td>0.022584</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111926</td>\n",
              "      <td>0.333355</td>\n",
              "      <td>8.563332e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.997235e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.002072</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.112020</td>\n",
              "      <td>0.339744</td>\n",
              "      <td>5.416666e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>9.153974e-09</td>\n",
              "      <td>0.014450</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0.000860</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.002072</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.112027</td>\n",
              "      <td>0.343590</td>\n",
              "      <td>2.888889e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>1.830795e-08</td>\n",
              "      <td>0.015640</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 59 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96ba08e8-43a6-4a89-882b-7ca298fb8fae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96ba08e8-43a6-4a89-882b-7ca298fb8fae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96ba08e8-43a6-4a89-882b-7ca298fb8fae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
              "0                  0.000000                 0.000000                0.000000   \n",
              "1                  0.000000                 0.009009                0.017725   \n",
              "2                  0.000000                 0.022911                0.040614   \n",
              "3                  0.020645                 0.008080                0.000000   \n",
              "4                  0.000000                 0.000000                0.000000   \n",
              "..                      ...                      ...                     ...   \n",
              "295                0.012903                 0.005050                0.000000   \n",
              "296                0.002581                 0.001010                0.000000   \n",
              "297                0.015914                 0.006228                0.000000   \n",
              "298                0.002581                 0.001010                0.000000   \n",
              "299                0.000860                 0.000337                0.000000   \n",
              "\n",
              "     Bwd Packet Length Max   Bwd Packet Length Min   Bwd Packet Length Mean  \\\n",
              "0                 0.000000                0.000000                 0.000000   \n",
              "1                 0.074757                0.000000                 0.181172   \n",
              "2                 0.115719                0.000000                 0.121231   \n",
              "3                 0.002458                0.016575                 0.008275   \n",
              "4                 0.000000                0.000000                 0.000000   \n",
              "..                     ...                     ...                      ...   \n",
              "295               0.006042                0.040746                 0.020343   \n",
              "296               0.000307                0.002072                 0.001034   \n",
              "297               0.006708                0.045235                 0.022584   \n",
              "298               0.000307                0.002072                 0.001034   \n",
              "299               0.000307                0.002072                 0.001034   \n",
              "\n",
              "      Bwd Packet Length Std  Flow Bytes/s   Flow Packets/s   Flow IAT Mean  \\\n",
              "0                  0.000000      0.111921         0.444444    1.333333e-07   \n",
              "1                  0.078494      0.111921         0.333334    6.738636e-03   \n",
              "2                  0.102224      0.111921         0.333334    7.323683e-03   \n",
              "3                  0.000000      0.111924         0.333354    1.338417e-04   \n",
              "4                  0.000000      0.111921         0.339506    5.583333e-07   \n",
              "..                      ...           ...              ...             ...   \n",
              "295                0.000000      0.111922         0.333342    2.039366e-04   \n",
              "296                0.000000      0.111982         0.337255    8.166666e-07   \n",
              "297                0.000000      0.111926         0.333355    8.563332e-05   \n",
              "298                0.000000      0.112020         0.339744    5.416666e-07   \n",
              "299                0.000000      0.112027         0.343590    2.888889e-07   \n",
              "\n",
              "     ...   Subflow Bwd Packets   Subflow Bwd Bytes  Init_Win_bytes_forward  \\\n",
              "0    ...              0.000000        0.000000e+00                0.082993   \n",
              "1    ...              0.000120        5.611539e-05                0.125015   \n",
              "2    ...              0.000034        1.072846e-05                0.125015   \n",
              "3    ...              0.000003        7.323179e-08                0.000000   \n",
              "4    ...              0.000003        0.000000e+00                0.001755   \n",
              "..   ...                   ...                 ...                     ...   \n",
              "295  ...              0.000007        3.600563e-07                0.000000   \n",
              "296  ...              0.000003        9.153974e-09                0.004379   \n",
              "297  ...              0.000007        3.997235e-07                0.000000   \n",
              "298  ...              0.000003        9.153974e-09                0.014450   \n",
              "299  ...              0.000007        1.830795e-08                0.015640   \n",
              "\n",
              "      Init_Win_bytes_backward   act_data_pkt_fwd   min_seg_size_forward  \\\n",
              "0                    0.000000           0.000000                    1.0   \n",
              "1                    0.000504           0.000103                    1.0   \n",
              "2                    0.000198           0.000033                    1.0   \n",
              "3                    0.000000           0.000000                    1.0   \n",
              "4                    0.003799           0.000000                    1.0   \n",
              "..                        ...                ...                    ...   \n",
              "295                  0.000000           0.000014                    1.0   \n",
              "296                  0.003922           0.000000                    1.0   \n",
              "297                  0.000000           0.000005                    1.0   \n",
              "298                  0.000015           0.000000                    1.0   \n",
              "299                  0.000015           0.000005                    1.0   \n",
              "\n",
              "     Active Mean   Active Std   Active Max   Label  \n",
              "0       0.000000     0.000000     0.000000  BENIGN  \n",
              "1       0.000471     0.000992     0.001474  BENIGN  \n",
              "2       0.009422     0.000000     0.009422  BENIGN  \n",
              "3       0.000000     0.000000     0.000000  BENIGN  \n",
              "4       0.000000     0.000000     0.000000  BENIGN  \n",
              "..           ...          ...          ...     ...  \n",
              "295     0.000000     0.000000     0.000000  BENIGN  \n",
              "296     0.000000     0.000000     0.000000  BENIGN  \n",
              "297     0.000000     0.000000     0.000000  BENIGN  \n",
              "298     0.000000     0.000000     0.000000  BENIGN  \n",
              "299     0.000000     0.000000     0.000000  BENIGN  \n",
              "\n",
              "[300 rows x 59 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "benign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Qt3hVO5Ar8"
      },
      "source": [
        "### Visualise the output\n",
        "\n",
        "We now have our data split into the classes, so we can use the violin plot for each of our classes independently, and compare the two figures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XI9Rr3r45Ar9"
      },
      "outputs": [],
      "source": [
        "def violinplot(traffictype, trafficstring):\n",
        "\n",
        "  plot_violin = False\n",
        "  \n",
        "  if(plot_violin):\n",
        "    # traffictype=benign\n",
        "    # trafficstring=\"benign\"\n",
        "    plt.figure(figsize=(30,5),dpi=300)\n",
        "    ax = sns.violinplot(data=traffictype)\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "    title = \"Violin Plot to show \" + str(trafficstring) + \" feature distributions\"\n",
        "    ax.set_title(title)\n",
        "    plt.savefig(('mount/My Drive/Colab Notebooks/Figures/' + trafficstring + '.png'))\n",
        "  else:\n",
        "    print(\"plot_violin = False - Skipping Plot\")\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "def plot_cluster(cm):\n",
        "  print(cm)\n",
        "  from scipy.cluster import hierarchy\n",
        "  l_col_list = list(outcome)\n",
        "  import string\n",
        "  for i in range(0,len(l_col_list)):\n",
        "    pretty_string = ''.join(filter(lambda x: x in string.printable, l_col_list[i]))\n",
        "    l_col_list[i] = pretty_string\n",
        "\n",
        "  metrics = [ 'euclidean', 'minkowski', 'cityblock', 'cosine', 'sqeuclidean', \n",
        "             'correlation', 'hamming', 'jaccard']\n",
        "\n",
        "  \n",
        "\n",
        "  for metric in metrics:\n",
        "    # fig = plt.plot(figsize=(8, 3))\n",
        "    Y = hierarchy.distance.pdist(cm, metric=metric)\n",
        "    Z  = hierarchy.linkage(Y, method='single')\n",
        "    print(Z)\n",
        "    title = f\"Dendogram: Hierarchy from agglometrative clustering\\nusing {metric} distance metric\"  \n",
        "  \n",
        "    plt.figure()\n",
        "    ax = hierarchy.dendrogram(Z, show_contracted=True, labels=l_col_list, leaf_rotation=0, \n",
        "                              leaf_font_size=18, orientation='left')\n",
        "    plt.title(title, fontsize=20)\n",
        "    \n",
        "    plt.savefig(('mount/My Drive/Colab Notebooks/Figures/' + 'dendogram-agg-cluster-' + metric + '.png'),dpi=300,bbox_inches='tight')\n",
        "    \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V11tDM81RxPn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def plot_cm(cm,title,savename):\n",
        "\n",
        "  print(cm)\n",
        "  plt.figure(figsize=(20,20),dpi=300)\n",
        "  plt.matshow(cm, cmap=\"OrRd\" )\n",
        "  plt.title(title, pad=150)\n",
        "  plt.colorbar()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  ax = plt.gca()\n",
        "  from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "  l_col_list = list(outcome)\n",
        "  import string\n",
        "  for i in range(0,len(l_col_list)):\n",
        "    pretty_string = ''.join(filter(lambda x: x in string.printable, l_col_list[i]))\n",
        "    l_col_list[i] = pretty_string\n",
        "\n",
        "  ax.set_xticklabels([''] + l_col_list, rotation=90)\n",
        "  ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "  # savename='ConfusionMatrix-Multiclass-Original.png'\n",
        "  basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "  filename=basedir+savename\n",
        "  plt.savefig(filename,dpi=300,bbox_inches='tight')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HDjQcr60TAUh"
      },
      "outputs": [],
      "source": [
        "def plot_cm_theta(cm,title,savename): # for JSMA theta and gamma values\n",
        "\n",
        "  print(cm)\n",
        "  plt.figure(figsize=(20,20),dpi=300)\n",
        "  plt.matshow(cm, cmap=\"OrRd\" )\n",
        "  title = title + ' (Theta=' +str(theta) + ' Gamma=' +str(gamma)+')'\n",
        "  plt.title(title, pad=150)\n",
        "  plt.colorbar()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  ax = plt.gca()\n",
        "  from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "  l_col_list = list(outcome)\n",
        "  import string\n",
        "  for i in range(0,len(l_col_list)):\n",
        "    pretty_string = ''.join(filter(lambda x: x in string.printable, l_col_list[i]))\n",
        "    l_col_list[i] = pretty_string\n",
        "\n",
        "  ax.set_xticklabels([''] + l_col_list, rotation=90)\n",
        "  ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "  # savename='ConfusionMatrix-Multiclass-Original.png'\n",
        "  basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "  filename=basedir+savename\n",
        "  plt.savefig(filename,dpi=300,bbox_inches='tight')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tH1aJ5gH_Lf-"
      },
      "outputs": [],
      "source": [
        "def plot_cm_thetahier(cm,title,labels,savename): # for JSMA theta and gamma values\n",
        "\n",
        "  print(cm)\n",
        "  plt.figure(figsize=(20,20),dpi=300)\n",
        "  plt.matshow(cm, cmap=\"OrRd\" )\n",
        "  title = title + ' (Theta=' +str(theta) + ' Gamma=' +str(gamma)+')'\n",
        "  plt.title(title, pad=150)\n",
        "  plt.colorbar()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  ax = plt.gca()\n",
        "  from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "  l_col_list = list(labels)\n",
        "  import string\n",
        "  for i in range(0,len(l_col_list)):\n",
        "    pretty_string = ''.join(filter(lambda x: x in string.printable, l_col_list[i]))\n",
        "    l_col_list[i] = pretty_string\n",
        "\n",
        "  ax.set_xticklabels([''] + l_col_list, rotation=90)\n",
        "  ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "  # savename='ConfusionMatrix-Multiclass-Original.png'\n",
        "  basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "  filename=basedir+savename\n",
        "  plt.savefig(filename,dpi=300,bbox_inches='tight')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oLoFE5YHYh6k"
      },
      "outputs": [],
      "source": [
        "def plot_errors(cm,title,savename):\n",
        "\n",
        "  #Plot of errors\n",
        "  row_sums = cm.sum(axis=1, keepdims=True)\n",
        "  norm_cm = cm / row_sums\n",
        "\n",
        "  np.fill_diagonal(norm_cm, 0)\n",
        "  plt.figure(figsize=(20,20),dpi=300)\n",
        "  plt.matshow(norm_cm, cmap=\"OrRd\")\n",
        "  plt.title(title, pad=150)\n",
        "\n",
        "  plt.colorbar()\n",
        "  ax = plt.gca()\n",
        "  from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "  l_col_list = list(outcome)\n",
        "  import string\n",
        "  for i in range(0,len(l_col_list)):\n",
        "    pretty_string = ''.join(filter(lambda x: x in string.printable, l_col_list[i]))\n",
        "    l_col_list[i] = pretty_string\n",
        "\n",
        "  ax.set_xticklabels([''] + l_col_list,rotation=90)\n",
        "  ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "  # savename='ErrorMatrix-Multiclass-Original.png'\n",
        "  basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "  filename=basedir+savename\n",
        "  plt.savefig(filename,dpi=300,bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gQlTy4xYi1tq"
      },
      "outputs": [],
      "source": [
        "def print_classification_report(predicted_labels, orig_labels, texfilename, caption):\n",
        "\n",
        "  print(predicted_labels)\n",
        "  print(orig_labels)\n",
        "\n",
        "\n",
        "  from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "  l_col_list = list(outcome)\n",
        "  import string\n",
        "  for i in range(0,len(l_col_list)):\n",
        "    pretty_string = ''.join(filter(lambda x: x in string.printable, l_col_list[i]))\n",
        "    l_col_list[i] = pretty_string\n",
        "\n",
        "  print(classification_report(\n",
        "        predicted_labels,orig_labels,\n",
        "        target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome)))))\n",
        "\n",
        "  DICT_CLASS_REPORT = classification_report(\n",
        "        predicted_labels,orig_labels,\n",
        "        target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome))),output_dict=True\n",
        "    )\n",
        "\n",
        "  print(DICT_CLASS_REPORT)\n",
        "  macro_f1 = DICT_CLASS_REPORT['macro avg']['f1-score']\n",
        "  print(macro_f1)\n",
        "\n",
        "  class_report_df = pd.DataFrame(DICT_CLASS_REPORT)\n",
        "  class_report_df = class_report_df.round(decimals=2)\n",
        "  class_report_df = class_report_df.transpose()\n",
        "  basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "  filename= basedir + texfilename\n",
        "  print(class_report_df.to_latex(caption=caption))\n",
        "  with open(filename, 'w') as f:\n",
        "    f.write(class_report_df.to_latex(caption=caption))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z_Fldz8L4Zp8",
        "outputId": "0efbf201-bcea-486f-c18f-c8da22849e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(benign, \"benign\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ViUVNCNlMr0n",
        "outputId": "ab39dfa7-e68b-4805-ca83-b231d39e0832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(ddos, \"DDoS\")\n",
        "\n",
        "# traffictype=ddos\n",
        "# trafficstring=\"DDoS\"\n",
        "# plt.figure(figsize=(30,13))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(trafficstring) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_zyorRhyMtA-",
        "outputId": "123844dc-4b7e-4a04-8dee-962505c18b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(portscan, \"PortScan\")\n",
        "# traffictype=portscan\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zHM93m9gMthc",
        "outputId": "ae192a48-b788-42af-a536-e44444f3a1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(bot, \"Botnet\")\n",
        "# traffictype=bot\n",
        "# trafficstring=\"botnet\"\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(trafficstring) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YFu0o-XmMt8r",
        "outputId": "b12bd702-784a-4652-b36b-05a751024128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(infiltration, \"infiltration\")\n",
        "# traffictype=infiltration\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9w7KlzfPMuWS",
        "outputId": "74bdbd46-c20e-4368-e77e-75ab5e68286f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(webattackbruteforce, \"web attack brute force\")\n",
        "# traffictype=webattackbruteforce\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JyNy8s5NMuwH",
        "outputId": "0b949741-8222-46ae-befc-04105458809e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(webattackxxs,\"web attack XXS\")\n",
        "# traffictype=webattackxxs\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M00CwrYsMvIE",
        "outputId": "af28d56c-5b02-4ebc-a696-4241d7960fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(webattacksqlinjection,\"web attack SQL injection\")\n",
        "# traffictype=webattacksqlinjection\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yuhhin-S5Ar_",
        "outputId": "e4b7ca25-9126-4f55-8878-295113aeff49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(ftppatator,\"FTP Patator\")\n",
        "# traffictype= ftppatator\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QDLwFRsLPbaR",
        "outputId": "6bd69a50-2d2e-46d7-a848-e665715e430f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(sshpatator,\"SSH Patator\")\n",
        "# traffictype= sshpatator\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8dPi4Qy4Q7WK",
        "outputId": "5bb712aa-5485-4b62-8657-712b181bb28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(dosslowloris,\"DoS slowloris\")\n",
        "# traffictype= dosslowloris\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eylOSuI_kNW9",
        "outputId": "06eea852-1345-4592-c147-16551e64e4c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(dosslowhttptest,\"DoS slow http test\")\n",
        "# traffictype= dosslowhttptest\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k5WxwX9MkTnm",
        "outputId": "a43a4294-4478-4c74-bfc7-3a6f9c251f74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(doshulk,\"DoS Hulk\")\n",
        "# traffictype= doshulk\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FQfsFWYLkZfJ",
        "outputId": "3e034c57-29a5-4197-8a20-bda30b024606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(dosgoldeneye,\"DoS GoldenEye\")\n",
        "# traffictype= dosgoldeneye\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0_GnxKbJkdEQ",
        "outputId": "95be0516-4e05-4553-ee0e-d4f6706db25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot_violin = False - Skipping Plot\n"
          ]
        }
      ],
      "source": [
        "violinplot(heartbleed,\"Heartbleed\")\n",
        "# traffictype= heartbleed\n",
        "# plt.figure(figsize=(30,5))\n",
        "# ax = sns.violinplot(data=traffictype)\n",
        "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "# title = \"Violin Plot to show \" + str(traffictype) + \"feature distributions\"\n",
        "# ax.set_title(title)\n",
        "# plt.savefig(traffictype + \".png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ywfEMR5AsB"
      },
      "source": [
        "### Findings\n",
        "\n",
        "Comparing the two charts, we can see that the following features are different across the two classes.\n",
        "\n",
        "* Flow Duration\n",
        "* Flow IAT (Mean, Std, Max, Min)\n",
        "* Fwd IAT (Total, Mean, Std, Max, Min)\n",
        "* Packet Length Variance\n",
        "* Idle (Mean, Std, Max, Min)\n",
        "\n",
        "We now have a clearer view (as far as this dataset is concerned) with what makes for a benign packet, and what makes for a malicious DDoS packet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6duBa_Dkvh-D"
      },
      "source": [
        "#Adversarial examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "StvVjsRq4glR",
        "outputId": "f03a80e8-34b0-4e75-d8ce-9f0234b8f3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numpy:1.21.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: adversarial-robustness-toolbox==1.08 in /usr/local/lib/python3.7/site-packages (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/site-packages (from adversarial-robustness-toolbox==1.08) (1.21.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from adversarial-robustness-toolbox==1.08) (49.6.0.post20210108)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from adversarial-robustness-toolbox==1.08) (4.59.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from adversarial-robustness-toolbox==1.08) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/site-packages (from adversarial-robustness-toolbox==1.08) (0.24.2)\n",
            "Requirement already satisfied: numba~=0.53.1 in /usr/local/lib/python3.7/site-packages (from adversarial-robustness-toolbox==1.08) (0.53.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/site-packages (from adversarial-robustness-toolbox==1.08) (1.7.0)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.7/site-packages (from numba~=0.53.1->adversarial-robustness-toolbox==1.08) (0.36.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox==1.08) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox==1.08) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "print(\"Numpy:\" + np.__version__)\n",
        "\n",
        "!pip install adversarial-robustness-toolbox==1.08\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.attacks.evasion import SaliencyMapMethod\n",
        "from art.estimators.classification import KerasClassifier\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.estimators.classification import EnsembleClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tMDvVWCD6AzV",
        "outputId": "12947764-f92e-41c8-c7ca-0a3852394adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3150, 58)\n",
            "(1350, 58)\n",
            "There are 15 distinct classes\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df2[' Label'])\n",
        "Y_class = transformed_label # multi-class \n",
        "\n",
        "#Train test split\n",
        "\n",
        "testSize = 0.3\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, Y_class, test_size = testSize, shuffle=True, random_state = 42)\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "print(\"There are \"+ str(num_classes) +\" distinct classes\")\n",
        "print(np.unique(y_train))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVMK5vRWQ0iy"
      },
      "source": [
        "# Train the model\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG8k9g2r7tx_"
      },
      "outputs": [],
      "source": [
        "CLASS_TO_TRAIN =\"multiclass\"\n",
        "epochs=1600\n",
        "    \n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=[x_train.shape[1]]),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(len(np.unique(Y_class))),\n",
        "        tf.keras.layers.Activation(tf.nn.softmax)\n",
        "])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "print(\"There are \" +str(len(x_train)) +\" lines in x_train\")\n",
        "  \n",
        "basedir = \"/mount/Notebooks/Classifier/ModelH5s/\"\n",
        "best_model_filename = basedir + CLASS_TO_TRAIN + \"-instance_best_model\" + \".h5\"\n",
        "    \n",
        "callbacks = [\n",
        "  keras.callbacks.ModelCheckpoint(\n",
        "    best_model_filename, save_best_only=True, monitor=\"val_loss\"\n",
        "  ),\n",
        "  keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "  ),\n",
        "  keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]\n",
        " \n",
        "model.compile(optimizer='adam',\n",
        "            #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "            loss= 'sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "        x_train, y_train, epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        shuffle=False,\n",
        "        validation_data=(x_test, y_test),\n",
        "        verbose=1\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S_W6wG36qpB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnhaRvPt91zo"
      },
      "outputs": [],
      "source": [
        "from sys import exit\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test,y_test)\n",
        "print(f'Test loss:', {loss}) \n",
        "print(f'Test accuracy:', {accuracy*100})\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "print(predictions)\n",
        "# rounded_predictions = predictions.round().astype(int)\n",
        "\n",
        "# We don't need to round and get better results if we keep the decimal places\n",
        "rounded_predictions = predictions * 100 \n",
        "\n",
        "# rounded_predictions = predictions.round().astype(int)\n",
        "print(rounded_predictions)\n",
        "integer_predictions = []\n",
        "\n",
        "print(\"-------\")\n",
        "for i in range(len(rounded_predictions)):\n",
        "\n",
        "  arr = [rounded_predictions[i][0], rounded_predictions[i][1], rounded_predictions[i][2], \n",
        "        rounded_predictions[i][3], rounded_predictions[i][4], rounded_predictions[i][5], \n",
        "        rounded_predictions[i][6], rounded_predictions[i][7], rounded_predictions[i][8],\n",
        "        rounded_predictions[i][9], rounded_predictions[i][10], rounded_predictions[i][11],\n",
        "        rounded_predictions[i][12], rounded_predictions[i][13], rounded_predictions[i][14],\n",
        "        ]\n",
        "\n",
        "  # print(arr)\n",
        "  HighestProbabilityClass = arr.index(max(arr))\n",
        "  # print(HighestProbabilityClass)\n",
        "  integer_predictions.append(HighestProbabilityClass)\n",
        "\n",
        "print(integer_predictions)\n",
        "\n",
        "print_classification_report(integer_predictions,y_test, \"KerasOriginal.tex\",\"Surrogate Model Classification Report\")\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import itertools\n",
        "\n",
        "\n",
        "# def plot_classification_report(classificationReport,\n",
        "#                                title='Classification report',\n",
        "#                                cmap='RdBu'):\n",
        "\n",
        "#     classificationReport = classificationReport.replace('\\n\\n', '\\n')\n",
        "#     classificationReport = classificationReport.replace(' / ', '/')\n",
        "#     lines = classificationReport.split('\\n')\n",
        "\n",
        "#     classes, plotMat, support, class_names = [], [], [], []\n",
        "#     for line in lines[1:]:  # if you don't want avg/total result, then change [1:] into [1:-1]\n",
        "#         t = line.strip().split()\n",
        "#         if len(t) < 2:\n",
        "#             continue\n",
        "#         classes.append(t[0])\n",
        "#         v = [float(x) for x in t[1: len(t) - 1]]\n",
        "#         support.append(int(t[-1]))\n",
        "#         class_names.append(t[0])\n",
        "#         plotMat.append(v)\n",
        "\n",
        "#     plotMat = np.array(plotMat)\n",
        "#     xticklabels = ['Precision', 'Recall', 'F1-score']\n",
        "#     yticklabels = ['{0} ({1})'.format(class_names[idx], sup)\n",
        "#                    for idx, sup in enumerate(support)]\n",
        "\n",
        "#     plt.imshow(plotMat, interpolation='nearest', cmap=cmap, aspect='auto')\n",
        "#     plt.title(title)\n",
        "#     plt.colorbar()\n",
        "#     plt.xticks(np.arange(3), xticklabels, rotation=45)\n",
        "#     plt.yticks(np.arange(len(classes)), yticklabels)\n",
        "\n",
        "#     upper_thresh = plotMat.min() + (plotMat.max() - plotMat.min()) / 10 * 8\n",
        "#     lower_thresh = plotMat.min() + (plotMat.max() - plotMat.min()) / 10 * 2\n",
        "#     for i, j in itertools.product(range(plotMat.shape[0]), range(plotMat.shape[1])):\n",
        "#         plt.text(j, i, format(plotMat[i, j], '.2f'),\n",
        "#                  horizontalalignment=\"center\",\n",
        "#                  color=\"white\" if (plotMat[i, j] > upper_thresh or plotMat[i, j] < lower_thresh) else \"black\")\n",
        "\n",
        "#     plt.ylabel('Metrics')\n",
        "#     plt.xlabel('Classes')\n",
        "#     plt.tight_layout()\n",
        "\n",
        "\n",
        "# plot_classification_report(sample)\n",
        "\n",
        "cm = confusion_matrix(y_test,integer_predictions)\n",
        "plot_cm(cm,'Keras Model - Original - Confusion Matrix','ConfusionMatrix-Keras-Original.png')\n",
        "\n",
        "plot_cluster(cm)\n",
        "\n",
        "#cm = confusion_matrix(y_test,integer_predictions)\n",
        "\n",
        "# print(cm)\n",
        "# plt.matshow(cm, cmap=\"OrRd\" )\n",
        "# plt.title('Multiclass - Original - Confusion Matrix', pad=150)\n",
        "# plt.colorbar()\n",
        "# plt.ylabel('True label')\n",
        "# plt.xlabel('Predicted label')\n",
        "# ax = plt.gca()\n",
        "# from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "# l_col_list = list(outcome)\n",
        "# ax.set_xticklabels([''] + l_col_list, rotation=90)\n",
        "# ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "# savename='ConfusionMatrix-Multiclass-Original.png'\n",
        "# basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "# filename=basedir+savename\n",
        "# plt.savefig(filename,dpi=300)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZzZd6ARUFnx"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "skMLP = MLPClassifier(hidden_layer_sizes=(128,64,15),activation ='relu',solver='adam', max_iter=300, shuffle=False,random_state=1, verbose=False) # Converges around 1600 iters / Achieves similar accuracy to keras at 300 iters\n",
        "\n",
        "\n",
        "history = skMLP.fit(\n",
        "        x_train, y_train\n",
        ")        \n",
        "\n",
        "result = skMLP.score(x_test, y_test)\n",
        "print(result)\n",
        "print(\"Accuracy: %.2f%%\" % (result*100.0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYF6yQi7PkfW"
      },
      "outputs": [],
      "source": [
        "DO_LIME = 0\n",
        "\n",
        "if(DO_LIME):\n",
        "  import lime\n",
        "  from lime import lime_tabular\n",
        "\n",
        "  explainer = lime_tabular.LimeTabularExplainer(\n",
        "      training_data=np.array(x_train),\n",
        "      feature_names=subset.columns,\n",
        "      class_names=outcome,\n",
        "      mode='classification'\n",
        "  )\n",
        "\n",
        "  exp = explainer.explain_instance(\n",
        "      data_row=x_test[1], \n",
        "      predict_fn=skMLP.predict_proba\n",
        "  )\n",
        "\n",
        "  exp.show_in_notebook(show_table=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xx2i3Hsp05I"
      },
      "outputs": [],
      "source": [
        "predictions = skMLP.predict_proba(x_test)\n",
        "print(predictions)\n",
        "rounded_predictions = predictions.round().astype(int)\n",
        "rounded_prediction = predictions * 100\n",
        "print(rounded_predictions)\n",
        "integer_predictions = []\n",
        "\n",
        "print(\"-------\")\n",
        "for i in range(len(rounded_predictions)):\n",
        "\n",
        "  arr = [rounded_predictions[i][0], rounded_predictions[i][1], rounded_predictions[i][2], \n",
        "        rounded_predictions[i][3], rounded_predictions[i][4], rounded_predictions[i][5], \n",
        "        rounded_predictions[i][6], rounded_predictions[i][7], rounded_predictions[i][8],\n",
        "        rounded_predictions[i][9], rounded_predictions[i][10], rounded_predictions[i][11],\n",
        "        rounded_predictions[i][12], rounded_predictions[i][13], rounded_predictions[i][14],\n",
        "        ]\n",
        "\n",
        "  # print(arr)\n",
        "  HighestProbabilityClass = arr.index(max(arr))\n",
        "  # print(HighestProbabilityClass)\n",
        "  integer_predictions.append(HighestProbabilityClass)\n",
        "\n",
        "print(integer_predictions)\n",
        "# print(len(integer_predictions))\n",
        "\n",
        "\n",
        "# results = model.evaluate(x_test, y_test)\n",
        "\n",
        "# # print(y_test)\n",
        "# print(len(y_test))\n",
        "\n",
        "# print(\"----- NORMAL test loss, test acc:\", results)\n",
        "# print(predictions)\n",
        "# OneHotEncoded_y_test = to_categorical(y_test)\n",
        "# print(OneHotEncoded_y_test)\n",
        "# print(len(OneHotEncoded_y_test))\n",
        "# rounded_predictions = predictions.round().astype(int)\n",
        "# integer_predictions = []\n",
        "# for i in range(len(rounded_predictions)):\n",
        "#   print(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DctAllPE0hZD"
      },
      "outputs": [],
      "source": [
        "targets = []\n",
        "classes = transformed_label\n",
        "#.unique gives the order of appearance and therefore does not sort.\n",
        "print(classes)\n",
        "new_order_classes = np.unique(Y_class)\n",
        "print(new_order_classes)\n",
        "\n",
        "\n",
        "print(classification_report(\n",
        "    integer_predictions,\n",
        "    y_test,\n",
        "    target_names=outcome,\n",
        "    labels=range(0,(len(outcome))))\n",
        ")\n",
        "print(y_test)\n",
        "\n",
        "count_arr = np.bincount(y_test)\n",
        "for i in range(0,len(outcome)):\n",
        "  print(i, count_arr[i])\n",
        "\n",
        "\n",
        "print_classification_report(integer_predictions,y_test, \"SK-MLPOriginal.tex\",\"Multiclass Original Classification Report\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-bWttVv9IBi"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test,integer_predictions)\n",
        "plot_cm(cm,'Sklearn MLP - Original - Confusion Matrix','ConfusionMatrix-SkLearn-Original.png')\n",
        "\n",
        "plot_cluster(cm)\n",
        "\n",
        "#cm = confusion_matrix(y_test,integer_predictions)\n",
        "\n",
        "# print(cm)\n",
        "# plt.matshow(cm, cmap=\"OrRd\" )\n",
        "# plt.title('Multiclass - Original - Confusion Matrix', pad=150)\n",
        "# plt.colorbar()\n",
        "# plt.ylabel('True label')\n",
        "# plt.xlabel('Predicted label')\n",
        "# ax = plt.gca()\n",
        "# from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "# l_col_list = list(outcome)\n",
        "# ax.set_xticklabels([''] + l_col_list, rotation=90)\n",
        "# ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "# savename='ConfusionMatrix-Multiclass-Original.png'\n",
        "# basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "# filename=basedir+savename\n",
        "# plt.savefig(filename,dpi=300)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoVbB0J9ANMx"
      },
      "outputs": [],
      "source": [
        "plot_errors(cm,'Multiclass - Original - Error Matrix','ErrorMatrix-Multiclass-Original.png')\n",
        "# #Plot of errors\n",
        "# row_sums = cm.sum(axis=1, keepdims=True)\n",
        "# norm_cm = cm / row_sums\n",
        "\n",
        "# np.fill_diagonal(norm_cm, 0)\n",
        "# plt.matshow(norm_cm, cmap=\"OrRd\")\n",
        "# plt.title('Multiclass - Original - Error Matrix', pad=150)\n",
        "\n",
        "# plt.colorbar()\n",
        "# ax = plt.gca()\n",
        "# from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "# l_col_list = list(outcome)\n",
        "# ax.set_xticklabels([''] + l_col_list,rotation=90)\n",
        "# ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "# savename='ErrorMatrix-Multiclass-Original.png'\n",
        "# basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "# filename=basedir+savename\n",
        "# plt.savefig(filename,dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vulbNthaFoFH"
      },
      "outputs": [],
      "source": [
        "# Create the ART Classifier\n",
        "art_classifier = KerasClassifier(model=model, use_logits=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSzYAw69F6ts"
      },
      "outputs": [],
      "source": [
        "# 0 - 14 labels =       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "OHE_benign =            [1, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0]\n",
        "\n",
        "targets=[]\n",
        "\n",
        "for i in range(0,len(x_test)):\n",
        "  targets.append(OHE_benign)\n",
        "numpy_targets = np.array(targets)\n",
        "\n",
        "#Generate FGSM Adversarial Examples\n",
        "\n",
        "# attack = FastGradientMethod(estimator=art_classifier, eps=0.5)\n",
        "# print(\"Generating FGSM\")\n",
        "\n",
        "# x_test_fgsm = attack.generate(x=x_test)\n",
        "# print(x_test_fgsm)\n",
        "\n",
        "# Theta = perturbation to each feature\n",
        "# Gamma = float max fraction of features being perturbed\n",
        "for theta in ([0.05]): # 0.05\n",
        "  for gamma in ([0.02]): # 0.02\n",
        "\n",
        "    # attack = SaliencyMapMethod(classifier=art_classifier, theta=0.1, gamma=0.1, batch_size=1,verbose=True) # Theta = Small Perturbation , Gamma = 10% of features\n",
        "\n",
        "    attack = SaliencyMapMethod(classifier=art_classifier, theta=theta, gamma=gamma, batch_size=1,verbose=True) # Theta = Small Perturbation , Gamma = 10% of features\n",
        "    print(\"Starting to Generate untargeted JSMA\")\n",
        "    #x_test_adv = attack.generate(x=x_test, y=oh_target_labels)\n",
        "    x_test_jsma = attack.generate(x=x_test)\n",
        "    # print(x_test_jsma)\n",
        "\n",
        "    print(\"Starting to Generate Targeted JSMA\")\n",
        "\n",
        "    targeted_benign_x_test_jsma = attack.generate(x=x_test,y=numpy_targets)\n",
        "\n",
        "    #Keep benign cases\n",
        "\n",
        "    for i in range(0,len(x_test)):\n",
        "      if(y_test[i] == 0):\n",
        "        # x_test_fgsm[i] = x_test[i]\n",
        "        x_test_jsma[i] = x_test[i]\n",
        "        targeted_benign_x_test_jsma[i] = x_test[i]\n",
        "\n",
        "\n",
        "    # Save x_test_jsma \n",
        "\n",
        "    savename='x_test_jsma-' + 'theta-' + str(theta) + 'gamma-'+ str(gamma) +'.npy'\n",
        "    basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "    filename=basedir+savename\n",
        "    print(f\"Writing file {filename}\")\n",
        "    np.save(filename, x_test_jsma)\n",
        "\n",
        "    savename='targeted_benign_jsma-'+ 'theta-' + str(theta) + 'gamma-'+ str(gamma) +'.npy'\n",
        "    basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "    filename=basedir+savename\n",
        "    print(f\"Writing file {filename}\")\n",
        "    np.save(filename, targeted_benign_x_test_jsma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHVM7MB3U5A-"
      },
      "outputs": [],
      "source": [
        "# for column in x_test.T:\n",
        "#    print(column)\n",
        "\n",
        "# a : numpy array from which it needs to find the maximum value.\n",
        "# ...\n",
        "# numpy. amax()\n",
        "# If it's provided then it will return for array of max values along the axis i.e.\n",
        "# If axis=0 then it returns an array containing max value for each columns.\n",
        "# If axis=1 then it returns an array containing max value for each row.\n",
        "\n",
        "x_test_feature_min_values = np.amin(x_test,axis=0)\n",
        "x_test_feature_max_values = np.amax(x_test,axis=0)\n",
        "\n",
        "x_test_jsma_feature_min_values = np.amin(x_test_jsma,axis=0)\n",
        "x_test_jsma_feature_max_values = np.amax(x_test_jsma,axis=0)\n",
        "\n",
        "benign_feature_min_values = np.amin(benign,axis=0)\n",
        "benign_feature_max_values = np.amax(benign,axis=0)\n",
        "\n",
        "# for i in range(0,len(x_test_feature_min_values)):\n",
        "#   plt.plot(i,x_test_feature_min_values[i])\n",
        "# plt.show\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# plt.style.use('_mpl-gallery')\n",
        "\n",
        "# make data\n",
        "\n",
        "\n",
        "numOfColumns = len(x_test_feature_min_values)\n",
        "print(numOfColumns)\n",
        "x = range(0,numOfColumns)\n",
        "# x = range(0,len(x_test_feature_min_values))\n",
        "y1 = x_test_feature_min_values\n",
        "y2 = x_test_feature_max_values\n",
        "\n",
        "y3 = x_test_jsma_feature_min_values\n",
        "y4 = x_test_jsma_feature_max_values\n",
        "\n",
        "y5 = benign_feature_min_values\n",
        "y6 = benign_feature_max_values\n",
        "# plot\n",
        "# fig, ax = plt.subplots()\n",
        "\n",
        "plt.figure(figsize=(20,5), dpi=300)\n",
        "\n",
        "\n",
        "# p1 = plt.fill_between(x, y3, y4, facecolor ='lime',alpha=.5, hatch='.', label='JSMA Range', linewidth=0)\n",
        "p1 = plt.plot(x, y3, alpha=0.5,linewidth=2, linestyle=\"dotted\", label='JSMA Min', color='green')\n",
        "p2 = plt.plot(x, (y3 + y4)/2, alpha=0.5,linewidth=2,linestyle=\"dashed\", label='JSMA Median', color='green')\n",
        "p3 = plt.plot(x, y4, alpha=0.5,linewidth=2, linestyle=\"dotted\", label='JSMA Max', color='green')\n",
        "\n",
        "# p3 = plt.fill_between(x, y1, y2,  facecolor='red', alpha=.5, hatch='/', label='Ordinary Range', linewidth=0)\n",
        "\n",
        "p4 = plt.plot(x, y1,  alpha=0.5,linewidth=2, label='Ordinary Min', color='blue')\n",
        "p5 = plt.plot(x, (y1 + y2)/2,  alpha=0.5,linewidth=2,linestyle=\"dashed\", label='Ordinary Median', color='blue')\n",
        "p6 = plt.plot(x, y2,  alpha=0.5,linewidth=2, label='Ordinary Max', color='blue')\n",
        "\n",
        "# p3 = plt.fill_between(x, y1, y2,  facecolor='red', alpha=.5, hatch='/', label='Ordinary Range', linewidth=0)\n",
        "# p4 = plt.plot(x, (y5 + y6)/2,  alpha=0.5,linewidth=2, label='BENIGN Mean', color='red')\n",
        "\n",
        "\n",
        "# ax.plot(t, mu1, lw=2, label='mean population 1', color='blue')\n",
        "# ax.plot(t, mu2, lw=2, label='mean population 2', color='yellow')\n",
        "\n",
        "# ax.set(xlim=(0, 58), xticks=np.arange(0, 58),\n",
        "#        ylim=(0, 2), yticks=np.arange(0, 2))\n",
        "\n",
        "# plt.xticks(ticks = tickvalues ,labels = labellist, rotation = 'vertical')\n",
        "\n",
        "plt.xticks(range(0,len(y1)), labels=subset.columns, rotation=90, fontsize=15)\n",
        "plt.ylim((-0.5, 2.5))\n",
        "      #  ylim=(0, 2), yticks=np.arange(0, 2))\n",
        "\n",
        "title = 'Distributions of Normal and JSMA Features (Theta=' +str(theta) + ' Gamma=' +str(gamma) +')'\n",
        "plt.title(title,fontsize=20)\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('Feature',fontsize=15)\n",
        "plt.ylabel('Scaled Value',fontsize=15)\n",
        "\n",
        "\n",
        "savename='Min-Max_Plot-'+'theta-'+str(theta)+'gamma'+str(gamma)+'.png'\n",
        "# savename='AllMeans.png'\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/MinMaxPlots/'\n",
        "filename=basedir+savename\n",
        "# plt.savefig(filename,dpi=300,bbox_inches='tight')\n",
        "\n",
        "plt.show()\n",
        "# fig, ax = plt.subplots()\n",
        "\n",
        "# # ax.fill_between(x, y1, y2,  facecolor='blue', alpha=.5, linewidth=0)\n",
        "# # ax.plot(x, (y1 + y2)/2,  alpha=.5,linewidth=2)\n",
        "\n",
        "# ax.fill_between(x, y3, y4, facecolor ='yellow',alpha=.5, linewidth=0)\n",
        "# ax.plot(x, (y3 + y4)/2, linewidth=2)\n",
        "\n",
        "# ax.set(xlim=(0, 58), xticks=np.arange(0, 58),\n",
        "#        ylim=(-3, 3), yticks=np.arange(0, 3))\n",
        "\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61HuUwI0HAik"
      },
      "outputs": [],
      "source": [
        "TARGETED = 0\n",
        "if(TARGETED):\n",
        "  x_test_jsma = targeted_benign_x_test_jsma\n",
        "else:\n",
        "  pass\n",
        "# Evaluate ART Classifier on adversarial test examples\n",
        "\n",
        "# fgsm_predictions = model.predict(x_test_fgsm)\n",
        "# # print(fgsm_predictions)\n",
        "# rounded_fgsm_predictions = fgsm_predictions.round().astype(int)\n",
        "# # print(rounded_fgsm_predictions)\n",
        "\n",
        "# fgsm_results = model.evaluate(x_test_fgsm, y_test)\n",
        "# print(\"------ FGSM test loss, test acc:\", fgsm_results)\n",
        "\n",
        "#---- JSMA\n",
        "keras_jsma_predictions = model.predict(x_test_jsma)\n",
        "skmlp_jsma_predictions = skMLP.predict_proba(x_test_jsma)\n",
        "integer_jsma_predictions = []\n",
        "# print(jsma_predictions)\n",
        "keras_rounded_jsma_predictions = keras_jsma_predictions.round().astype(int)\n",
        "skmlp_rounded_jsma_predictions = skmlp_jsma_predictions.round().astype(int)\n",
        "# rounded_jsma_predictions = jsma_predictions * 100\n",
        "# print(rounded_jsma_predictions)\n",
        "\n",
        "\n",
        "\n",
        "jsma_results = model.evaluate(x_test_jsma, y_test)\n",
        "print(\"------ JSMA test loss, test acc:\", jsma_results)\n",
        "\n",
        "skMLP.score(x_test_jsma,y_test)\n",
        "\n",
        "# print(rounded_fgsm_predictions)\n",
        "# print(y_test)\n",
        "OHE_y_test = to_categorical(y_test)\n",
        "# print(OHE_y_test)\n",
        "print(\"--- FGSM Classification Report ---\")\n",
        "# print(classification_report(\n",
        "#       rounded_fgsm_predictions,\n",
        "#       OHE_y_test,\n",
        "#       target_names=outcome,\n",
        "#       labels=range(0,(len(outcome))))\n",
        "# )\n",
        "\n",
        "# fgsm_class_report = classification_report(\n",
        "#       rounded_fgsm_predictions,\n",
        "#       OHE_y_test,\n",
        "#       target_names=outcome,\n",
        "#       labels=range(0,(len(outcome))),output_dict=True)\n",
        "# fgsm_class_report_df = pd.DataFrame(fgsm_class_report) #.transponse\n",
        "\n",
        "# with open(basedir + 'multiclass_fgsm_class_report.tex', 'w') as f:\n",
        "#   f.write(fgsm_class_report_df.to_latex(caption=\"FGSM Multiclass Classification Report\"))\n",
        "\n",
        "# print_classification_report(rounded_fgsm_predictions,OHE_y_test,'multiclass_fgsm_class_report.tex','FGSM Multiclass Classification Report')\n",
        "\n",
        "\n",
        "print(\"--- JSMA Classification Report ---\")\n",
        "# print(classification_report(\n",
        "#       rounded_jsma_predictions,\n",
        "#       OHE_y_test,\n",
        "#       target_names=outcome,\n",
        "#       labels=range(0,(len(outcome))))\n",
        "# )\n",
        "\n",
        "# jsma_class_report = classification_report(\n",
        "#       rounded_jsma_predictions,\n",
        "#       OHE_y_test,\n",
        "#       target_names=outcome,\n",
        "#       labels=range(0,(len(outcome))),output_dict=True)\n",
        "# jsma_class_report_df = pd.DataFrame(jsma_class_report) #.transponse\n",
        "\n",
        "# with open(basedir + 'multiclass_jsma_class_report.tex', 'w') as f:\n",
        "#   f.write(jsma_class_report_df.to_latex(caption=\"JSMA Multiclass Classification Report\"))\n",
        "\n",
        "if(TARGETED):\n",
        "  print_classification_report(keras_rounded_jsma_predictions,OHE_y_test,'keras_TARGETED_jsma_class_report.tex','Keras Targeted JSMA Multiclass Classification Report')\n",
        "  print_classification_report(skmlp_rounded_jsma_predictions,OHE_y_test,'skmlp_TARGETED_jsma_class_report.tex','SKlearn MLP Targeted JSMA Multiclass Classification Report')\n",
        "\n",
        "else: \n",
        "  print_classification_report(keras_rounded_jsma_predictions,OHE_y_test,'keras_UNTARGETED_jsma_class_report.tex','Keras JSMA Multiclass Classification Report')\n",
        "  print_classification_report(skmlp_rounded_jsma_predictions,OHE_y_test,'skmlp_UNTARGETED_jsma_class_report.tex','SKlearn MLP JSMA Multiclass Classification Report')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbp_2mq51vYa"
      },
      "outputs": [],
      "source": [
        "# integer_fgsm_predictions = []\n",
        "# print(rounded_fgsm_predictions)\n",
        "# for i in range(len(rounded_fgsm_predictions)):\n",
        "\n",
        "#   arr = [rounded_fgsm_predictions[i][0], rounded_fgsm_predictions[i][1], rounded_fgsm_predictions[i][2], \n",
        "#         rounded_fgsm_predictions[i][3], rounded_fgsm_predictions[i][4], rounded_fgsm_predictions[i][5], \n",
        "#         rounded_fgsm_predictions[i][6], rounded_fgsm_predictions[i][7], rounded_fgsm_predictions[i][8],\n",
        "#         rounded_fgsm_predictions[i][9], rounded_fgsm_predictions[i][10], rounded_fgsm_predictions[i][11],\n",
        "#         rounded_fgsm_predictions[i][12], rounded_fgsm_predictions[i][13], rounded_fgsm_predictions[i][14],\n",
        "#         ]\n",
        "\n",
        "#   # print(arr)\n",
        "#   HighestProbabilityClass = arr.index(max(arr))\n",
        "#   # print(HighestProbabilityClass)\n",
        "#   integer_fgsm_predictions.append(HighestProbabilityClass)\n",
        "\n",
        "# print(integer_fgsm_predictions)\n",
        "\n",
        "# cm = confusion_matrix(y_test,integer_fgsm_predictions)\n",
        "# plot_cm(cm,'Multiclass - FGSM - Confusion Matrix','ConfusionMatrix-Multiclass-FGSM.png')\n",
        "# plot_errors(cm,'Multiclass - FGSM - Error Matrix','ErrorMatrix-Multiclass-FGSM.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwPWqsSWvN_b"
      },
      "outputs": [],
      "source": [
        "keras_integer_jsma_predictions = []\n",
        "skmlp_integer_jsma_predictions = []\n",
        "# --- Do Keras\n",
        "print(keras_rounded_jsma_predictions)\n",
        "for i in range(len(keras_rounded_jsma_predictions)):\n",
        "\n",
        "  arr = [keras_rounded_jsma_predictions[i][0], keras_rounded_jsma_predictions[i][1], keras_rounded_jsma_predictions[i][2], \n",
        "        keras_rounded_jsma_predictions[i][3], keras_rounded_jsma_predictions[i][4], keras_rounded_jsma_predictions[i][5], \n",
        "        keras_rounded_jsma_predictions[i][6], keras_rounded_jsma_predictions[i][7], keras_rounded_jsma_predictions[i][8],\n",
        "        keras_rounded_jsma_predictions[i][9], keras_rounded_jsma_predictions[i][10], keras_rounded_jsma_predictions[i][11],\n",
        "        keras_rounded_jsma_predictions[i][12], keras_rounded_jsma_predictions[i][13], keras_rounded_jsma_predictions[i][14],\n",
        "        ]\n",
        "\n",
        "  print(arr)\n",
        "  Keras_HighestProbabilityClass = arr.index(max(arr))\n",
        "  # print(HighestProbabilityClass)\n",
        "  keras_integer_jsma_predictions.append(Keras_HighestProbabilityClass)\n",
        "\n",
        "print(keras_integer_jsma_predictions)\n",
        "# ---- Now do SKLearn\n",
        "print(skmlp_rounded_jsma_predictions)\n",
        "for i in range(len(skmlp_rounded_jsma_predictions)):\n",
        "\n",
        "  arr = [skmlp_rounded_jsma_predictions[i][0], skmlp_rounded_jsma_predictions[i][1], skmlp_rounded_jsma_predictions[i][2], \n",
        "        skmlp_rounded_jsma_predictions[i][3], skmlp_rounded_jsma_predictions[i][4], skmlp_rounded_jsma_predictions[i][5], \n",
        "        skmlp_rounded_jsma_predictions[i][6], skmlp_rounded_jsma_predictions[i][7], skmlp_rounded_jsma_predictions[i][8],\n",
        "        skmlp_rounded_jsma_predictions[i][9], skmlp_rounded_jsma_predictions[i][10], skmlp_rounded_jsma_predictions[i][11],\n",
        "        skmlp_rounded_jsma_predictions[i][12], skmlp_rounded_jsma_predictions[i][13], skmlp_rounded_jsma_predictions[i][14],\n",
        "        ]\n",
        "\n",
        "  # print(arr)\n",
        "  skmlp_HighestProbabilityClass = arr.index(max(arr))\n",
        "  # print(HighestProbabilityClass)\n",
        "  skmlp_integer_jsma_predictions.append(skmlp_HighestProbabilityClass)\n",
        "\n",
        "print(skmlp_integer_jsma_predictions)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test,keras_integer_jsma_predictions)\n",
        "#cm = confusion_matrix(y_test,integer_predictions)\n",
        "\n",
        "if(TARGETED):\n",
        "  plot_cm_theta(cm,'Keras Model - Targeted JSMA - Confusion Matrix','ConfusionMatrix-Keras-TARGETED-JSMA.png')\n",
        "\n",
        "  # plot_errors(cm,'Multiclass - Targeted JSMA - Error Matrix','ErrorMatrix-Multiclass-JSMA.png')\n",
        "\n",
        "  cm = confusion_matrix(y_test,skmlp_integer_jsma_predictions)\n",
        "  plot_cm_theta(cm,'SKlearn MLP - Targeted JSMA - Confusion Matrix','ConfusionMatrix-SKMLP-TARGETED-JSMA.png')\n",
        "  \n",
        "else:\n",
        "\n",
        "  plot_cm_theta(cm,'Keras Model - Untargeted JSMA - Confusion Matrix','ConfusionMatrix-Keras-UNTARGETED-JSMA.png')\n",
        "\n",
        "  # plot_errors(cm,'Multiclass - Untargeted JSMA - Error Matrix','ErrorMatrix-Multiclass-JSMA.png')\n",
        "\n",
        "  cm = confusion_matrix(y_test,skmlp_integer_jsma_predictions)\n",
        "  plot_cm_theta(cm,'SKlearn MLP - Untargeted JSMA - Confusion Matrix','ConfusionMatrix-SKMLP-UNTARGETED-JSMA.png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICqj8RtoHSso"
      },
      "outputs": [],
      "source": [
        "# exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2L1bDU-1UGT"
      },
      "outputs": [],
      "source": [
        "normal_count_arr = np.bincount(y_test)\n",
        "\n",
        "for i in range(0,14):\n",
        "  print(f\"{i} : {normal_count_arr[i]}\")\n",
        "print(\"-----------\")\n",
        "\n",
        "jsma_count_arr = np.bincount(keras_integer_jsma_predictions)\n",
        "# for i in range(0,14):\n",
        "#   print(f\"{i} : {jsma_count_arr[i]}\")\n",
        "\n",
        "matches = []\n",
        "\n",
        "for i in range (0,len(y_test)):\n",
        "  if(y_test[i] == keras_integer_jsma_predictions[i]):\n",
        "    # print(f\"Match for {y_test[i]}\")\n",
        "    matches.append(y_test[i])\n",
        "\n",
        "  else:\n",
        "    # print(f\"No Match for {y_test[i]}\")\n",
        "    matches.append(20*y_test[i])\n",
        "\n",
        "print(\"-----------\")\n",
        "matches_count_arr = np.bincount(matches)\n",
        "list_of_lists = []\n",
        "# my_df = pd.DataFrame(columns=['Traffic Type','Original Instances','Perturbed but Correctly Classified', 'Percentage Correctly Classified'])\n",
        "for i in range(0,15):\n",
        "  print(f\"{outcome[i]} : \\t{normal_count_arr[i]} \\t{matches_count_arr[i]}  \\t{matches_count_arr[i]/normal_count_arr[i]*100}\")\n",
        "  list_of_lists.append([outcome[i],normal_count_arr[i],matches_count_arr[i],(100-(matches_count_arr[i]/normal_count_arr[i]*100))])\n",
        "  my_df = pd.DataFrame(list_of_lists, columns=['Traffic Type','Number of Original Samples','Correct after Targeted JSMA', 'Successful Attack Percentage'])\n",
        "my_df = my_df.sort_values('Successful Attack Percentage', ascending=False)\n",
        "my_df = my_df.round(decimals=2)\n",
        "print(my_df)\n",
        "print(my_df.to_latex())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX0iVREXjIn3"
      },
      "outputs": [],
      "source": [
        "# exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb9RmL5pLi0e"
      },
      "outputs": [],
      "source": [
        "# from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# ovr = OneVsRestClassifier(skMLP)\n",
        "# ovr.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# keras_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model)\n",
        "# keras_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_shallow_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_shallow)\n",
        "# keras_shallow_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_dropout_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_dropout)\n",
        "# keras_dropout_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_dropout1_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_dropout1)\n",
        "# keras_dropout1_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_dropout2_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_dropout2)\n",
        "# keras_dropout2_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_dropout3_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_dropout3)\n",
        "# keras_dropout3_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_deeper_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_deeper)\n",
        "# keras_deeper_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_deeper_dropout_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_deeper_dropout)\n",
        "# keras_deeper_dropout_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_V_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_V)\n",
        "# keras_V_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# keras_A_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:model_A)\n",
        "# keras_A_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# ovr = OneVsRestClassifier(keras_clf)\n",
        "# ovr.fit(x_train,y_train)\n",
        "# ovrdropout = OneVsRestClassifier(keras_dropout_clf)\n",
        "# ovrdropout.fit(x_train,y_train)\n",
        "\n",
        "# print(\"Get the predictions\")\n",
        "\n",
        "# ovr_predictions = ovr.predict(x_test)\n",
        "\n",
        "# print(ovr_predictions)\n",
        "# print(y_test)\n",
        "\n",
        "# print(classification_report(\n",
        "#         ovr_predictions,y_test,\n",
        "#         target_names=outcome,\n",
        "#         labels=range(0,(len(outcome)))))\n",
        "\n",
        "# OVR_CLASS_REPORT = classification_report(\n",
        "#         ovr_predictions,y_test,\n",
        "#         target_names=outcome,\n",
        "#         labels=range(0,(len(outcome))),output_dict=True\n",
        "#     )\n",
        "\n",
        "# print(OVR_CLASS_REPORT)\n",
        "\n",
        "# ovr_class_report_df = pd.DataFrame(OVR_CLASS_REPORT)\n",
        "# filename= basedir + 'multiclass_OvR_class_report.tex'\n",
        "# print(ovr_class_report_df.to_latex(caption=\"OvR Multiclass Classification Report\"))\n",
        "# with open(filename, 'w') as f:\n",
        "#   f.write(ovr_class_report_df.to_latex(caption=\"OvR Classification Report\"))\n",
        "\n",
        "# print_classification_report(ovr_predictions,y_test,'multiclass_OvR_class_report.tex','OvR Classification Report')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xju9t921QKEM"
      },
      "outputs": [],
      "source": [
        "# cm = confusion_matrix(y_test,ovr_predictions)\n",
        "# #cm = confusion_matrix(y_test,integer_predictions)\n",
        "# plot_cm(cm,'OvR - Original - Confusion Matrix','ConfusionMatrix-Multiclass-OvR.png')\n",
        "# plot_errors(cm,'OvR - Original - Error Matrix','ErrorMatrix-Multiclass-OvR.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbCKq84pRQHM"
      },
      "outputs": [],
      "source": [
        "# # ovr_fgsm_predictions = ovr.predict(x_test_fgsm)\n",
        "# ovr_jsma_predictions = ovr.predict(x_test_jsma)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz_anxP9SIjS"
      },
      "outputs": [],
      "source": [
        "# cm = confusion_matrix(y_test,ovr_fgsm_predictions)\n",
        "#cm = confusion_matrix(y_test,integer_predictions)\n",
        "\n",
        "# plot_cm(cm,'OvR - FGSM - Confusion Matrix','ConfusionMatrix-OvR-FGSM.png')\n",
        "# plot_errors(cm,'OvR - FGSM - Error Matrix','ErrorMatrix-OvR-FGSM.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcH9PqNcSqCw"
      },
      "outputs": [],
      "source": [
        "# print_classification_report(ovr_jsma_predictions,y_test,'multiclass_OvR_class_report.tex','OvR Classification Report')\n",
        "\n",
        "# cm = confusion_matrix(y_test,ovr_jsma_predictions)\n",
        "# plot_cm(cm,'OvR - JSMA - Confusion Matrix','ConfusionMatrix-OvR-JSMA.png')\n",
        "# plot_errors(cm,'OvR - JSMA - Error Matrix','ErrorMatrix-OvR-JSMA.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T46PFMzrxLRg"
      },
      "source": [
        "Plot confusion matrices for individual models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbvUlggtxXVW"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import tree\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "original_f1_macros = []\n",
        "jsma_f1_macros = []\n",
        "\n",
        "#prepare algorithms to test\n",
        "models = []\n",
        "# models.append(('Keras Model',keras_clf))\n",
        "# models.append(('NB', MultinomialNB()))\n",
        "# models.append(('KNN', KNeighborsClassifier(n_neighbors = 10)))\n",
        "# models.append(('LR', LogisticRegression()))\n",
        "# models.append(('SVC', SVC(C=10, gamma=0.001))) #model is tuned using\n",
        "#GridSearch (code in seperate file)\n",
        "# models.append(('DT', tree.DecisionTreeClassifier()))\n",
        "# models.append(('RF', RandomForestClassifier(bootstrap=True, n_jobs=2, verbose=True, max_features=20, n_estimators=170, max_depth=None,min_samples_split=5, random_state=7)))\n",
        "# models.append(('AdaBoost', AdaBoostClassifier()))\n",
        "# models.append(('XGBoost',XGBClassifier()))\n",
        "# models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
        "# models.append(('HBBC',HistGradientBoostingClassifier()))\n",
        "# models.append(('LGBM',LGBMClassifier()))\n",
        "models.append(('MLP',MLPClassifier(hidden_layer_sizes=(128,64,15),activation ='relu',solver='adam', max_iter=300, shuffle=False,random_state=1, verbose=False))) # Converges around 1600 iters / Achieves similar accuracy to keras at 300 iters\n",
        "\n",
        "\n",
        "#evaluate each algorithm\n",
        "results = []\n",
        "names = []\n",
        "for name, current_model in models:\n",
        "  names.append(name)\n",
        "  current_model.fit(x_train, y_train)\n",
        "  orig_predictions = current_model.predict(x_test)\n",
        "  print(orig_predictions)\n",
        "  loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "  print(loss, accuracy)\n",
        "  if(name=='Kerasy Model'):\n",
        "    predictions = current_model.predict(x_test)\n",
        "    print(predictions)\n",
        "    # rounded_predictions = predictions.round().astype(int)\n",
        "    # print(rounded_predictions)\n",
        "    # integer_predictions = []\n",
        "\n",
        "    # print(\"-------\")\n",
        "    # for i in range(len(rounded_predictions)):\n",
        "\n",
        "    #   arr = [rounded_predictions[i][0], rounded_predictions[i][1], rounded_predictions[i][2], \n",
        "    #         rounded_predictions[i][3], rounded_predictions[i][4], rounded_predictions[i][5], \n",
        "    #         rounded_predictions[i][6], rounded_predictions[i][7], rounded_predictions[i][8],\n",
        "    #         rounded_predictions[i][9], rounded_predictions[i][10], rounded_predictions[i][11],\n",
        "    #         rounded_predictions[i][12], rounded_predictions[i][13], rounded_predictions[i][14],\n",
        "    #         ]\n",
        "\n",
        "    #   # print(arr)\n",
        "    #   HighestProbabilityClass = arr.index(max(arr))\n",
        "    #   # print(HighestProbabilityClass)\n",
        "    #   integer_predictions.append(HighestProbabilityClass)\n",
        "\n",
        "    print(predictions)\n",
        "    cm = confusion_matrix(y_test,predictions)\n",
        "    plot_cm(cm,str(name) + ' (Original)',str(name) + '-Original.png')\n",
        "\n",
        "    jsma_predictions = current_model.predict(x_test_jsma)\n",
        "    print(jsma_predictions)\n",
        "    print(jsma_predictions)\n",
        "    cm = confusion_matrix(y_test,jsma_predictions)\n",
        "    plot_cm(cm,str(name) + ' (JSMA)',str(name) + '-JSMA.png')\n",
        "\n",
        "  else:\n",
        "    cm = confusion_matrix(y_test,orig_predictions)\n",
        "    plot_cm(cm,str(name) + ' (Original)',str(name) + '-Original.png')\n",
        "    DICT = classification_report(\n",
        "        orig_predictions,y_test,\n",
        "        # target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome))),output_dict=True\n",
        "    )\n",
        "    original_f1_macros.append(DICT['macro avg']['f1-score'])\n",
        "    print_classification_report(orig_predictions, y_test, 'class_report_' + str(name) +'-Original.tex', str(name) + 'Classification Report (Original)')\n",
        "\n",
        "    jsma_predictions = current_model.predict(x_test_jsma)\n",
        "    cm = confusion_matrix(y_test,jsma_predictions)\n",
        "    plot_cm(cm,str(name) + ' (JSMA)',str(name) + '-JSMA.png')\n",
        "    DICT = classification_report(\n",
        "        jsma_predictions,y_test,\n",
        "        # target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome))),output_dict=True\n",
        "    )\n",
        "    jsma_f1_macros.append(DICT['macro avg']['f1-score'])\n",
        "    print_classification_report(jsma_predictions, y_test, 'class_report_' + str(name) +'-JSMA.tex', str(name) + 'Classification Report (JSMA)')\n",
        "\n",
        "# print(\"Name, original f1_macro, JSMA f1 macro\")\n",
        "# for i in range(0,len(names)):\n",
        "# print(names[i],original_f1_macros[i],jsma_f1_macros[i])\n",
        "\n",
        "robustness_df = pd.DataFrame(np.column_stack([names, original_f1_macros, jsma_f1_macros]), \n",
        "                               columns=['Model Name', 'Original F1-Score Macro Avg', 'Adversarial F1-Score Macro Avg'])\n",
        "\n",
        "robustness_df[[\"Original F1-Score Macro Avg\", \"Adversarial F1-Score Macro Avg\"]] = robustness_df[[\"Original F1-Score Macro Avg\", \"Adversarial F1-Score Macro Avg\"]].apply(pd.to_numeric)\n",
        "rounded_decimals = robustness_df.round(decimals=2)\n",
        "print(rounded_decimals)\n",
        "print(rounded_decimals.sort_values('Adversarial F1-Score Macro Avg'))\n",
        "sorted_df = rounded_decimals.sort_values('Adversarial F1-Score Macro Avg')\n",
        "\n",
        "print(sorted_df.to_latex(caption='Model Types sorted by Adversarial F1-Score Macro Avg'))\n",
        "with open('modeltype_f1_score_amacro_avg.tex', 'w') as f:\n",
        "  f.write(sorted_df.to_latex(caption='Model Types sorted by Adversarial F1-Score Macro Avg'))\n",
        "\n",
        "conditions = []\n",
        "for i in range (0,len(names)):\n",
        "  conditions.append('Ordinary')\n",
        "for i in range (0,len(names)):\n",
        "  conditions.append('Adversarial')\n",
        "\n",
        "\n",
        "orig_df = pd.DataFrame(np.column_stack([names, original_f1_macros]), \n",
        "                               columns=['Model Name', 'F1-Score'])\n",
        "adversarial_df = pd.DataFrame(np.column_stack([names, jsma_f1_macros]), \n",
        "                               columns=['Model Name', 'F1-Score'])\n",
        "\n",
        "group_frames = [orig_df,adversarial_df]\n",
        "group_df = pd.concat(group_frames)\n",
        "group_df['Conditions'] = conditions\n",
        "group_df[['F1-Score']] = group_df[['F1-Score']].apply(pd.to_numeric)\n",
        "print(group_df)\n",
        "group_df = group_df.round(decimals=2)\n",
        "group_df = group_df.sort_values('F1-Score')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#set seaborn plotting aesthetics\n",
        "sns.set(style='white')\n",
        "\n",
        "#create grouped bar chart\n",
        "sns.barplot(x='Model Name', y='F1-Score', hue='Conditions', hue_order={'Ordinary','Adversarial'}, data=group_df,\n",
        "            palette=['purple', 'steelblue'])\n",
        "\n",
        "#add overall title\n",
        "plt.title('F1-Score Macro Avg (Ordinary Vs. Adversarial)', fontsize=16)\n",
        "\n",
        "#add axis titles\n",
        "plt.xlabel('Model Name')\n",
        "plt.ylabel('F1-Score Macro Avg')\n",
        "\n",
        "#rotate x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "# Put the legend out of the figure\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "#save the plot\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "savename='F1-Score-Plot.png'\n",
        "filename=basedir+savename\n",
        "plt.savefig(filename,dpi=300,bbox_inches='tight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE0sZT3z2ecj"
      },
      "outputs": [],
      "source": [
        "# Do the Hierarchical \n",
        "\n",
        "# Install conda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!conda install -c conda-forge hiclass=3.1.6 --yes\n",
        "# !conda install -c conda-forge hiclass=4.0.6 --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BakN5lbF5T5M"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import tree\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "#Importing MLPClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "# model = MLPClassifier(hidden_layer_sizes=(128,64),activation ='relu',solver='sgd',random_state=1)\n",
        "\n",
        "\n",
        "original_f1_macros = []\n",
        "jsma_f1_macros = []\n",
        "\n",
        "#prepare algorithms to test\n",
        "models = []\n",
        "# models.append(('Keras Model',keras_clf))\n",
        "models.append(('MLP',MLPClassifier(hidden_layer_sizes=(128,64,15),activation ='relu',solver='adam', max_iter=300, shuffle=False,random_state=1, verbose=False))) # Converges around 1600 iters / Achieves similar accuracy to keras at 300 iters\n",
        "# models.append(('NB', MultinomialNB())) # Naive Bayes\n",
        "# models.append(('KNN', KNeighborsClassifier(n_neighbors = 10))) # k Nearest Neighbour\n",
        "# models.append(('LR', LogisticRegression())) # Logistic Regression\n",
        "# models.append(('SVC', SVC(C=10, gamma=0.001, probability=True))) # Support Vector Classifier model is tuned using GridSearch (code in seperate file)\n",
        "# models.append(('DT', tree.DecisionTreeClassifier())) # Decision Tree\n",
        "# models.append(('RF', RandomForestClassifier(bootstrap=True, n_jobs=2, verbose=True, max_features=20, n_estimators=170, max_depth=None,min_samples_split=5, random_state=7))) # Random Forest\n",
        "# models.append(('AdaBoost', AdaBoostClassifier()))\n",
        "# models.append(('XGBoost',XGBClassifier()))\n",
        "# models.append(('QDA', QuadraticDiscriminantAnalysis())) # Quadratic Discrimination Analysis\n",
        "# models.append(('HBBC',HistGradientBoostingClassifier())) # Histogram Based Boosting Classifier\n",
        "# models.append(('LGBM',LGBMClassifier())) # Light Gradient Boosting Machine\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "#evaluate each algorithm\n",
        "results = []\n",
        "names = []\n",
        "for name, current_model in models:\n",
        "  names.append(name)\n",
        "  current_model.fit(x_train, y_train)\n",
        "  orig_predictions = current_model.predict(x_test)\n",
        "  print(orig_predictions)\n",
        "  loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "  print(loss, accuracy)\n",
        "  if(name=='Kerasy Model'):\n",
        "    predictions = current_model.predict(x_test)\n",
        "    print(predictions)\n",
        "    # rounded_predictions = predictions.round().astype(int)\n",
        "    # print(rounded_predictions)\n",
        "    # integer_predictions = []\n",
        "\n",
        "    # print(\"-------\")\n",
        "    # for i in range(len(rounded_predictions)):\n",
        "\n",
        "    #   arr = [rounded_predictions[i][0], rounded_predictions[i][1], rounded_predictions[i][2], \n",
        "    #         rounded_predictions[i][3], rounded_predictions[i][4], rounded_predictions[i][5], \n",
        "    #         rounded_predictions[i][6], rounded_predictions[i][7], rounded_predictions[i][8],\n",
        "    #         rounded_predictions[i][9], rounded_predictions[i][10], rounded_predictions[i][11],\n",
        "    #         rounded_predictions[i][12], rounded_predictions[i][13], rounded_predictions[i][14],\n",
        "    #         ]\n",
        "\n",
        "    #   # print(arr)\n",
        "    #   HighestProbabilityClass = arr.index(max(arr))\n",
        "    #   # print(HighestProbabilityClass)\n",
        "    #   integer_predictions.append(HighestProbabilityClass)\n",
        "\n",
        "    print(predictions)\n",
        "    cm = confusion_matrix(y_test,predictions)\n",
        "    plot_cm(cm,str(name) + ' (Original)',str(name) + '-Original.png')\n",
        "\n",
        "    jsma_predictions = current_model.predict(x_test_jsma)\n",
        "    print(jsma_predictions)\n",
        "    print(jsma_predictions)\n",
        "    cm = confusion_matrix(y_test,jsma_predictions)\n",
        "    plot_cm(cm,str(name) + ' (JSMA)',str(name) + '-JSMA.png')\n",
        "\n",
        "  else:\n",
        "    cm = confusion_matrix(y_test,orig_predictions)\n",
        "    plot_cm(cm,str(name) + ' (Original)',str(name) + '-Original.png')\n",
        "    DICT = classification_report(\n",
        "        orig_predictions,y_test,\n",
        "        # target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome))),output_dict=True\n",
        "    )\n",
        "    original_f1_macros.append(DICT['macro avg']['f1-score'])\n",
        "    print_classification_report(orig_predictions, y_test, 'class_report_' + str(name) +'-Original.tex', str(name) + 'Classification Report (Original)')\n",
        "\n",
        "    jsma_predictions = current_model.predict(x_test_jsma)\n",
        "    cm = confusion_matrix(y_test,jsma_predictions)\n",
        "    plot_cm(cm,str(name) + ' (JSMA)',str(name) + '-JSMA.png')\n",
        "    DICT = classification_report(\n",
        "        jsma_predictions,y_test,\n",
        "        # target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome))),output_dict=True\n",
        "    )\n",
        "    jsma_f1_macros.append(DICT['macro avg']['f1-score'])\n",
        "    print_classification_report(jsma_predictions, y_test, 'class_report_' + str(name) +'-JSMA.tex', str(name) + 'Classification Report (JSMA)')\n",
        "\n",
        "# print(\"Name, original f1_macro, JSMA f1 macro\")\n",
        "# for i in range(0,len(names)):\n",
        "# print(names[i],original_f1_macros[i],jsma_f1_macros[i])\n",
        "\n",
        "robustness_df = pd.DataFrame(np.column_stack([names, original_f1_macros, jsma_f1_macros]), \n",
        "                               columns=['Model Name', 'Original F1-Score Macro Avg', 'Adversarial F1-Score Macro Avg'])\n",
        "\n",
        "robustness_df[[\"Original F1-Score Macro Avg\", \"Adversarial F1-Score Macro Avg\"]] = robustness_df[[\"Original F1-Score Macro Avg\", \"Adversarial F1-Score Macro Avg\"]].apply(pd.to_numeric)\n",
        "rounded_decimals = robustness_df.round(decimals=2)\n",
        "print(rounded_decimals)\n",
        "print(rounded_decimals.sort_values('Adversarial F1-Score Macro Avg'))\n",
        "sorted_df = rounded_decimals.sort_values('Adversarial F1-Score Macro Avg')\n",
        "\n",
        "print(sorted_df.to_latex(caption='Model Types sorted by Adversarial F1-Score Macro Avg'))\n",
        "with open('modeltype_f1_score_amacro_avg.tex', 'w') as f:\n",
        "  f.write(sorted_df.to_latex(caption='Model Types sorted by Adversarial F1-Score Macro Avg'))\n",
        "\n",
        "conditions = []\n",
        "for i in range (0,len(names)):\n",
        "  conditions.append('Original')\n",
        "for i in range (0,len(names)):\n",
        "  conditions.append('Adversarial')\n",
        "\n",
        "\n",
        "orig_df = pd.DataFrame(np.column_stack([names, original_f1_macros]), \n",
        "                               columns=['Model Name', 'F1-Score'])\n",
        "adversarial_df = pd.DataFrame(np.column_stack([names, jsma_f1_macros]), \n",
        "                               columns=['Model Name', 'F1-Score'])\n",
        "\n",
        "group_frames = [orig_df,adversarial_df]\n",
        "group_df = pd.concat(group_frames)\n",
        "group_df['Conditions'] = conditions\n",
        "group_df[['F1-Score']] = group_df[['F1-Score']].apply(pd.to_numeric)\n",
        "print(group_df)\n",
        "group_df = group_df.round(decimals=2)\n",
        "group_df = group_df.sort_values('F1-Score')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#set seaborn plotting aesthetics\n",
        "sns.set(style='white')\n",
        "\n",
        "#create grouped bar chart\n",
        "sns.barplot(x='Model Name', y='F1-Score', hue='Conditions', hue_order={'Original','Adversarial'}, data=group_df,\n",
        "            palette=['purple', 'steelblue'])\n",
        "\n",
        "#add overall title\n",
        "plt.title('F1-Score Macro Avg (Normal Vs. Adversarial)', fontsize=16)\n",
        "\n",
        "#add axis titles\n",
        "plt.xlabel('Model Name')\n",
        "plt.ylabel('F1-Score Macro Avg')\n",
        "\n",
        "#rotate x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "# Put the legend out of the figure\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "#save the plot\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "savename='F1-Score-Plot.png'\n",
        "filename=basedir+savename\n",
        "plt.savefig(filename,dpi=300,bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQosddrLeliz"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import tree\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "original_f1_macros = []\n",
        "jsma_f1_macros = []\n",
        "\n",
        "# eclfdropout = VotingClassifier(\n",
        "#     estimators = [\n",
        "#                   ('Keras Model', keras_clf), \n",
        "#                   ('Keras+Dropout', keras_dropout_clf)\n",
        "#     ],voting='soft'\n",
        "# )\n",
        "\n",
        "# eclfdeeper = VotingClassifier(\n",
        "#     estimators = [\n",
        "#                   ('Keras Model', keras_clf), \n",
        "#                   ('Deeper Model', keras_deeper_clf)\n",
        "#     ],voting='soft'\n",
        "# )\n",
        "\n",
        "# eclfdeeper = VotingClassifier(\n",
        "#     estimators = [\n",
        "#                   ('Keras Model', keras_clf), \n",
        "#                   ('Deeper Model', keras_deeper_dropout_clf)\n",
        "#     ],voting='soft'\n",
        "# )\n",
        "\n",
        "\n",
        "#prepare algorithms to test\n",
        "models = []\n",
        "# models.append(('Keras Model',keras_clf))\n",
        "# models.append(('Keras+Dropout', keras_dropout_clf))\n",
        "# models.append(('Keras+DeeperDropout', keras_deeper_dropout_clf))\n",
        "# models.append(('ECLF+Dropout', eclfdropout))\n",
        "# models.append(('ECLF+Deeper', eclfdeeper))\n",
        "# models.append(('OvR', ovr))\n",
        "# models.append(('OvR+Dropout', ovrdropout))\n",
        "# models.append(('ECLF+Deeper', LogisticRegression()))\n",
        "# models.append(('ECLF+Deeper+Dropout', SVC(C=10, gamma=0.001))) #model is tuned using\n",
        "# #GridSearch (code in seperate file)\n",
        "# models.append(('DT', tree.DecisionTreeClassifier()))\n",
        "# models.append(('RF', RandomForestClassifier(bootstrap=True, n_jobs=2, verbose=True, max_features=20, n_estimators=170, max_depth=None,min_samples_split=5, random_state=7)))\n",
        "# models.append(('AdaBoost', AdaBoostClassifier()))\n",
        "# models.append(('XGBoost',XGBClassifier()))\n",
        "# models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
        "# models.append(('HBBC',HistGradientBoostingClassifier()))\n",
        "# models.append(('LGBM',LGBMClassifier()))\n",
        "models.append(('MLP',MLPClassifier(hidden_layer_sizes=(128,64,15),activation ='relu',solver='adam', max_iter=300, shuffle=False,random_state=1, verbose=False))) # Converges around 1600 iters / Achieves similar accuracy to keras at 300 iters\n",
        "\n",
        "\n",
        "#evaluate each algorithm\n",
        "results = []\n",
        "names = []\n",
        "for name, current_model in models:\n",
        "  names.append(name)\n",
        "  current_model.fit(x_train, y_train)\n",
        "  orig_predictions = current_model.predict(x_test)\n",
        "  print(orig_predictions)\n",
        "  loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "  print(loss, accuracy)\n",
        "  if(name=='Kerasy Model'):\n",
        "    predictions = current_model.predict(x_test)\n",
        "    print(predictions)\n",
        "    # rounded_predictions = predictions.round().astype(int)\n",
        "    # print(rounded_predictions)\n",
        "    # integer_predictions = []\n",
        "\n",
        "    # print(\"-------\")\n",
        "    # for i in range(len(rounded_predictions)):\n",
        "\n",
        "    #   arr = [rounded_predictions[i][0], rounded_predictions[i][1], rounded_predictions[i][2], \n",
        "    #         rounded_predictions[i][3], rounded_predictions[i][4], rounded_predictions[i][5], \n",
        "    #         rounded_predictions[i][6], rounded_predictions[i][7], rounded_predictions[i][8],\n",
        "    #         rounded_predictions[i][9], rounded_predictions[i][10], rounded_predictions[i][11],\n",
        "    #         rounded_predictions[i][12], rounded_predictions[i][13], rounded_predictions[i][14],\n",
        "    #         ]\n",
        "\n",
        "    #   # print(arr)\n",
        "    #   HighestProbabilityClass = arr.index(max(arr))\n",
        "    #   # print(HighestProbabilityClass)\n",
        "    #   integer_predictions.append(HighestProbabilityClass)\n",
        "\n",
        "    print(predictions)\n",
        "    cm = confusion_matrix(y_test,predictions)\n",
        "    plot_cm(cm,str(name) + ' (Original)',str(name) + '-Original.png')\n",
        "\n",
        "    jsma_predictions = current_model.predict(x_test_jsma)\n",
        "    print(jsma_predictions)\n",
        "    print(jsma_predictions)\n",
        "    cm = confusion_matrix(y_test,jsma_predictions)\n",
        "    plot_cm(cm,str(name) + ' (JSMA)',str(name) + '-JSMA.png')\n",
        "\n",
        "  else:\n",
        "    cm = confusion_matrix(y_test,orig_predictions)\n",
        "    plot_cm(cm,str(name) + ' (Original)',str(name) + '-Original.png')\n",
        "    DICT = classification_report(\n",
        "        orig_predictions,y_test,\n",
        "        # target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome))),output_dict=True\n",
        "    )\n",
        "    original_f1_macros.append(DICT['macro avg']['f1-score'])\n",
        "    print_classification_report(orig_predictions, y_test, 'class_report_' + str(name) +'-Original.tex', str(name) + 'Classification Report (Original)')\n",
        "\n",
        "    jsma_predictions = current_model.predict(x_test_jsma)\n",
        "    cm = confusion_matrix(y_test,jsma_predictions)\n",
        "    plot_cm(cm,str(name) + ' (JSMA)',str(name) + '-JSMA.png')\n",
        "    DICT = classification_report(\n",
        "        jsma_predictions,y_test,\n",
        "        # target_names=l_col_list,\n",
        "        labels=range(0,(len(outcome))),output_dict=True\n",
        "    )\n",
        "    jsma_f1_macros.append(DICT['macro avg']['f1-score'])\n",
        "    print_classification_report(jsma_predictions, y_test, 'class_report_' + str(name) +'-JSMA.tex', str(name) + 'Classification Report (JSMA)')\n",
        "\n",
        "# print(\"Name, original f1_macro, JSMA f1 macro\")\n",
        "# for i in range(0,len(names)):\n",
        "# print(names[i],original_f1_macros[i],jsma_f1_macros[i])\n",
        "\n",
        "robustness_df = pd.DataFrame(np.column_stack([names, original_f1_macros, jsma_f1_macros]), \n",
        "                               columns=['Model Name', 'Original F1-Score Macro Avg', 'Adversarial F1-Score Macro Avg'])\n",
        "\n",
        "robustness_df[[\"Original F1-Score Macro Avg\", \"Adversarial F1-Score Macro Avg\"]] = robustness_df[[\"Original F1-Score Macro Avg\", \"Adversarial F1-Score Macro Avg\"]].apply(pd.to_numeric)\n",
        "rounded_decimals = robustness_df.round(decimals=2)\n",
        "print(rounded_decimals)\n",
        "print(rounded_decimals.sort_values('Adversarial F1-Score Macro Avg'))\n",
        "sorted_df = rounded_decimals.sort_values('Adversarial F1-Score Macro Avg')\n",
        "\n",
        "print(sorted_df.to_latex(caption='Model Types sorted by Adversarial F1-Score Macro Avg'))\n",
        "with open('modeltype_f1_score_amacro_avg.tex', 'w') as f:\n",
        "  f.write(sorted_df.to_latex(caption='Model Types sorted by Adversarial F1-Score Macro Avg'))\n",
        "\n",
        "conditions = []\n",
        "for i in range (0,len(names)):\n",
        "  conditions.append('Ordinary')\n",
        "for i in range (0,len(names)):\n",
        "  conditions.append('Adversarial')\n",
        "\n",
        "\n",
        "orig_df = pd.DataFrame(np.column_stack([names, original_f1_macros]), \n",
        "                               columns=['Model Name', 'F1-Score'])\n",
        "adversarial_df = pd.DataFrame(np.column_stack([names, jsma_f1_macros]), \n",
        "                               columns=['Model Name', 'F1-Score'])\n",
        "\n",
        "group_frames = [orig_df,adversarial_df]\n",
        "group_df = pd.concat(group_frames)\n",
        "group_df['Conditions'] = conditions\n",
        "group_df[['F1-Score']] = group_df[['F1-Score']].apply(pd.to_numeric)\n",
        "print(group_df)\n",
        "group_df = group_df.round(decimals=2)\n",
        "group_df = group_df.sort_values('F1-Score')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#set seaborn plotting aesthetics\n",
        "sns.set(style='white')\n",
        "\n",
        "#create grouped bar chart\n",
        "sns.barplot(x='Model Name', y='F1-Score', hue='Conditions', hue_order={'Ordinary','Adversarial'}, data=group_df,\n",
        "            palette=['purple', 'steelblue'])\n",
        "\n",
        "#add overall title\n",
        "plt.title('F1-Score Macro Avg (Ordinary Vs. Adversarial)', fontsize=16)\n",
        "\n",
        "#add axis titles\n",
        "plt.xlabel('Model Name')\n",
        "plt.ylabel('F1-Score Macro Avg')\n",
        "\n",
        "#rotate x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "# Put the legend out of the figure\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "#save the plot\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "savename='Basic-Hardening-Plot.png'\n",
        "filename=basedir+savename\n",
        "plt.savefig(filename,dpi=300,bbox_inches='tight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qneKnFyS-8HT"
      },
      "outputs": [],
      "source": [
        "# Define Expert Hierarchy \n",
        "hier_labels = []\n",
        "for i in range (0,len(Y_class)):\n",
        "  # print(str(Y_class[i]))\n",
        "  # print(outcome)\n",
        "  if(int(Y_class[i]) == 0): # outcome[0]):\n",
        "    hier_labels.append(['Other', 'BENIGN'])\n",
        "\n",
        "  elif(int(Y_class[i]) == 1):\n",
        "    hier_labels.append(['DoS','DDoS'])\n",
        "\n",
        "  elif(int(Y_class[i]) == 2):\n",
        "      hier_labels.append(['Penetration','PortScan'])\n",
        "\n",
        "  elif(int(Y_class[i]) == 3):\n",
        "      hier_labels.append(['Penetration','Bot'])\n",
        "  \n",
        "  elif(int(Y_class[i]) == 4):\n",
        "      hier_labels.append(['Penetration','Infiltration'])\n",
        "  \n",
        "  elif(int(Y_class[i]) == 5):\n",
        "      hier_labels.append(['BruteForce','WebAttack Brute Force'])\n",
        "  \n",
        "  elif(int(Y_class[i]) == 6):\n",
        "      hier_labels.append(['Exploit','XXS'])\n",
        "  elif(int(Y_class[i]) == 7):\n",
        "      hier_labels.append(['Exploit','SQL Injection'])\n",
        "  elif(int(Y_class[i]) == 8):\n",
        "      hier_labels.append(['BruteForce','FTP-Patator'])\n",
        "  elif(int(Y_class[i]) == 9):\n",
        "      hier_labels.append(['BruteForce','SSH-Patator'])\n",
        "  elif(int(Y_class[i]) == 10):\n",
        "      hier_labels.append(['DoS','DoS slowloris'])\n",
        "  elif(int(Y_class[i]) == 11):\n",
        "      hier_labels.append(['DoS','DoS Slowhttptest'])\n",
        "  elif(int(Y_class[i]) == 12):\n",
        "      hier_labels.append(['DoS','DoS Hulk'])\n",
        "  elif(int(Y_class[i]) == 13):\n",
        "      hier_labels.append(['DoS','Dos GoldenEye'])\n",
        "  elif(int(Y_class[i]) == 14):\n",
        "      hier_labels.append(['Exploit','Heartbleed'])\n",
        "print(len(Y_class))\n",
        "print(len(hier_labels))\n",
        "print(len(Y_class)-(len(hier_labels)))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X99HeAUvckl5"
      },
      "outputs": [],
      "source": [
        "# # Define Dataset Hierarchy\n",
        "# hier_labels = []\n",
        "# for i in range (0,len(Y_class)):\n",
        "#   # print(str(Y_class[i]))\n",
        "#   # print(outcome)\n",
        "#   if(int(Y_class[i]) == 0): # outcome[0]):\n",
        "#     hier_labels.append(['Other', 'BENIGN'])\n",
        "\n",
        "#   elif(int(Y_class[i]) == 1):\n",
        "#     hier_labels.append(['DoS/DDoS/Heartbleed','DDoS'])\n",
        "\n",
        "#   elif(int(Y_class[i]) == 2):\n",
        "#       hier_labels.append(['Botnet/PortScan','PortScan'])\n",
        "\n",
        "#   elif(int(Y_class[i]) == 3):\n",
        "#       hier_labels.append(['Botnet/PortScan','Bot'])\n",
        "  \n",
        "#   elif(int(Y_class[i]) == 4):\n",
        "#       hier_labels.append(['Infiltration','Infiltration'])\n",
        "  \n",
        "#   elif(int(Y_class[i]) == 5):\n",
        "#       hier_labels.append(['WebAttack','WebAttack Brute Force'])\n",
        "  \n",
        "#   elif(int(Y_class[i]) == 6):\n",
        "#       hier_labels.append(['WebAttack','WebAttackXXS'])\n",
        "#   elif(int(Y_class[i]) == 7):\n",
        "#       hier_labels.append(['WebAttack','WebAttack SQL Injection'])\n",
        "#   elif(int(Y_class[i]) == 8):\n",
        "#       hier_labels.append(['BruteForce','FTP-Patator'])\n",
        "#   elif(int(Y_class[i]) == 9):\n",
        "#       hier_labels.append(['BruteForce','SSH-Patator'])\n",
        "#   elif(int(Y_class[i]) == 10):\n",
        "#       hier_labels.append(['DoS/DDoS/Heartbleed','DoS slowloris'])\n",
        "#   elif(int(Y_class[i]) == 11):\n",
        "#       hier_labels.append(['DoS/DDoS/Heartbleed','DoS Slowhttptest'])\n",
        "#   elif(int(Y_class[i]) == 12):\n",
        "#       hier_labels.append(['DoS/DDoS/Heartbleed','DoS Hulk'])\n",
        "#   elif(int(Y_class[i]) == 13):\n",
        "#       hier_labels.append(['DoS/DDoS/Heartbleed','Dos GoldenEye'])\n",
        "#   elif(int(Y_class[i]) == 14):\n",
        "#       hier_labels.append(['DoS/DDoS/Heartbleed','Heartbleed'])\n",
        "# print(len(Y_class))\n",
        "# print(len(hier_labels))\n",
        "# print(len(Y_class)-(len(hier_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0nH5jsgbIqA"
      },
      "outputs": [],
      "source": [
        "# # Define Ward Hierarchy \n",
        "# hier_labels = []\n",
        "# for i in range (0,len(Y_class)):\n",
        "#   # print(str(Y_class[i]))\n",
        "#   # print(outcome)\n",
        "#   if(int(Y_class[i]) == 0): # outcome[0]):\n",
        "#     hier_labels.append(['0', 'BENIGN'])\n",
        "\n",
        "#   elif(int(Y_class[i]) == 1):\n",
        "#     hier_labels.append(['0','DDoS'])\n",
        "\n",
        "#   elif(int(Y_class[i]) == 2):\n",
        "#       hier_labels.append(['1','PortScan'])\n",
        "\n",
        "#   elif(int(Y_class[i]) == 3):\n",
        "#       hier_labels.append(['1','Bot'])\n",
        "  \n",
        "#   elif(int(Y_class[i]) == 4):\n",
        "#       hier_labels.append(['0','Infiltration'])\n",
        "  \n",
        "#   elif(int(Y_class[i]) == 5):\n",
        "#       hier_labels.append(['1','WebAttack Brute Force'])\n",
        "  \n",
        "#   elif(int(Y_class[i]) == 6):\n",
        "#       hier_labels.append(['2','XXS'])\n",
        "#   elif(int(Y_class[i]) == 7):\n",
        "#       hier_labels.append(['1','SQL Injection'])\n",
        "#   elif(int(Y_class[i]) == 8):\n",
        "#       hier_labels.append(['3','FTP-Patator'])\n",
        "#   elif(int(Y_class[i]) == 9):\n",
        "#       hier_labels.append(['4','SSH-Patator'])\n",
        "#   elif(int(Y_class[i]) == 10):\n",
        "#       hier_labels.append(['1','DoS slowloris'])\n",
        "#   elif(int(Y_class[i]) == 11):\n",
        "#       hier_labels.append(['0','DoS Slowhttptest'])\n",
        "#   elif(int(Y_class[i]) == 12):\n",
        "#       hier_labels.append(['1','DoS Hulk'])\n",
        "#   elif(int(Y_class[i]) == 13):\n",
        "#       hier_labels.append(['1','Dos GoldenEye'])\n",
        "#   elif(int(Y_class[i]) == 14):\n",
        "#       hier_labels.append(['1','Heartbleed'])\n",
        "# print(len(Y_class))\n",
        "# print(len(hier_labels))\n",
        "# print(len(Y_class)-(len(hier_labels)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIP5NRXZ_eew"
      },
      "outputs": [],
      "source": [
        "# Split training and test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Train test split\n",
        "\n",
        "testSize = 0.3\n",
        "\n",
        "print(len(x_scaled))\n",
        "print(len(hier_labels))\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, hier_labels, test_size = testSize, shuffle=True, random_state = 42)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.3, random_state=42\n",
        "# )\n",
        "\n",
        "print(y_train)\n",
        "\n",
        "coarse_label = np.empty(len(x_train),dtype=object)\n",
        "finer_label = np.empty(len(x_train),dtype=object)\n",
        "\n",
        "for i in range(0,len(y_train)):\n",
        "\n",
        "  coarse_label[i] = y_train[i][0]\n",
        "  finer_label[i] = y_train[i][1]\n",
        "\n",
        "print(coarse_label[0])\n",
        "print(finer_label[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(y_test)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(coarse_label)\n",
        "print(coarse_label[0])\n",
        "coarse_label= le.transform(coarse_label) # multi-class \n",
        "print(coarse_label[0])\n",
        "\n",
        "le.fit(finer_label)\n",
        "print(finer_label[0])\n",
        "finer_label= le.transform(finer_label) # multi-class \n",
        "print(finer_label[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9eZRK0ncY8z"
      },
      "outputs": [],
      "source": [
        "# Build pipeline\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from hiclass import LocalClassifierPerNode, LocalClassifierPerParentNode, LocalClassifierPerLevel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# base_classifier = LogisticRegression(\n",
        "#     random_state=0,\n",
        "#     max_iter=10000,\n",
        "#     n_jobs=1,\n",
        "# )\n",
        "\n",
        "base_classifier = MLPClassifier(hidden_layer_sizes=(128,64,15),activation ='relu',solver='adam', max_iter=300, shuffle=False,random_state=1, verbose=False) # Converges around 1600 iters / Achieves similar accuracy to keras at 300 iters\n",
        "\n",
        "LCPPN = 0\n",
        "LCPN  = 0 \n",
        "LCPL  = 0\n",
        "\n",
        "lcpn = LocalClassifierPerParentNode(\n",
        "    local_classifier=base_classifier,\n",
        "    verbose=20,\n",
        "    n_jobs=1,\n",
        ")\n",
        "LCPPN = 1\n",
        "\n",
        "# lcpn = LocalClassifierPerNode(\n",
        "#     local_classifier=base_classifier,\n",
        "#     verbose=20,\n",
        "#     n_jobs=1,\n",
        "# )\n",
        "# LCPN = 1\n",
        "\n",
        "# lcpn = LocalClassifierPerLevel(\n",
        "#     local_classifier=base_classifier,\n",
        "#     verbose=20,\n",
        "#     n_jobs=1,\n",
        "# )\n",
        "# LCPL =1 \n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    # ('count', CountVectorizer()),\n",
        "    # ('tfidf', TfidfTransformer()),\n",
        "    ('model', lcpn),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Train classifier\n",
        "pipeline.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJUqvtCG-gRj"
      },
      "outputs": [],
      "source": [
        "# Predict\n",
        "predictions = lcpn.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iiCqwvx_-pgX",
        "outputId": "fc04d1f4-51b8-4fbb-cd70-5e8555a24719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Exploit', 'DoS', 'BruteForce', 'BruteForce', 'DoS', 'BruteForce', 'Exploit', 'Other', 'DoS', 'DoS', 'DoS', 'Exploit', 'DoS', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'DoS', 'BruteForce', 'Exploit', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'DoS', 'Penetration', 'BruteForce', 'Penetration', 'DoS', 'Penetration', 'DoS', 'DoS', 'DoS', 'Exploit', 'Exploit', 'DoS', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'Other', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'Exploit', 'BruteForce', 'DoS', 'Penetration', 'Penetration', 'DoS', 'DoS', 'Exploit', 'DoS', 'DoS', 'Other', 'Other', 'Other', 'BruteForce', 'Penetration', 'Exploit', 'DoS', 'Penetration', 'Exploit', 'Other', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'Other', 'DoS', 'DoS', 'Exploit', 'Penetration', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'BruteForce', 'BruteForce', 'Penetration', 'Exploit', 'Exploit', 'Penetration', 'DoS', 'Penetration', 'DoS', 'Exploit', 'Penetration', 'BruteForce', 'Penetration', 'Exploit', 'Exploit', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'Exploit', 'BruteForce', 'DoS', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'Penetration', 'BruteForce', 'Exploit', 'Exploit', 'DoS', 'Exploit', 'DoS', 'Exploit', 'DoS', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'Exploit', 'BruteForce', 'DoS', 'BruteForce', 'Penetration', 'Other', 'Penetration', 'DoS', 'Exploit', 'DoS', 'Penetration', 'BruteForce', 'Other', 'DoS', 'DoS', 'BruteForce', 'DoS', 'Other', 'Other', 'BruteForce', 'Exploit', 'Exploit', 'Other', 'Exploit', 'DoS', 'Penetration', 'Penetration', 'DoS', 'DoS', 'Exploit', 'BruteForce', 'Other', 'DoS', 'Exploit', 'Penetration', 'BruteForce', 'Other', 'Exploit', 'BruteForce', 'DoS', 'DoS', 'Penetration', 'Other', 'DoS', 'DoS', 'BruteForce', 'Penetration', 'Exploit', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'DoS', 'DoS', 'DoS', 'DoS', 'Penetration', 'BruteForce', 'BruteForce', 'Penetration', 'Penetration', 'Penetration', 'BruteForce', 'Other', 'DoS', 'DoS', 'Penetration', 'DoS', 'DoS', 'DoS', 'Exploit', 'DoS', 'Penetration', 'BruteForce', 'BruteForce', 'Penetration', 'DoS', 'Exploit', 'BruteForce', 'DoS', 'DoS', 'DoS', 'BruteForce', 'Penetration', 'Penetration', 'Exploit', 'Other', 'Exploit', 'DoS', 'BruteForce', 'Penetration', 'BruteForce', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'Exploit', 'BruteForce', 'Other', 'DoS', 'DoS', 'DoS', 'Other', 'DoS', 'Exploit', 'Exploit', 'Other', 'DoS', 'DoS', 'DoS', 'DoS', 'Exploit', 'DoS', 'BruteForce', 'BruteForce', 'DoS', 'DoS', 'Exploit', 'Other', 'DoS', 'DoS', 'Exploit', 'Exploit', 'Penetration', 'BruteForce', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'DoS', 'DoS', 'Penetration', 'BruteForce', 'Other', 'DoS', 'Other', 'Exploit', 'BruteForce', 'Other', 'DoS', 'Exploit', 'BruteForce', 'BruteForce', 'DoS', 'Penetration', 'Exploit', 'DoS', 'Penetration', 'DoS', 'DoS', 'Exploit', 'DoS', 'Other', 'DoS', 'Penetration', 'DoS', 'Exploit', 'DoS', 'BruteForce', 'BruteForce', 'Penetration', 'BruteForce', 'Penetration', 'DoS', 'Penetration', 'BruteForce', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'BruteForce', 'BruteForce', 'Penetration', 'Other', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'Penetration', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'DoS', 'Other', 'DoS', 'BruteForce', 'Other', 'DoS', 'Exploit', 'Exploit', 'Penetration', 'BruteForce', 'Penetration', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'DoS', 'Other', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'BruteForce', 'BruteForce', 'Exploit', 'Penetration', 'DoS', 'Penetration', 'Exploit', 'Other', 'Penetration', 'Penetration', 'Exploit', 'DoS', 'DoS', 'DoS', 'Exploit', 'Other', 'DoS', 'DoS', 'BruteForce', 'Exploit', 'Exploit', 'Exploit', 'BruteForce', 'DoS', 'Penetration', 'DoS', 'DoS', 'Other', 'Other', 'Penetration', 'DoS', 'Exploit', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'BruteForce', 'Exploit', 'BruteForce', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'Penetration', 'DoS', 'BruteForce', 'Exploit', 'Exploit', 'BruteForce', 'DoS', 'Other', 'Exploit', 'DoS', 'Penetration', 'DoS', 'DoS', 'DoS', 'Other', 'Penetration', 'DoS', 'Other', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'DoS', 'Exploit', 'DoS', 'DoS', 'Penetration', 'Exploit', 'BruteForce', 'DoS', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'BruteForce', 'Penetration', 'BruteForce', 'Exploit', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'Exploit', 'Exploit', 'DoS', 'Exploit', 'BruteForce', 'Penetration', 'DoS', 'Penetration', 'Other', 'Penetration', 'Penetration', 'BruteForce', 'DoS', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'Penetration', 'DoS', 'Exploit', 'Exploit', 'Penetration', 'Other', 'Exploit', 'Penetration', 'Penetration', 'Exploit', 'DoS', 'Exploit', 'Penetration', 'Exploit', 'Other', 'Penetration', 'Penetration', 'Penetration', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'Penetration', 'Penetration', 'Exploit', 'BruteForce', 'Exploit', 'Other', 'Other', 'Exploit', 'BruteForce', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'DoS', 'BruteForce', 'Other', 'Other', 'DoS', 'Exploit', 'DoS', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'Penetration', 'DoS', 'Penetration', 'Other', 'DoS', 'BruteForce', 'Penetration', 'BruteForce', 'BruteForce', 'Penetration', 'BruteForce', 'DoS', 'BruteForce', 'BruteForce', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'Exploit', 'Penetration', 'Exploit', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'BruteForce', 'Penetration', 'Penetration', 'Other', 'Other', 'DoS', 'DoS', 'DoS', 'Penetration', 'Other', 'Penetration', 'Exploit', 'Exploit', 'Exploit', 'BruteForce', 'Exploit', 'Other', 'BruteForce', 'Other', 'Penetration', 'Penetration', 'Penetration', 'Exploit', 'Exploit', 'BruteForce', 'Penetration', 'Penetration', 'Other', 'Exploit', 'DoS', 'DoS', 'DoS', 'DoS', 'BruteForce', 'DoS', 'Other', 'BruteForce', 'DoS', 'Other', 'DoS', 'Exploit', 'Other', 'Exploit', 'DoS', 'Exploit', 'Exploit', 'DoS', 'DoS', 'Exploit', 'Other', 'Exploit', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'Exploit', 'DoS', 'Penetration', 'DoS', 'DoS', 'Penetration', 'Penetration', 'Penetration', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'BruteForce', 'DoS', 'Other', 'Exploit', 'Penetration', 'DoS', 'Exploit', 'Penetration', 'Exploit', 'BruteForce', 'Other', 'Exploit', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'Penetration', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'DoS', 'DoS', 'DoS', 'DoS', 'BruteForce', 'DoS', 'BruteForce', 'Exploit', 'Penetration', 'Exploit', 'BruteForce', 'Exploit', 'Penetration', 'Exploit', 'Other', 'Exploit', 'DoS', 'Penetration', 'BruteForce', 'BruteForce', 'BruteForce', 'Exploit', 'DoS', 'BruteForce', 'Exploit', 'DoS', 'Exploit', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'BruteForce', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'Penetration', 'Penetration', 'BruteForce', 'Exploit', 'BruteForce', 'Exploit', 'Penetration', 'Penetration', 'DoS', 'DoS', 'Penetration', 'Exploit', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'BruteForce', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'Exploit', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'Penetration', 'Exploit', 'BruteForce', 'DoS', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'DoS', 'Exploit', 'DoS', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'BruteForce', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'Other', 'BruteForce', 'BruteForce', 'DoS', 'BruteForce', 'Exploit', 'DoS', 'Penetration', 'DoS', 'Exploit', 'BruteForce', 'DoS', 'Exploit', 'Penetration', 'DoS', 'Exploit', 'DoS', 'BruteForce', 'Penetration', 'Penetration', 'BruteForce', 'BruteForce', 'DoS', 'BruteForce', 'DoS', 'DoS', 'Exploit', 'Exploit', 'Exploit', 'Penetration', 'DoS', 'DoS', 'DoS', 'DoS', 'Penetration', 'DoS', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'BruteForce', 'BruteForce', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'Penetration', 'DoS', 'DoS', 'DoS', 'Penetration', 'BruteForce', 'DoS', 'Penetration', 'Exploit', 'Exploit', 'DoS', 'Penetration', 'BruteForce', 'Exploit', 'Penetration', 'Exploit', 'Exploit', 'Penetration', 'BruteForce', 'Penetration', 'Exploit', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'Penetration', 'BruteForce', 'DoS', 'DoS', 'Other', 'Exploit', 'DoS', 'Exploit', 'Exploit', 'Penetration', 'BruteForce', 'BruteForce', 'Penetration', 'Penetration', 'DoS', 'DoS', 'Other', 'Exploit', 'DoS', 'DoS', 'DoS', 'Exploit', 'Exploit', 'Exploit', 'Penetration', 'Penetration', 'BruteForce', 'DoS', 'DoS', 'BruteForce', 'BruteForce', 'Penetration', 'BruteForce', 'Penetration', 'BruteForce', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'Other', 'Penetration', 'DoS', 'Exploit', 'DoS', 'Other', 'DoS', 'DoS', 'DoS', 'Penetration', 'Exploit', 'Penetration', 'Penetration', 'Exploit', 'BruteForce', 'BruteForce', 'DoS', 'BruteForce', 'DoS', 'BruteForce', 'Penetration', 'Penetration', 'Penetration', 'BruteForce', 'BruteForce', 'DoS', 'Other', 'DoS', 'Exploit', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'Exploit', 'DoS', 'DoS', 'Other', 'DoS', 'BruteForce', 'Exploit', 'DoS', 'Penetration', 'Exploit', 'Penetration', 'BruteForce', 'DoS', 'BruteForce', 'BruteForce', 'BruteForce', 'Penetration', 'DoS', 'Exploit', 'DoS', 'DoS', 'DoS', 'Exploit', 'Exploit', 'Penetration', 'DoS', 'Exploit', 'BruteForce', 'DoS', 'DoS', 'BruteForce', 'DoS', 'DoS', 'Other', 'BruteForce', 'DoS', 'Exploit', 'Penetration', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'Exploit', 'Penetration', 'DoS', 'BruteForce', 'DoS', 'BruteForce', 'Exploit', 'Exploit', 'Exploit', 'DoS', 'Penetration', 'Penetration', 'BruteForce', 'DoS', 'DoS', 'DoS', 'DoS', 'BruteForce', 'Penetration', 'Exploit', 'Penetration', 'Penetration', 'Exploit', 'DoS', 'BruteForce', 'Exploit', 'Other', 'Other', 'Penetration', 'DoS', 'BruteForce', 'Other', 'Penetration', 'Penetration', 'BruteForce', 'BruteForce', 'Other', 'BruteForce', 'Exploit', 'Exploit', 'DoS', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'BruteForce', 'BruteForce', 'Penetration', 'BruteForce', 'Penetration', 'Penetration', 'Penetration', 'DoS', 'BruteForce', 'Penetration', 'Exploit', 'DoS', 'Exploit', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'DoS', 'Other', 'Penetration', 'Penetration', 'BruteForce', 'Penetration', 'DoS', 'Exploit', 'Exploit', 'Penetration', 'Exploit', 'Exploit', 'Exploit', 'Other', 'Exploit', 'Other', 'Penetration', 'Penetration', 'Exploit', 'Other', 'Penetration', 'BruteForce', 'BruteForce', 'BruteForce', 'DoS', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'Other', 'Exploit', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'DoS', 'BruteForce', 'BruteForce', 'Penetration', 'Other', 'Penetration', 'BruteForce', 'DoS', 'DoS', 'Penetration', 'Penetration', 'Other', 'BruteForce', 'Penetration', 'BruteForce', 'Exploit', 'Exploit', 'DoS', 'Exploit', 'DoS', 'DoS', 'Other', 'DoS', 'Exploit', 'Penetration', 'BruteForce', 'Exploit', 'Other', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'Other', 'DoS', 'Penetration', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'DoS', 'DoS', 'DoS', 'BruteForce', 'Penetration', 'BruteForce', 'BruteForce', 'BruteForce', 'Other', 'DoS', 'DoS', 'Exploit', 'DoS', 'Exploit', 'DoS', 'Exploit', 'Other', 'Penetration', 'Penetration', 'BruteForce', 'Exploit', 'Penetration', 'DoS', 'BruteForce', 'BruteForce', 'Other', 'Exploit', 'DoS', 'Penetration', 'Exploit', 'Penetration', 'BruteForce', 'DoS', 'Penetration', 'Exploit', 'Penetration', 'Exploit', 'BruteForce', 'Other', 'Penetration', 'Other', 'DoS', 'Penetration', 'Penetration', 'Penetration', 'BruteForce', 'BruteForce', 'Penetration', 'BruteForce', 'DoS', 'Exploit', 'Other', 'DoS', 'BruteForce', 'Penetration', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'DoS', 'DoS', 'Exploit', 'DoS', 'DoS', 'Penetration', 'Exploit', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'DoS', 'DoS', 'Exploit', 'DoS', 'DoS', 'DoS', 'Penetration', 'Exploit', 'Exploit', 'Exploit', 'Penetration', 'Penetration', 'DoS', 'DoS', 'Penetration', 'Exploit', 'Exploit', 'BruteForce', 'BruteForce', 'Penetration', 'Other', 'Other', 'Penetration', 'Other', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'Penetration', 'BruteForce', 'Other', 'Exploit', 'Penetration', 'DoS', 'BruteForce', 'Exploit', 'DoS', 'Penetration', 'DoS', 'Penetration', 'Exploit', 'Penetration', 'DoS', 'DoS', 'Other', 'Penetration', 'BruteForce', 'Exploit', 'Exploit', 'Penetration', 'Exploit', 'DoS', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'DoS', 'BruteForce', 'BruteForce', 'Exploit', 'DoS', 'Other', 'DoS', 'Penetration', 'Other', 'Other', 'DoS', 'DoS', 'DoS', 'Penetration', 'DoS', 'Penetration', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'Exploit', 'Exploit', 'Exploit', 'DoS', 'Penetration', 'Other', 'DoS', 'BruteForce', 'BruteForce', 'Penetration', 'DoS', 'Exploit', 'DoS', 'BruteForce', 'DoS', 'BruteForce', 'BruteForce', 'BruteForce', 'DoS', 'BruteForce', 'Exploit', 'BruteForce', 'Exploit', 'BruteForce', 'Penetration', 'BruteForce', 'Exploit', 'Penetration', 'DoS', 'Exploit', 'Other', 'Penetration', 'DoS', 'Exploit', 'BruteForce', 'Exploit', 'DoS', 'Penetration', 'DoS', 'Exploit', 'DoS', 'Penetration', 'DoS', 'DoS', 'Exploit', 'Other', 'Exploit', 'BruteForce', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'Penetration', 'BruteForce', 'Exploit', 'Other', 'DoS', 'Penetration', 'DoS', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'Penetration', 'Other', 'Other', 'BruteForce', 'Exploit', 'DoS', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'BruteForce', 'BruteForce', 'BruteForce', 'DoS', 'DoS', 'Exploit', 'Exploit', 'Penetration', 'Penetration', 'Penetration', 'Exploit', 'Exploit', 'BruteForce', 'BruteForce', 'DoS', 'DoS', 'Exploit', 'DoS', 'Exploit', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'BruteForce', 'BruteForce', 'Exploit', 'Penetration', 'BruteForce', 'Exploit', 'BruteForce', 'Other', 'BruteForce', 'Penetration', 'DoS', 'BruteForce', 'BruteForce', 'Exploit', 'BruteForce', 'DoS', 'DoS', 'Penetration', 'DoS', 'BruteForce', 'DoS', 'DoS', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'BruteForce', 'DoS', 'BruteForce', 'Exploit', 'Exploit', 'Penetration', 'DoS', 'BruteForce', 'DoS', 'Penetration', 'Penetration', 'Exploit', 'DoS', 'Exploit', 'DoS', 'DoS', 'Penetration', 'DoS', 'Penetration', 'Penetration', 'Penetration', 'DoS', 'Exploit', 'DoS', 'Exploit', 'Penetration', 'DoS', 'Exploit', 'DoS', 'BruteForce', 'BruteForce', 'Penetration', 'DoS', 'DoS', 'Exploit', 'DoS', 'Exploit', 'DoS', 'DoS', 'BruteForce', 'DoS', 'Exploit', 'DoS', 'Other', 'DoS', 'Exploit', 'Exploit']\n",
            "<built-in method tolist of numpy.ndarray object at 0x7fb36be9b090>\n",
            "[[271   1   3   1   3]\n",
            " [  0 375  47   1   1]\n",
            " [  1  11 247   2   4]\n",
            " [  8  11   0  75   7]\n",
            " [  0   3   0   0 278]]\n",
            "[[271   1   3   1   3]\n",
            " [  0 375  47   1   1]\n",
            " [  1  11 247   2   4]\n",
            " [  8  11   0  75   7]\n",
            " [  0   3   0   0 278]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 6000x6000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[75  0  0  1  3  4  3  0  0  7  0  0  6  2  0]\n",
            " [ 0 93  0  0  0  0  3  0  0  0  0  0  0  0  0]\n",
            " [ 1  0 88  0  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 33  1  0  9  0 47  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 47  0 32  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 75  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0 75  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 97  0  0  0  0  0  0  0]\n",
            " [ 0  1  0 10  0  0  1  0 80  2  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 98  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 11 76  0  0  0  0]\n",
            " [ 2  0  0  0  0  0  0  0  0  1  0 87  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  3  0  0 87  0  0]\n",
            " [ 1  0  0  0  0  0  1  0  1  0  0  0  0 87  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  1 79]]\n",
            "[[75  0  0  1  3  4  3  0  0  7  0  0  6  2  0]\n",
            " [ 0 93  0  0  0  0  3  0  0  0  0  0  0  0  0]\n",
            " [ 1  0 88  0  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 33  1  0  9  0 47  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 47  0 32  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 75  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 14  0 75  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 97  0  0  0  0  0  0  0]\n",
            " [ 0  1  0 10  0  0  1  0 80  2  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 98  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 11 76  0  0  0  0]\n",
            " [ 2  0  0  0  0  0  0  0  0  1  0 87  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  3  0  0 87  0  0]\n",
            " [ 1  0  0  0  0  0  1  0  1  0  0  0  0 87  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  1 79]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 6000x6000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Level\tf1_macro\t\tf1_micro\t\tf1_weighted\t\tf1_hierarchical\n",
            "\n",
            "1\t0.9119314934219162\t0.922962962962963\t0.9224151957157948\t0.9486349477798816\n",
            "\n",
            "2\t0.8675759637355293\t0.8718518518518519\t0.8680588581810774\t0.9089387033764302\n",
            "\n",
            "Ordinary Hier Layer 1: 0.9486349477798816\n",
            "Ordinary Hier Layer 2: 0.9089387033764302\n"
          ]
        }
      ],
      "source": [
        "def unique(list1):\n",
        "    x = np.array(list1)\n",
        "    return (np.unique(x).tolist)\n",
        "\n",
        "# print(y_test)\n",
        "# print(predictions)\n",
        "coarse_ground_truth = []\n",
        "coarse_predictions = []\n",
        "\n",
        "fine_ground_truth = []\n",
        "fine_predictions = []\n",
        "\n",
        "for i in range(0,len(y_test)):\n",
        "  coarse_ground_truth.append(y_test[i][0])\n",
        "  coarse_predictions.append(predictions[i][0])\n",
        "  fine_ground_truth.append(y_test[i][1])\n",
        "  fine_predictions.append(predictions[i][1])\n",
        "print(coarse_ground_truth)\n",
        "cm = confusion_matrix(coarse_ground_truth,coarse_predictions)\n",
        "labels = unique(coarse_ground_truth)\n",
        "print(cm)\n",
        "if(LCPPN):\n",
        "  plot_cm_thetahier(cm,'Hierarchical MLP (LCPPN) \\n Targeted JSMA \\n Coarse Labels\\n', coarse_ground_truth, 'ConfusionMatrix-Hier-LCPPN-MLPCoarse-TARGETED-JSMA.png')\n",
        "\n",
        "  cm = confusion_matrix(fine_ground_truth,fine_predictions)\n",
        "  print(cm)\n",
        "  plot_cm_theta(cm,'Hierarchical MLP (LCPPN) \\n Targeted JSMA \\n Fine Labels\\n','ConfusionMatrix-Hier-LCPPN-MLPFine-TARGETED-JSMA.png')\n",
        "elif(LCPN):\n",
        "  plot_cm_thetahier(cm,'Hierarchical MLP (LCPN) \\n Targeted JSMA \\n Coarse Labels\\n', coarse_ground_truth, 'ConfusionMatrix-Hier-LCPN-MLPCoarse-TARGETED-JSMA.png')\n",
        "\n",
        "  cm = confusion_matrix(fine_ground_truth,fine_predictions)\n",
        "  print(cm)\n",
        "  plot_cm_theta(cm,'Hierarchical MLP (LCPN) \\n Targeted JSMA \\n Fine Labels\\n','ConfusionMatrix-Hier-LCPN-MLPFine-TARGETED-JSMA.png')\n",
        "elif(LCPL): \n",
        "  plot_cm_thetahier(cm,'Hierarchical MLP (LCPL) \\n Targeted JSMA \\n Coarse Labels\\n', coarse_ground_truth, 'ConfusionMatrix-Hier-LCPL-MLPCoarse-TARGETED-JSMA.png')\n",
        "\n",
        "  cm = confusion_matrix(fine_ground_truth,fine_predictions)\n",
        "  print(cm)\n",
        "  plot_cm_theta(cm,'Hierarchical MLP (LCPL) \\n Targeted JSMA \\n Fine Labels\\n','ConfusionMatrix-Hier-LCPL-MLPFine-TARGETED-JSMA.png')\n",
        "# Compute metrics\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from hiclass.metrics import f1\n",
        "\n",
        "# print(y_test.shape)\n",
        "\n",
        "# print(y_test[0])\n",
        "# print(y_test[1])\n",
        "\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "# print(y_test)\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "\n",
        "# print(y_test)\n",
        "# print(predictions[0][0])\n",
        "# # \n",
        "# # print(y_test[:, col])\n",
        "# print(predictions[:, col])\n",
        "# predictions = predictions.reshape(113,2)\n",
        "# print(predictions)\n",
        "\n",
        "# print(predictions_df[0])\n",
        "# print(y_test_df[0])\n",
        "# print(predictions_df[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Level\\tf1_macro\\t\\tf1_micro\\t\\tf1_weighted\\t\\tf1_hierarchical\\n\")\n",
        "for col in range(2):\n",
        "    f1_macro = f1_score(y_test_df[col], predictions_df[col], average=\"macro\")\n",
        "    f1_micro = f1_score(y_test_df[col], predictions_df[col], average=\"micro\")\n",
        "    f1_weighted = f1_score(y_test_df[col], predictions_df[col], average=\"weighted\")\n",
        "    f1_hierarchical = f1(y_test_df[col], predictions_df[col])\n",
        "    print(f\"{col + 1}\\t{f1_macro}\\t{f1_micro}\\t{f1_weighted}\\t{f1_hierarchical}\\n\")\n",
        "\n",
        "HierMLPNormalTrafficF1 = f1(y_test_df[0], predictions_df[0])\n",
        "\n",
        "HierMLPNormalTrafficF1Layer1 = f1(y_test_df[0], predictions_df[0])\n",
        "HierMLPNormalTrafficF1Layer2 = f1(y_test_df[1], predictions_df[1])\n",
        "\n",
        "# print(HierMLPNormalTrafficF1)\n",
        "\n",
        "print(f\"Ordinary Hier Layer 1: {HierMLPNormalTrafficF1Layer1}\")\n",
        "print(f\"Ordinary Hier Layer 2: {HierMLPNormalTrafficF1Layer2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lHBcMS3cfaY4",
        "outputId": "a9cbaafe-c05d-4387-cfd0-f685b5f7382a"
      },
      "outputs": [
        {
          "ename": "SystemExit",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vaqH6vYKF5ie"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Train classifier\n",
        "pipeline.fit(x_train, y_train)\n",
        "\n",
        "# Load in the x_test_jsma numpy \n",
        "savename='x_test_jsma.npy'\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "filename=basedir+savename\n",
        "print(\"Reading file\")\n",
        "# x_test_jsma = np.load(filename)\n",
        "\n",
        "# Predict\n",
        "predictions = lcpn.predict(x_test_jsma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dd-4n1YvF_ja"
      },
      "outputs": [],
      "source": [
        "# Compute metrics for x_test_jsma\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from hiclass.metrics import f1\n",
        "\n",
        "# print(y_test.shape)\n",
        "\n",
        "# print(y_test[0])\n",
        "# print(y_test[1])\n",
        "\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "# print(y_test)\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "\n",
        "# print(y_test)\n",
        "# print(predictions[0][0])\n",
        "# # \n",
        "# # print(y_test[:, col])\n",
        "# print(predictions[:, col])\n",
        "# predictions = predictions.reshape(113,2)\n",
        "# print(predictions)\n",
        "\n",
        "# print(predictions_df[0])\n",
        "# print(y_test_df[0])\n",
        "# print(predictions_df[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Level\\tf1_macro\\t\\tf1_micro\\t\\tf1_weighted\\t\\tf1_hierarchical\\n\")\n",
        "for col in range(2):\n",
        "    f1_macro = f1_score(y_test_df[col], predictions_df[col], average=\"macro\")\n",
        "    f1_micro = f1_score(y_test_df[col], predictions_df[col], average=\"micro\")\n",
        "    f1_weighted = f1_score(y_test_df[col], predictions_df[col], average=\"weighted\")\n",
        "    f1_hierarchical = f1(y_test_df[col], predictions_df[col])\n",
        "    print(f\"{col + 1}\\t{f1_macro}\\t{f1_micro}\\t{f1_weighted}\\t{f1_hierarchical}\\n\")\n",
        "\n",
        "HierMLPAdversarialF1 = f1(y_test_df[0], predictions_df[0])\n",
        "\n",
        "HierMLPAdversarialF1Layer1 = f1(y_test_df[0], predictions_df[0])\n",
        "HierMLPAdversarialF1Layer2 = f1(y_test_df[1], predictions_df[1])\n",
        "\n",
        "print(f\"JSMA Hier Layer 1: {HierMLPAdversarialF1Layer1}\")\n",
        "print(f\"JSMA Hier Layer 2: {HierMLPAdversarialF1Layer2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0HnYYBykKTXF"
      },
      "outputs": [],
      "source": [
        "# Plot F1-Scores for Original and Hierarchical models\n",
        "\n",
        "# models =['MLP', 'Hierarchical MLP']\n",
        "\n",
        "# names=[]\n",
        "# conditions = []\n",
        "# f1scores = []\n",
        "\n",
        "\n",
        "# f1scores.append()\n",
        "\n",
        "print(HierMLPNormalTrafficF1,\n",
        "      HierMLPAdversarialF1)\n",
        "\n",
        "\n",
        "# print(orig_df)\n",
        "# print(adversarial_df)\n",
        "print(conditions)\n",
        "conditions = []\n",
        "conditions.append('Ordinary')\n",
        "conditions.append('Ordinary')\n",
        "conditions.append('Adversarial')\n",
        "conditions.append('Adversarial')\n",
        "\n",
        "print(conditions)\n",
        "if(LCPPN):\n",
        "  new_row = {'F1-Score' : HierMLPNormalTrafficF1, 'Model Name': 'Hierarchical MLP (LCPPN)'}\n",
        "elif(LCPN):\n",
        "  new_row = {'F1-Score' : HierMLPNormalTrafficF1, 'Model Name': 'Hierarchical MLP (LCPN)'}\n",
        "elif(LCPL):\n",
        "  new_row = {'F1-Score' : HierMLPNormalTrafficF1, 'Model Name': 'Hierarchical MLP (LCPL)'}\n",
        "orig_df = orig_df.append(new_row,ignore_index=True)\n",
        "# conditions.append('Ordinary')\n",
        "\n",
        "\n",
        "if(LCPPN):\n",
        "  new_row = {'F1-Score' : HierMLPAdversarialF1, 'Model Name': 'Hierarchical MLP (LCPPN)'}\n",
        "elif(LCPN):\n",
        "  new_row = {'F1-Score' : HierMLPAdversarialF1, 'Model Name': 'Hierarchical MLP (LCPN)'}\n",
        "\n",
        "elif(LCPL):\n",
        "  new_row = {'F1-Score' : HierMLPAdversarialF1, 'Model Name': 'Hierarchical MLP (LCPL)'}\n",
        "\n",
        "\n",
        "adversarial_df = adversarial_df.append(new_row,ignore_index=True)\n",
        "# conditions.append('Adversarial')\n",
        "\n",
        "\n",
        "group_frames = [orig_df,adversarial_df]\n",
        "group_df = pd.concat(group_frames)\n",
        "group_df['Conditions'] = conditions\n",
        "group_df[['F1-Score']] = group_df[['F1-Score']].apply(pd.to_numeric)\n",
        "print(group_df)\n",
        "group_df = group_df.round(decimals=2)\n",
        "# group_df = group_df.sort_values('Model Name')\n",
        "\n",
        "print('<<')\n",
        "print(group_df)\n",
        "\n",
        "\n",
        "print(f\"Ordinary Hier Layer 1: {HierMLPNormalTrafficF1Layer1}\")\n",
        "print(f\"Ordinary Hier Layer 2: {HierMLPNormalTrafficF1Layer2}\")\n",
        "print(\"\")\n",
        "print(f\"JSMA Hier Layer 1: {HierMLPAdversarialF1Layer1}\")\n",
        "print(f\"JSMA Hier Layer 2: {HierMLPAdversarialF1Layer2}\")\n",
        "\n",
        "print(\"<<\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#set seaborn plotting aesthetics\n",
        "sns.set(style='white')\n",
        "sns.set_context(\"paper\")\n",
        "sns.color_palette(\"dark:salmon_r\", as_cmap=True)\n",
        "\n",
        "#create grouped bar chart hue_order={'Ordinary','Adversarial'}\n",
        "bar = sns.barplot(x='Model Name', y='F1-Score', hue='Conditions',  data=group_df)\n",
        "            # palette=['purple', 'steelblue'])\n",
        "            # palette=['orange', 'red'])\n",
        "\n",
        "\n",
        "\n",
        "bar.grid(b=True, which='major', color='black', linewidth=0.075)\n",
        "bar.grid(b=True, which='minor', color='black', linewidth=0.075)\n",
        "# Define some hatches\n",
        "hatches = ['/', '/', '//', '//'] # , 'x', '\\\\', '*', 'o']\n",
        "\n",
        "# Loop over the bars\n",
        "for i,thisbar in enumerate(bar.patches):\n",
        "    # Set a different hatch for each bar\n",
        "    thisbar.set_hatch(hatches[i])\n",
        "\n",
        "#add overall title\n",
        "if(LCPPN):\n",
        "  plt.title('Improvement of F1-Score Macro Avg\\nStandard MLP Vs. Hierarchical (LCPPN) MLP', fontsize=16)\n",
        "elif(LCPN):\n",
        "  plt.title('Improvement of F1-Score Macro Avg\\nStandrad MLP Vs. Hierarchical (LCPN) MLP ', fontsize=16)\n",
        "elif(LCPL):\n",
        "  plt.title('Improvement of F1-Score Macro Avg\\nStandard MLP Vs. Hierarchical (LCPL) MLP ', fontsize=16)\n",
        "\n",
        "\n",
        "#add axis titles\n",
        "plt.xlabel('Model Name')\n",
        "plt.ylabel('F1-Score Macro Avg')\n",
        "plt.ylim(0.0,1.05)\n",
        "\n",
        "\n",
        "#rotate x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "# Put the legend out of the figure\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "#save the plot\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "if(LCPPN):\n",
        "  savename='ComparisonMLPHier-LCPPN.png'\n",
        "elif(LCPN):\n",
        "  savename='ComparisonMLPHier-LCPN.png'\n",
        "elif(LCPL):\n",
        "  savename='ComparisonMLPHier-LCPL.png'\n",
        "filename=basedir+savename\n",
        "plt.savefig(filename,dpi=300,bbox_inches='tight')\n",
        "group_df.to_csv(filename+'.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_fqHFS2CVSFH"
      },
      "outputs": [],
      "source": [
        "#plot_cl binary_classifier = tf.keras.Sequential([\n",
        "#         tf.keras.layers.Dense(128, activation='relu', input_shape=[x_train.shape[1]]),\n",
        "#         tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "# ])\n",
        "\n",
        "# binary_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# keras_binary_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(lambda:binary_classifier)\n",
        "# keras_binary_clf._estimator_type = \"classifier\"\n",
        "\n",
        "# binary_ovr = (keras_binary_clf)\n",
        "\n",
        "# binary_ovr.fit(x_train,y_train)\n",
        "\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "\n",
        "# XGB = XGBClassifier()\n",
        "\n",
        "# RF = RandomForestClassifier(bootstrap=True, max_features='auto', n_estimators=140, max_depth=None, \n",
        "#                             min_samples_split=5, random_state=7)\n",
        "\n",
        "# RF.fit(x_train, y_train)\n",
        "\n",
        "# XGB.fit(x_train, y_train)\n",
        "\n",
        "# solo_rf_predictions = RF.predict(x_test)\n",
        "# cm = confusion_matrix(y_test,solo_rf_predictions)\n",
        "\n",
        "# plot_cm(cm,'Multiclass Random Forest (Original)','only_rf.png')\n",
        "\n",
        "# solo_rf_jsma_predictions = RF.predict(x_test_jsma)\n",
        "\n",
        "# cm = confusion_matrix(y_test,solo_rf_jsma_predictions)\n",
        "\n",
        "# plot_cm(cm,'Multiclass Random Forest (JSMA)','only_rf.png')\n",
        "\n",
        "# solo_xgb_predictions = XGB.predict(x_test)\n",
        "\n",
        "# cm = confusion_matrix(y_test,solo_xgb_predictions)\n",
        "\n",
        "# plot_cm(cm,'Multiclass XGB (Original)','only_xgb.png')\n",
        "\n",
        "# solo_xgb_jsma_predictions = XGB.predict(x_test_jsma)\n",
        "\n",
        "# cm = confusion_matrix(y_test,solo_xgb_jsma_predictions)\n",
        "\n",
        "# plot_cm(cm,'Multiclass XGB (JSMA)','only_xgb_jsma.png')\n",
        "\n",
        "\n",
        "# # Extract single tree\n",
        "# estimator = RF.estimators_[5]\n",
        "\n",
        "# from sklearn.tree import export_graphviz\n",
        "# # Export as dot file\n",
        "# basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "# print(basedir)\n",
        "# export_graphviz(estimator, out_file=basedir+'tree.dot', \n",
        "#                 feature_names = subset.columns,\n",
        "#                 class_names = outcome,\n",
        "#                 rounded = True, proportion = False, \n",
        "#                 precision = 2, filled = True)\n",
        "\n",
        "# # Convert to png using system command (requires Graphviz)\n",
        "# from subprocess import call\n",
        "# call(['dot', '-Tpng', basedir+'tree.dot', '-o', basedir+'tree.png', '-Gdpi=600'])\n",
        "\n",
        "# # Display in jupyter notebook\n",
        "# from IPython.display import Image\n",
        "# Image(filename = basedir+'tree.png')\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "print(models)\n",
        "\n",
        "eclf1 = VotingClassifier(\n",
        "    estimators = [\n",
        "                  ('Keras Model', keras_clf), \n",
        "                  ('NB', MultinomialNB()), \n",
        "                  ('kNN', KNeighborsClassifier(n_neighbors=10)),\n",
        "                  ('LogR', LogisticRegression()), \n",
        "                  ('SVC', SVC(C=10, gamma=0.001)),\n",
        "                  ('DT', tree.DecisionTreeClassifier()),\n",
        "                  ('RF', RandomForestClassifier(max_features=20, min_samples_split=5, n_estimators=170, n_jobs=2, random_state=7, verbose=True)),\n",
        "                  ('AdaB', AdaBoostClassifier()),\n",
        "                  ('XGBoost', XGBClassifier()),\n",
        "                  ('QDA', QuadraticDiscriminantAnalysis()),\n",
        "                  ('Histogram Based Boosting Classifier', HistGradientBoostingClassifier())\n",
        "                  \n",
        "                  \n",
        "                  # ('Multiclass', keras_clf),\n",
        "                  # ('OneVsRest', ovr)\n",
        "                  # #('RF', RF)\n",
        "\n",
        "                  # #('OneVsRest', binary_ovr)\n",
        "\n",
        "    ],voting='hard'\n",
        ")\n",
        "\n",
        "eclf1 = eclf1.fit(x_train, y_train)\n",
        "\n",
        "eclf2 = VotingClassifier(\n",
        "    estimators = [\n",
        "                  ('Keras Model', keras_clf), \n",
        "                  ('NB', MultinomialNB()), \n",
        "                  ('kNN', KNeighborsClassifier(n_neighbors=10)),\n",
        "                  ('LogR', LogisticRegression()), \n",
        "                  ('SVC', SVC(C=10, gamma=0.001,probability=True)),\n",
        "                  ('DT', tree.DecisionTreeClassifier()),\n",
        "                  ('RF', RandomForestClassifier(max_features=20, min_samples_split=5, n_estimators=170, n_jobs=2, random_state=7, verbose=True)),\n",
        "                  ('AdaB', AdaBoostClassifier()),\n",
        "                  ('XGBoost', XGBClassifier()),\n",
        "                  ('QDA', QuadraticDiscriminantAnalysis()),\n",
        "                  ('Histogram Based Boosting Classifier', HistGradientBoostingClassifier())\n",
        "                  \n",
        "                  \n",
        "                  # ('Multiclass', keras_clf),\n",
        "                  # ('OneVsRest', ovr)\n",
        "                  # #('RF', RF)\n",
        "\n",
        "                  # #('OneVsRest', binary_ovr)\n",
        "\n",
        "    ],voting='soft'\n",
        ")\n",
        "\n",
        "eclf2 = eclf2.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "eclf3 = VotingClassifier(\n",
        "    estimators = [\n",
        "                  # ('Keras Model', keras_clf), \n",
        "                  # ('Shallow Model', keras_shallow_clf),\n",
        "                  # ('Deeper Model', keras_deeper_clf),\n",
        "                  ('Dropout Model1', keras_dropout1_clf),\n",
        "                  ('Dropout Model2', keras_dropout2_clf),\n",
        "                  \n",
        "                  ('Dropout Model3', keras_dropout3_clf)\n",
        "\n",
        "                 ],voting='soft'\n",
        ")\n",
        "\n",
        "eclf4 = VotingClassifier(\n",
        "    estimators = [\n",
        "                  # ('Keras Model', keras_clf), \n",
        "                  ('V Model', keras_V_clf),\n",
        "                  ('A Model', keras_A_clf)\n",
        "                 ],voting='soft'\n",
        ")\n",
        "\n",
        "eclf3 = eclf3.fit(x_train, y_train)\n",
        "eclf4 = eclf4.fit(x_train, y_train)\n",
        "print()\n",
        "\n",
        "ensemble_hardvoting_predictions = eclf1.predict(x_test_jsma)\n",
        "cm = confusion_matrix(y_test, ensemble_hardvoting_predictions)\n",
        "plot_cm(cm,'Ensemble - HardVoting (JSMA)- Confusion Matrix','ConfusionMatrix-Ensemble-OvR-JSMA.png')\n",
        "plot_errors(cm,'Ensemble - HardVoting (JSMA) - Error Matrix','ErrorMatrix-Ensemble-OvR-JSMA.png')\n",
        "print(classification_report(y_test, ensemble_hardvoting_predictions))\n",
        "print_classification_report(ensemble_hardvoting_predictions, y_test, 'class_report_ensemble_hardvoting.tex', 'Ensemble Classification Report (Hard Voting)')\n",
        "\n",
        "ensemble_softvoting_predictions = eclf2.predict(x_test_jsma)\n",
        "cm = confusion_matrix(y_test, ensemble_softvoting_predictions)\n",
        "plot_cm(cm,'Ensemble - SoftVoting - Confusion Matrix','ConfusionMatrix-Ensemble-RF-JSMA.png')\n",
        "plot_errors(cm,'Ensemble - SoftVoting - Error Matrix','ErrorMatrix-Ensemble-RF-JSMA.png')\n",
        "print(classification_report(y_test, ensemble_softvoting_predictions))\n",
        "print_classification_report(ensemble_softvoting_predictions, y_test, 'class_report_ensemble_softvoting.tex', 'Ensemble Classification Report (Soft Voting)')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bFuLwRRaJ37M"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uJpEIs7DaC38"
      },
      "outputs": [],
      "source": [
        "ensemble_predictions = eclf2.predict(x_test_jsma)\n",
        "cm = confusion_matrix(y_test, ensemble_predictions)\n",
        "#cm = confusion_matrix(y_test,integer_predictions)\n",
        "\n",
        "print(cm)\n",
        "plt.matshow(cm, cmap=\"OrRd\" )\n",
        "plt.title('Ensemble - Original - Confusion Matrix', pad=150)\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "ax = plt.gca()\n",
        "from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "l_col_list = list(outcome)\n",
        "ax.set_xticklabels([''] + l_col_list, rotation=90)\n",
        "ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "savename='ConfusionMatrix-Ensemble-Original.png'\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "filename=basedir+savename\n",
        "plt.savefig(filename,dpi=300)\n",
        "plt.show()\n",
        "\n",
        "#Plot of errors\n",
        "row_sums = cm.sum(axis=1, keepdims=True)\n",
        "norm_cm = cm / row_sums\n",
        "\n",
        "np.fill_diagonal(norm_cm, 0)\n",
        "plt.matshow(norm_cm, cmap=\"OrRd\")\n",
        "plt.title('Ensemble - Original - Error Matrix', pad=150)\n",
        "\n",
        "plt.colorbar()\n",
        "ax = plt.gca()\n",
        "from matplotlib.ticker import MultipleLocator; ax.xaxis.set_major_locator(MultipleLocator(1)); ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "l_col_list = list(outcome)\n",
        "ax.set_xticklabels([''] + l_col_list,rotation=90)\n",
        "ax.set_yticklabels([''] + l_col_list)\n",
        "\n",
        "savename='ErrorMatrix-Ensemble-Original.png'\n",
        "basedir='mount/My Drive/Colab Notebooks/Figures/'\n",
        "filename=basedir+savename\n",
        "plt.savefig(filename,dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_qN2PoGX7SzE"
      },
      "outputs": [],
      "source": [
        "just_keras_predictions = keras_clf.predict(x_test_jsma)\n",
        "ensemble_predictions = eclf2.predict(x_test_jsma)\n",
        "ovr_predictions = ovr.predict(x_test_jsma)\n",
        "better_keras_predictions = eclf3.predict(x_test_jsma)\n",
        "opposites_keras_predictions = eclf4.predict(x_test_jsma)\n",
        "\n",
        "\n",
        "print(\"----------------- JUST KERAS ----------------------\")\n",
        "print(classification_report(\n",
        "        just_keras_predictions,y_test,\n",
        "        target_names=outcome,\n",
        "        labels=range(0,(len(outcome)))))\n",
        "\n",
        "\n",
        "print(\"----------------- OVR KERAS ----------------------\")\n",
        "print(classification_report(\n",
        "        ovr_predictions,y_test,\n",
        "        target_names=outcome,\n",
        "        labels=range(0,(len(outcome)))))\n",
        "# Ensemble with RF\n",
        "# print(classification_report(\n",
        "#         ensemble_predictions,y_test,\n",
        "#         target_names=outcome,\n",
        "#         labels=range(0,(len(outcome)))))\n",
        "\n",
        "print(\"----------------- BETTER KERAS ----------------------\")\n",
        "print(classification_report(\n",
        "        better_keras_predictions,y_test,\n",
        "        target_names=outcome,\n",
        "        labels=range(0,(len(outcome)))))\n",
        "\n",
        "print(\"----------------- OPPOSITES KERAS ----------------------\")\n",
        "print(classification_report(\n",
        "        opposites_keras_predictions,y_test,\n",
        "        target_names=outcome,\n",
        "        labels=range(0,(len(outcome)))))\n",
        "\n",
        "\n",
        "print_classification_report(ensemble_predictions,y_test,'ensemble_jsma_classification_report.tex','Ensemble (RF) Classification Report - JSMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dh9rMgD6vUsp"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "from lime import lime_tabular\n",
        "\n",
        "explainer = lime_tabular.LimeTabularExplainer(\n",
        "    training_data=np.array(x_train),\n",
        "    feature_names=subset.columns,\n",
        "    class_names=outcome,\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "print(len(x_test_jsma))\n",
        "list_of_labels = []\n",
        "set_of_labels = {}\n",
        "# for i in range(0,1):\n",
        "for i in range (0,len(x_test_jsma)):\n",
        "  exp_orig = explainer.explain_instance(\n",
        "      data_row=x_test[i], \n",
        "      predict_fn=eclf2.predict_proba,\n",
        "      top_labels=5, num_features=len(subset.columns)\n",
        "  )\n",
        "\n",
        "  exp_jsma = explainer.explain_instance(\n",
        "      data_row=x_test_jsma[i], \n",
        "      predict_fn=eclf2.predict_proba,\n",
        "      top_labels=5, num_features=len(subset.columns)\n",
        "  )\n",
        "\n",
        "  # exp_orig.show_in_notebook(show_table=True)\n",
        "  # exp_jsma.show_in_notebook(show_table=True)\n",
        "\n",
        "  print(y_test[i])\n",
        "  list_of_labels.append(str(y_test[i]))\n",
        "  \n",
        "  if((str(y_test[i]) not in set_of_labels)):\n",
        "    if(str(y_test[i]) not in ['5','9']):\n",
        "  \n",
        "      exp = exp_orig.as_list(label=y_test[i])\n",
        "      fig = plt.figure(figsize=(25,13))\n",
        "      vals = [x[1] for x in exp]\n",
        "      names = [x[0] for x in exp]\n",
        "      vals.reverse()\n",
        "      names.reverse()\n",
        "      colors = ['green' if x > 0 else 'red' for x in vals]\n",
        "      pos = np.arange(len(exp)) + .5\n",
        "      plt.barh(pos, vals, align='center', color=colors)\n",
        "      plt.yticks(pos, names)\n",
        "      if explainer.mode == \"classification\":\n",
        "        title = 'Local explanation for class %s (Original)' % explainer.class_names[y_test[i]]\n",
        "      else:\n",
        "        title = 'Local explanation'\n",
        "      plt.title(title)\n",
        "      savename='Lime-Explanation-Class-' + str(y_test[i]) + '-Original'\n",
        "      basedir='mount/My Drive/Colab Notebooks/Figures/Lime/'\n",
        "      filename=basedir+savename+'.png'\n",
        "      plt.savefig(filename,dpi=300)\n",
        "      exp_orig.save_to_file(basedir+savename+'.html')\n",
        "      print('Saved ' +str(filename))\n",
        "      plt.close\n",
        "      # plt.show\n",
        "\n",
        "\n",
        "      exp = exp_jsma.as_list(y_test[i])\n",
        "      fig = plt.figure(figsize=(25,13))\n",
        "      vals = [x[1] for x in exp]\n",
        "      names = [x[0] for x in exp]\n",
        "      vals.reverse()\n",
        "      names.reverse()\n",
        "      colors = ['green' if x > 0 else 'red' for x in vals]\n",
        "      pos = np.arange(len(exp)) + .5\n",
        "      plt.barh(pos, vals, align='center', color=colors)\n",
        "      plt.yticks(pos, names)\n",
        "      if explainer.mode == \"classification\":\n",
        "        title = 'Local explanation for class %s (JSMA)' % explainer.class_names[y_test[i]]\n",
        "      else:\n",
        "        title = 'Local explanation'\n",
        "      plt.title(title)\n",
        "      savename='Lime-Explanation-Class-' + str(y_test[i]) + '-JSMA'\n",
        "      basedir='mount/My Drive/Colab Notebooks/Figures/Lime/'\n",
        "      filename=basedir+savename+'.png'\n",
        "      plt.savefig(filename,dpi=300)\n",
        "      exp_jsma.save_to_file(basedir+savename+'.html')\n",
        "      print('Saved ' +str(filename))\n",
        "      # plt.show\n",
        "      plt.close\n",
        "\n",
        "      set_of_labels = set(list_of_labels)\n",
        "      print(set_of_labels)\n",
        "      print(\"How many labels:\" + str(len(set_of_labels)))\n",
        "    else:\n",
        "      print(\"No Example of \" + str(y_test[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yyk5KyjM0hkF"
      },
      "outputs": [],
      "source": [
        "# !pip install shap\n",
        "# import shap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# explainer = shap.KernelExplainer(model.predict,x_test)\n",
        "# shap_values = explainer.shap_values(x_test)\n",
        "\n",
        "# # explain first sample from test data\n",
        "# print(\"Kernel Explainer SHAP run time\", round(elapsed_time,3) , \" seconds. \", current_model[\"name\"])\n",
        "# print(\"SHAP expected value\", explainer.expected_value)\n",
        "# print(\"Model mean value\", clf.predict_proba(scaled_train_data).mean(axis=0))\n",
        "# print(\"Model prediction for test data\", clf.predict_proba(subsampled_test_data))\n",
        "# shap.initjs()\n",
        "# pred_ind = 0\n",
        "# shap.force_plot(explainer.expected_value[1], shap_values[1][0], subsampled_test_data[0], feature_names=subset.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pf329Mxxtjcq"
      },
      "outputs": [],
      "source": [
        "#parallel coords plot \n",
        "print(x_test)\n",
        "print(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ms0ROr2DwQ7v"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "!pip install cleverhans==3.1.0\n",
        "# Install bleeding edge version of cleverhans\n",
        "#!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
        "\n",
        "# Import the attack\n",
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "!pip freeze\n",
        "\n",
        "features = []\n",
        "accuracys = []\n",
        "mseerrors = []\n",
        "minmseerrors = []\n",
        "test_accuracys = []\n",
        "\n",
        "num_features = 59\n",
        "\n",
        "# Transform Objects to Digits\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "for column_name in df2.columns:\n",
        "        if df2[column_name].dtype == object:\n",
        "            print(df2[column_name])\n",
        "            df2[column_name] = le.fit_transform(df2[column_name])\n",
        "        else:\n",
        "            pass\n",
        " \n",
        "X = df2.iloc[:,0:num_features+1].values\n",
        "X = X.astype(int)\n",
        "\n",
        "numpydf2 = np.array(df2)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(numpydf2, Y_attack, test_size = 0.7, random_state = 42, stratify=Y_attack)\n",
        "\n",
        "print (\"X_Train:\", X_train.shape)\n",
        "print (\"X_Test:\", X_test.shape)\n",
        "print (\"Y_Train:\", Y_train.shape)\n",
        "print (\"Y_Test:\", Y_test.shape)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(np.unique(Y_class))),\n",
        "    tf.keras.layers.Activation(tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=10, validation_split=0.2)\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Number of features\\t  Test accuracy:')\n",
        "print(\"{}\\t{}\".format(num_features, test_acc))\n",
        "features.append(num_features+1)\n",
        "accuracys.append(test_acc)\n",
        "#print(\"{}\\t{}\".format(features,accuracys))\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n",
        "\n",
        "# Batch run on all test data\n",
        "\n",
        "CLASS_TO_CHANGE = 1 # 1 will make all true cases appear as false (DDoS -> Benign)\n",
        "\n",
        "#df2 = pd.DataFrame(min_max_scaler.fit_transform(subset), columns=subset.columns, index=subset.index)\n",
        "\n",
        "X_adv = np.zeros(X_test.shape)\n",
        "\n",
        "print (X_test.shape)\n",
        "headers = df2.columns[:80]\n",
        "printheaders =True\n",
        "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
        "print(Y_test[0])\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    current_class = Y_test[i]\n",
        "    #print(\"Class:\", current_class)\n",
        "    #print(X_test[0,:])\n",
        "    if current_class == 0:\n",
        "        example_vals = X_test[i, :]\n",
        "        example_labels = Y_test[i]\n",
        "        example_vals = tf.convert_to_tensor(example_vals.reshape((1, num_features)))\n",
        "        example_labels = np.reshape(example_labels, (1,)).astype('int64')\n",
        "        epsilon = 0.1\n",
        "        adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n",
        "        adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "\n",
        "        X_adv[i,:] = adv_example_untargeted_label\n",
        "        X_test[i,:] = adv_example_untargeted_label\n",
        "        #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n",
        "        #print(X_test[i,:])\n",
        "        #df2 = pd.DataFrame(min_max_scaler.fit_transform(subset), columns=subset.columns, index=subset.index)\n",
        "        ae_ddos_to_benign =pd.DataFrame(X_adv)\n",
        "        #print(subset.columns)\n",
        "        #, columns=subset.columns, index=subset.index\n",
        "        #print(subset.columns)\n",
        "        #if(printheaders):\n",
        "        #  outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/my_adversarial.csv', mode='a', header=headers)\n",
        "        #else: \n",
        "        #  outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/my_adversarial.csv', mode='a')\n",
        "        printheaders = False\n",
        "        #inverted.to_csv('mount/My Drive/Colab Notebooks/network_data/my_inverted.csv', mode='a', header=headers)\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e0c53As-30YA"
      },
      "outputs": [],
      "source": [
        "CLASS_TO_CHANGE = 0 # 0 will make all benign -> DDoS)\n",
        "\n",
        "X_adv = np.zeros(X_test.shape)\n",
        "\n",
        "#print (X_test.shape)\n",
        "#headers = df2.columns[:80]\n",
        "printheaders =True\n",
        "print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
        "print(Y_test[0])\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    current_class = Y_test[i]\n",
        "    #print(\"Class:\", current_class)\n",
        "    #print(X_test[0,:])\n",
        "    if current_class == 0:\n",
        "        example_vals = X_test[i, :]\n",
        "        example_labels = Y_test[i]\n",
        "        example_vals = tf.convert_to_tensor(example_vals.reshape((1, num_features)))\n",
        "        example_labels = np.reshape(example_labels, (1,)).astype('int64')\n",
        "        epsilon = 0.1\n",
        "        adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n",
        "        adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "\n",
        "        X_adv[i,:] = adv_example_untargeted_label\n",
        "        X_test[i,:] = adv_example_untargeted_label\n",
        "        #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n",
        "        #print(X_test[i,:])\n",
        "        #df2 = pd.DataFrame(min_max_scaler.fit_transform(subset), columns=subset.columns, index=subset.index)\n",
        "        ae_benign_to_ddos =pd.DataFrame(X_adv)\n",
        "        #print(subset.columns)\n",
        "        #, columns=subset.columns, index=subset.index\n",
        "        #print(subset.columns)\n",
        "        #if(printheaders):\n",
        "        #  outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/my_adversarial.csv', mode='a', header=headers)\n",
        "        #else: \n",
        "        #  outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/my_adversarial.csv', mode='a')\n",
        "        printheaders = False\n",
        "        #inverted.to_csv('mount/My Drive/Colab Notebooks/network_data/my_inverted.csv', mode='a', header=headers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caI_jYLMeeKO"
      },
      "source": [
        "# ViolinPlot of AEs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xNCxDaLoekBz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "ax = sns.violinplot(data=benign)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "ax.set_title(\"Violin Plot to show benign feature distributions\");\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "ax = sns.violinplot(data=ae_ddos_to_benign)\n",
        "ax.set_xticklabels(subset.columns, rotation=90);\n",
        "#ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "ax.set_title(\"Violin Plot to show Adversarial Example (DDoS -> BENIGN) feature distributions\");\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "ax = sns.violinplot(data=ae_benign_to_ddos)\n",
        "ax.set_xticklabels(subset.columns, rotation=90);\n",
        "#ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "ax.set_title(\"Violin Plot to show Adversarial Example (BENIGN -> DDoS) feature distributions\");\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "ax = sns.violinplot(data=ddos)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "ax.set_title(\"Violin Plot to show DDoS feature distributions\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1VqQhSr5AsB"
      },
      "source": [
        "### Extra: PCA decomposition to separate classes\n",
        "\n",
        "Given the high dimensionality of the data, what does the data look like if we perform dimensionality reduction? Can we better separate between the two classes? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "enRphWut5AsC"
      },
      "outputs": [],
      "source": [
        "from sklearn import decomposition\n",
        "pca = decomposition.PCA(n_components=2)\n",
        "X = pd.DataFrame(pca.fit_transform(df2.values), columns=['x', 'y'])\n",
        "X['Label'] = df[' Label']\n",
        "\n",
        "benignX = X[X['Label'] == outcome[0]]\n",
        "ddosX = X[X['Label'] == outcome[1]]\n",
        "\n",
        "plt.scatter(benignX['x'], benignX['y'])\n",
        "plt.scatter(ddosX['x'], ddosX['y'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9K5OVI5AsD"
      },
      "source": [
        "***Unfortunately not*** - this is not a great surprise, our violin plot shows overlap between the features of the two classes and there is no clear decision boundary that separates the two. PCA is quite poor when there is little variance in many features (as we have here) hence why the plot has artefacts where straight lines appear. Other methods like t-SNE and UMAP may perform better but at greater computational cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYC_YrGfECmD"
      },
      "source": [
        "#TSNE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rQqAzjN7EEXa"
      },
      "outputs": [],
      "source": [
        "TSNE_PLOT=False\n",
        "if(TSNE_PLOT):\n",
        "  from sklearn.manifold import TSNE\n",
        "  import time\n",
        "\n",
        "  time_start = time.time()\n",
        "  tsne = TSNE(n_components=2)\n",
        "  X = pd.DataFrame(tsne.fit_transform(df2.values), columns=['x', 'y'])\n",
        "  X['Label'] = df[' Label']\n",
        "\n",
        "  benignX = X[X['Label'] == outcome[0]]\n",
        "  ddosX = X[X['Label'] == outcome[1]]\n",
        "\n",
        "  plt.scatter(benignX['x'], benignX['y'])\n",
        "  plt.scatter(ddosX['x'], ddosX['y'])\n",
        "  print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "else:\n",
        "  print(\"Skipping TSNE Plot\")\n",
        "  print(\"Typical TSNE plot time: 54 Mins (3245 seconds)\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l73kKG_3HR9c"
      },
      "source": [
        "#UMAP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QGAy5PaVGnMQ"
      },
      "outputs": [],
      "source": [
        "DO_UMAP = False\n",
        "\n",
        "\n",
        "import time\n",
        "import umap.umap_ as umap\n",
        "\n",
        "if(DO_UMAP):\n",
        "\n",
        "  time_start = time.time()\n",
        "  X = pd.DataFrame(umap.fit_transform(df2.values), columns=['x', 'y'])\n",
        "  X['Label'] = df[' Label']\n",
        "\n",
        "  benignX = X[X['Label'] == outcome[0]]\n",
        "  ddosX = X[X['Label'] == outcome[1]]\n",
        "\n",
        "  plt.scatter(benignX['x'], benignX['y'])\n",
        "  plt.scatter(ddosX['x'], ddosX['y'])\n",
        "  print('UMAP done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "else: \n",
        "  print(\"Skipping UMAP Plot\")\n",
        "  print(\"Typical plot time: Unknown (>54 Mins?)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c2UL7GctrJaG"
      },
      "outputs": [],
      "source": [
        "# Here's an example of selecting all columns that contain the.phrase 'IAT'\n",
        "\n",
        "cols = 5\n",
        "\n",
        "df3 = df2[ df2.columns[ df2.columns.str.contains(\"IAT\") ] ]\n",
        "#df3 = df3.iloc[:,0:cols]\n",
        "\n",
        "df3[' Label'] = df2[' Label']\n",
        "\n",
        "\n",
        "samples = 1000\n",
        "benign3 = df3[df3[' Label'] == outcome[0]].iloc[0:samples,:]\n",
        "ddos3 = df3[df3[' Label'] == outcome[1]].iloc[0:samples,:]\n",
        "\n",
        "benignjust1 = df3[df3[' Label'] == outcome[0]].iloc[0:1,:]\n",
        "\n",
        "df3 = pd.concat([benign3, ddos3])\n",
        "df3\n",
        "\n",
        "ae_ddos_to_benign.columns = ddos.columns\n",
        "\n",
        "ae_ddos_to_benign[' Label'] =\"adv_x to appear benign\"\n",
        "\n",
        "print(ae_ddos_to_benign.iloc[0:1])\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "ax = pd.plotting.parallel_coordinates(benign.iloc[0:1], ' Label', color=('#00FF00'))\n",
        "\n",
        "ax = pd.plotting.parallel_coordinates(ddos.iloc[0:1], ' Label', color=('#0000FF'))\n",
        "\n",
        "ax = pd.plotting.parallel_coordinates(ae_ddos_to_benign.iloc[0:1], ' Label', color=('#FF6270'))\n",
        "\n",
        "ax.yaxis.grid(False) # horizontal lines\n",
        "ax.xaxis.grid(False) # vertical lines\n",
        "\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZVcf7SljPX-"
      },
      "source": [
        "## Per Feature Difference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WzFgENx5jXlB"
      },
      "outputs": [],
      "source": [
        "feature_difference = pd.DataFrame(columns=np.arange(58), dtype=np.dtype(\"float\"))\n",
        "feature_difference[' Label']  = \"\"\n",
        "#print(feature_difference.dtypes)\n",
        "\n",
        "\n",
        "for feature in ddos.columns:\n",
        "  if( feature == \" Label\"):\n",
        "    print(\"Label\\n\"); break\n",
        "\n",
        "  #print(ddos.iloc[0][feature])\n",
        "  \n",
        "\n",
        "  feature_difference.columns = ddos.columns\n",
        "  feature_difference[feature] = abs(ddos.iloc[0:1][feature].astype(float).sub(ae_ddos_to_benign.iloc[0:1][feature].astype(float), fill_value=0))\n",
        "#print(feature_difference.dtypes)\n",
        "\n",
        "feature_difference[' Label'] = \"Per Feature Absolute Difference\"\n",
        "print(feature_difference.dtypes)\n",
        "print(feature_difference)\n",
        "plt.figure(figsize=(20,5))\n",
        "# Hide grid lines\n",
        "ax.grid(False)\n",
        "\n",
        "ax = pd.plotting.parallel_coordinates(feature_difference.iloc[0:1], ' Label', color=('#FF6270', '#4ECDC4'))\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "\n",
        "\n",
        "#maybe get the mean of each feature and subtract them?\n",
        "\n",
        "#mean_feature_difference = pd.DataFrame(columns=np.arange(59), dtype=np.dtype(\"float\"))\n",
        "#mean_feature_difference.columns = ddos.columns\n",
        "#for feature in ddos.columns:  \n",
        "#  if( feature == \" Label\"):\n",
        "#        print(\"Label\\n\"); break   \n",
        "        \n",
        "#  #print(ddos.iloc[0][feature])     \n",
        "#  print(abs(ddos.iloc[0:2][feature].mean().sub(ae_ddos_to_benign.iloc[0:2][feature].mean(), fill_value=0)))\n",
        "\n",
        "#print(mean_feature_difference)\n",
        "#plt.figure(figsize=(20,5))\n",
        "#ax = pd.plotting.parallel_coordinates(mean_feature_difference.iloc[0:1].astype(float), ' Label', color=('#FF6270', '#4ECDC4'))\n",
        "#ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrnlyOiofyHo"
      },
      "source": [
        "## Mean Difference per Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xl9VnJ-X0Ipm"
      },
      "outputs": [],
      "source": [
        "numpy_ddos = ddos.to_numpy(copy=True)\n",
        "print(numpy_ddos)\n",
        "print(numpy_ddos.shape)\n",
        "numpy_ae_ddos_to_benign = ae_ddos_to_benign.to_numpy(copy=True)\n",
        "print(numpy_ae_ddos_to_benign)\n",
        "\n",
        "samples = 10000\n",
        "\n",
        "numpy_difference = np.zeros(shape=(samples,58))\n",
        "print(numpy_difference)\n",
        "for row in range(samples):\n",
        "  for feature_col in range(58):\n",
        "    pass\n",
        "    #print(numpy_ddos[row,feature_col])\n",
        "    numpy_difference[row,feature_col] = abs(numpy_ddos[row,feature_col] - numpy_ae_ddos_to_benign[row,feature_col])\n",
        "\n",
        "\n",
        "    #new_row[] = abs(ddosrow[ddosfeature] - advxrow[advxfeature])\n",
        "  print(\".\") #Done a row\\n\")\n",
        "print(\"Done {} rows\\n\".format(samples))\n",
        "print(numpy_difference)\n",
        "\n",
        "all_features = pd.DataFrame(numpy_difference,dtype=float,copy=True)\n",
        "all_features[' Label]'] = \"Difference\"\n",
        "#print(all_features)\n",
        "all_features.columns = ddos.columns\n",
        "#print(all_features)\n",
        "\n",
        "mean_feature_difference = pd.DataFrame(index=[0],columns=range(59),dtype=np.dtype(\"float\"),)\n",
        "mean_feature_difference.columns = all_features.columns\n",
        "for feature in all_features.columns:\n",
        "  if(feature == ' Label'):\n",
        "    mean_feature_difference[' Label'] = \"Mean Difference\"\n",
        "    break;\n",
        "  #print(all_features[feature].mean())\n",
        "  mean_feature_difference[feature] = all_features[feature].mean()\n",
        "print(mean_feature_difference)\n",
        "print(mean_feature_difference.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "# Hide grid lines\n",
        "ax.grid(False)\n",
        "# Turns off grid on the left Axis.\n",
        "ax.grid(False)\n",
        "\n",
        "plt.grid(b=None,which='both',axis='both')\n",
        "\n",
        "\n",
        "ax = pd.plotting.parallel_coordinates(mean_feature_difference.iloc[0:1], ' Label', color=('#FF6270', '#4ECDC4'))\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        "plt.grid(b=None,which='both',axis='both')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LElHpnN3MLN4"
      },
      "source": [
        "## Find the Biggest Difference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vfRs-gqQMRX9"
      },
      "outputs": [],
      "source": [
        "pass\n",
        "print(mean_feature_difference)\n",
        "#print(mean_feature_difference[' Label'])\n",
        "#drop the label\n",
        "mean_feature_difference = mean_feature_difference.drop(' Label', axis=1)\n",
        "numpy_mean_feature_difference = mean_feature_difference.to_numpy(copy=True)\n",
        "list_feature_names = []\n",
        "list_features_sorted_biggest_difference = []\n",
        "for column_name in ddos.columns:\n",
        "  list_feature_names.append(column_name)\n",
        "\n",
        "\n",
        "print(list_feature_names)\n",
        "\n",
        "\n",
        "\n",
        "print(numpy_mean_feature_difference.shape)\n",
        "for feature in range(58):\n",
        "  print(numpy_mean_feature_difference[0, feature])\n",
        "\n",
        "for feature in range(58):\n",
        "  maxvalue = np.argmax(numpy_mean_feature_difference)\n",
        "  print(maxvalue)\n",
        "  print(numpy_mean_feature_difference[0,maxvalue])\n",
        "  print(list_feature_names[maxvalue])\n",
        "  list_features_sorted_biggest_difference.append(list_feature_names[maxvalue])\n",
        "\n",
        "  #zero the difference\n",
        "  numpy_mean_feature_difference[0,maxvalue] = 0.0\n",
        "\n",
        "print(\"Sorted, Biggest Feature First\")\n",
        "print(list_features_sorted_biggest_difference)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4jJPqp5xCSv"
      },
      "source": [
        "## Find the smallest Difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nvLXqZRjxJ2D"
      },
      "outputs": [],
      "source": [
        "pass\n",
        "print(mean_feature_difference)\n",
        "#print(mean_feature_difference[' Label'])\n",
        "#drop the label\n",
        "#mean_feature_difference = mean_feature_difference.drop(' Label', axis=1)\n",
        "numpy_mean_feature_difference = mean_feature_difference.to_numpy(copy=True)\n",
        "list_feature_names = []\n",
        "list_features_sorted_smallest_difference = []\n",
        "for column_name in ddos.columns:\n",
        "  list_feature_names.append(column_name)\n",
        "\n",
        "\n",
        "print(list_feature_names)\n",
        "\n",
        "\n",
        "\n",
        "print(numpy_mean_feature_difference.shape)\n",
        "for feature in range(58):\n",
        "  print(numpy_mean_feature_difference[0, feature])\n",
        "\n",
        "for feature in range(58):\n",
        "  minxvalue = np.argmin(numpy_mean_feature_difference)\n",
        "  print(minxvalue)\n",
        "  print(numpy_mean_feature_difference[0,minxvalue])\n",
        "  print(list_feature_names[minxvalue])\n",
        "  list_features_sorted_smallest_difference.append(list_feature_names[minxvalue])\n",
        "\n",
        "  #Now make this a large difference so it's not used again\n",
        "  numpy_mean_feature_difference[0,minxvalue] = 100.00\n",
        "\n",
        "print(\"Sorted, Smallest Feature First\")\n",
        "print(list_features_sorted_smallest_difference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGLLjm0lna6P"
      },
      "source": [
        "#Parallel CoOrds Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cILK1pD45AsE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load in the dataset\n",
        "df = pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
        "#df = pd.read_csv('./CICIDS2017/TrafficLabelling/Monday-WorkingHours.pcap_ISCX.csv')\n",
        "# Remove NaN and Inf\n",
        "df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "# Remove columns with all zero values\n",
        "df = df.loc[:, (df != 0).any(axis=0)]\n",
        "# Output table\n",
        "print(\"Output Table\")\n",
        "df\n",
        "print(\"df.shape\")\n",
        "print(df.shape)\n",
        "print(\"ae_ddos_to_benign.shape\")\n",
        "print(ae_ddos_to_benign.shape)\n",
        "print(\"df.columns\")\n",
        "print(df.columns)\n",
        "print(\"ae_ddos_to_benign.columns\")\n",
        "print(ae_ddos_to_benign.columns)\n",
        "\n",
        "\n",
        "print(ae_ddos_to_benign.columns)\n",
        "\n",
        "print(X_adv.shape)\n",
        "\n",
        "#drop non numerics\n",
        "\n",
        "# Import scikit learn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Creating X and Y from the dataset\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df[' Label'])\n",
        "Y_attack = le.transform(df[' Label']) # multi-class \n",
        "Y_class = df.iloc[:,-1].values # binary\n",
        "\n",
        "# Extract only the numerical feature columns\n",
        "subset = df.iloc[:,7:65].astype(float)\n",
        "# Define the scaler\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# Apply the scaler to each column of our dataframe\n",
        "df2 = pd.DataFrame(min_max_scaler.fit_transform(subset), columns=subset.columns, index=subset.index)\n",
        "df2\n",
        "\n",
        "\n",
        "print(\"df2 columns\")\n",
        "print(df2.columns)\n",
        "print(df2.shape)\n",
        "\n",
        "print(\"df2 doesn't have label\")\n",
        "df2[' Label'] = \"\" #= \"NULL\"\n",
        "print(\"OK set columns to equal df2 columns\")\n",
        "\n",
        "ae_ddos_to_benign.columns = df2.columns\n",
        "\n",
        "print(\"done\")\n",
        "\n",
        "\n",
        "samples = 1000\n",
        "thousand_advx = ae_ddos_to_benign.iloc[0:samples]\n",
        "print(thousand_advx)\n",
        "iat_thousand_advx = thousand_advx[ thousand_advx.columns[ thousand_advx.columns.str.contains(\"IAT\") ] ]\n",
        "iat_thousand_advx[' Label'] =\"adv_x to appear benign\"\n",
        "\n",
        "\n",
        "print(iat_thousand_advx)\n",
        "\n",
        "\n",
        "# Here's an example of selecting all columns that contain the.phrase 'IAT'\n",
        "\n",
        "cols = 5\n",
        "\n",
        "df3 = df2[ df2.columns[ df2.columns.str.contains(\"IAT\") ] ]\n",
        "#df3 = df3.iloc[:,0:cols]\n",
        "\n",
        "df3[' Label'] = df2[' Label']\n",
        "\n",
        "# Reread the df \n",
        "\n",
        "samples = 1000\n",
        "benign3 = df3[df3[' Label'] == outcome[0]].iloc[0:samples,:]\n",
        "ddos3 = df3[df3[' Label'] == outcome[1]].iloc[0:samples,:]\n",
        "\n",
        "\n",
        "df3 = pd.concat([benign3, ddos3])\n",
        "df3\n",
        "print(df3.shape)\n",
        "\n",
        "plot_benign = benign.iloc[0:samples]\n",
        "plot_benign = benign[ benign.columns[ benign.columns.str.contains(\"IAT\") ] ]\n",
        "plot_benign[' Label'] = \"Benign\"\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "ax = pd.plotting.parallel_coordinates(plot_benign, ' Label', color=('#556270', '#4ECDC4'))\n",
        "ax = pd.plotting.parallel_coordinates(iat_thousand_advx, ' Label', color=('#FF0000', '#4ECDC4'))\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=12)\n",
        "ax.set_xticklabels(ax.get_yticklabels(), fontsize=12)\n",
        "ax.set_ylabel(\"Scaled Value\", fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1n44d3xZMaj"
      },
      "source": [
        "## END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PzTJtO3CfxFN"
      },
      "outputs": [],
      "source": [
        "#define pandas dataframe to hold all feature differences for each sample\n",
        "\n",
        "\n",
        "row_count = 0 \n",
        "all_feature_difference = []\n",
        "new_row = pd.DataFrame(columns = ddos.columns, dtype=np.dtype(\"float\"))\n",
        "#all_feature_difference = pd.DataFrame(columns=np.arange(58), dtype=np.dtype(\"float\"))\n",
        "#all_feature_difference = pd.DataFrame(index=np.arange(len(ddos.index)), columns=np.arange(58), dtype=np.dtype(\"float\"))\n",
        "#all_feature_difference[' Label']  = \"\"\n",
        "\n",
        "#define pandas dataframe for the mean difference\n",
        "mean_feature_difference = pd.DataFrame(columns=np.arange(58), dtype=np.dtype(\"float\"))\n",
        "mean_feature_difference[' Label']  = \"\"\n",
        "\n",
        "#set the colum names\n",
        "\n",
        "#all_feature_difference.columns = ddos.columns\n",
        "\n",
        "for ddosindex, ddosrow in ddos.iterrows():\n",
        "  for advindex, advxrow in ae_ddos_to_benign.iterrows():\n",
        "    \n",
        "\n",
        "      for ddosfeature in ddos.columns:\n",
        "        if(ddosfeature == ' Label'):\n",
        "            pass\n",
        "            #break;\n",
        "\n",
        "        for advxfeature in ae_ddos_to_benign.columns:\n",
        "          \n",
        "            if(ddosfeature == ' Label'):\n",
        "            \n",
        "              all_feature_difference.append(new_row)\n",
        "              row_count = row_count +1\n",
        "              if((row_count % 1000) == 0):\n",
        "                print(\"Done a row: \",row_count)\n",
        "                print(new_row)\n",
        "              break;\n",
        "\n",
        "            #print(advxfeature)\n",
        "            #print(\"Difference:\")\n",
        "            if(ddosfeature == advxfeature):\n",
        "\n",
        "              #print(abs(ddosrow[ddosfeature] - advxrow[advxfeature]))\n",
        "              new_row[advxfeature] = abs(ddosrow[ddosfeature] - advxrow[advxfeature])\n",
        "            #new_row[newindex] = abs(ddosrow[feature] - advxrow[advxfeature])\n",
        "            #print(new_row)\n",
        "          \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    #all_feature_difference.loc[row:feature] = abs(ddos.loc[row:feature].astype(float) - ae_ddos_to_benign.loc[row:feature].astype(float))\n",
        "  \n",
        "print(\"Done All Rows!\\n\")\n",
        "print(all_feature_difference)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#loop for each feature in each row\n",
        "for row in range(100): #len(ddos.index)):\n",
        "  #print(\"Row: {}\".format(row))\n",
        "\n",
        "  for feature in ddos.columns:\n",
        "    if( feature == \" Label\"):\n",
        "      #print(\"Label\\n\"); \n",
        "      break\n",
        "\n",
        "    #print(ddos.iloc[row][feature])\n",
        "  \n",
        "\n",
        "    #calculate the absolute difference and store it in the new pandas dataframe\n",
        "    #all_feature_difference.iloc[row:][feature] = abs(ddos.iloc[0:1][feature].astype(float).sub(ae_ddos_to_benign.iloc[0:1][feature].astype(float), fill_value=0))\n",
        "    \n",
        "    all_feature_difference.loc[row,feature] = abs(ddos.iloc[0:1][feature].astype(float).sub(ae_ddos_to_benign.iloc[0:1][feature].astype(float), fill_value=0))\n",
        "    \n",
        "\n",
        "    #all_feature_difference.iloc[row:][feature] = abs(ddos.iloc[row:][feature].astype(float).sub(ae_ddos_to_benign.iloc[row:][feature].astype(float), fill_value=0))\n",
        "    #print(feature_difference.dtypes)\n",
        "    #print(all_feature_difference.iloc[row:][feature])\n",
        "\n",
        "print(all_feature_difference)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mean_feature_difference[' Label'] = \"Per Feature Absolute Difference\"\n",
        "print(feature_difference.dtypes)\n",
        "print(feature_difference)\n",
        "plt.figure(figsize=(20,5))\n",
        "ax = pd.plotting.parallel_coordinates(feature_difference.iloc[0:1], ' Label', color=('#FF6270', '#4ECDC4'))\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90);\n",
        "\n",
        "for feature in ddos.columns:\n",
        "  print(feature)\n",
        "  mean_feature_difference[feature] = all_feature_difference.mean(column_name=feature)\n",
        "  print(mean_feature_difference[feature])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hchbAoEo5AsG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Fig12 coarse and fine - Better Keras2 Multiclassifier Systems.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}